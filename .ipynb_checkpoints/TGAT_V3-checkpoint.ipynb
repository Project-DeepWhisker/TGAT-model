{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393be218-97a4-45ba-8c22-cbc7496b4bb9",
   "metadata": {},
   "source": [
    "# preprocess_kdd_large.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85382bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Preprocessing for Large Datasets\n",
    "This notebook handles the preprocessing of KDD-like datasets, optimized for larger files using Dask.\n",
    "It performs the following steps:\n",
    "1. Loads raw data in chunks.\n",
    "2. Defines column names and types.\n",
    "3. Preprocesses labels (binary and multi-class).\n",
    "4. Preprocesses features:\n",
    "   - One-hot encodes categorical features using Dask's `get_dummies`.\n",
    "   - Scales numerical features using Dask's mean/std.\n",
    "5. Constructs temporal graph components (node features `x`, edge indices `edge_index`, timestamps `ts`).\n",
    "6. Saves the processed data and metadata for the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018adbb",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ee8550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (69.0.3)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.35.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.35.1\n",
      "    Uninstalling wheel-0.35.1:\n",
      "      Successfully uninstalled wheel-0.35.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.0.3\n",
      "    Uninstalling setuptools-69.0.3:\n",
      "      Successfully uninstalled setuptools-69.0.3\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient-utils 0.5.0 requires wheel<0.36.0,>=0.35.1, but you have wheel 0.45.1 which is incompatible.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-25.1.1 setuptools-80.8.0 wheel-0.45.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing PyG dependencies for Torch 2.1.1 and CUDA cu121...\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.1+cu121.html\n",
      "Collecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (935 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m936.0/936.0 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.3)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torch_cluster]0m [torch_sparse]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing pyg-lib for Torch 2.1.1 and CUDA cu121...\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.1.1+cu121.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp311-cp311-linux_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyg_lib\n",
      "Successfully installed pyg_lib-0.4.0+pt21cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch_geometric==2.6.1\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric==2.6.1) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric==2.6.1) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric==2.6.1) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric==2.6.1) (2020.6.20)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch-geometric-temporal==0.56.0\n",
      "  Downloading torch_geometric_temporal-0.56.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting decorator==4.4.2 (from torch-geometric-temporal==0.56.0)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.1.1+cu121)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.0.2)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (0.6.18+pt21cu121)\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.1.2+pt21cu121)\n",
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (1.26.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-geometric-temporal==0.56.0) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->torch-geometric-temporal==0.56.0) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (3.9.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2020.6.20)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse->torch-geometric-temporal==0.56.0) (1.11.2)\n",
      "Downloading torch_geometric_temporal-0.56.0-py3-none-any.whl (98 kB)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: decorator, torch-geometric-temporal\n",
      "\u001b[2K  Attempting uninstall: decorator\n",
      "\u001b[2K    Found existing installation: decorator 5.1.1\n",
      "\u001b[2K    Uninstalling decorator-5.1.1:\n",
      "\u001b[2K      Successfully uninstalled decorator-5.1.1━━\u001b[0m \u001b[32m0/2\u001b[0m [decorator]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch-geometric-temporal]\n",
      "\u001b[1A\u001b[2KSuccessfully installed decorator-4.4.2 torch-geometric-temporal-0.56.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
      "Collecting dask\n",
      "  Downloading dask-2025.5.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask) (8.1.7)\n",
      "Collecting cloudpickle>=3.0.0 (from dask)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask) (2023.6.0)\n",
      "Collecting partd>=1.4.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask) (5.4.1)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib_metadata>=4.13.0 (from dask)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata>=4.13.0->dask)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading dask-2025.5.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: zipp, toolz, locket, cloudpickle, partd, importlib_metadata, dask\n",
      "\u001b[2K  Attempting uninstall: zipp\n",
      "\u001b[2K    Found existing installation: zipp 1.0.0\n",
      "\u001b[2K    Uninstalling zipp-1.0.0:\n",
      "\u001b[2K      Successfully uninstalled zipp-1.0.0\n",
      "\u001b[2K  Attempting uninstall: cloudpickle━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K    Found existing installation: cloudpickle 2.2.1━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K    Uninstalling cloudpickle-2.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K      Successfully uninstalled cloudpickle-2.2.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K  Attempting uninstall: importlib_metadata━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K    Found existing installation: importlib-metadata 4.6.4━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K    Uninstalling importlib-metadata-4.6.4:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K      Successfully uninstalled importlib-metadata-4.6.4━━━━━━━\u001b[0m \u001b[32m1/7\u001b[0m [toolz]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [dask][32m6/7\u001b[0m [dask]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cloudpickle-3.1.1 dask-2025.5.1 importlib_metadata-8.7.0 locket-1.0.0 partd-1.4.2 toolz-1.0.0 zipp-3.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# --- Environment Setup ---\n",
    "# Make sure torch is installed first if not already\n",
    "# %pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install PyTorch Geometric core dependencies (adjust torch version and cuda suffix as needed)\n",
    "TORCH_VERSION = torch.__version__.split('+')[0] # Get base torch version\n",
    "CUDA_VERSION = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "CUDA_SUFFIX = f'cu{CUDA_VERSION}' if CUDA_VERSION != 'cpu' else 'cpu'\n",
    "print(f\"Installing PyG dependencies for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "\n",
    "# --- Install pyg-lib for potential speedup (addresses warning) ---\n",
    "print(f\"Installing pyg-lib for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install pyg_lib -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "%pip install \"torch_geometric==2.6.1\"\n",
    "%pip install \"torch-geometric-temporal==0.56.0\"\n",
    "\n",
    "# Other necessary libraries\n",
    "%pip install pandas numpy scikit-learn matplotlib seaborn tqdm requests dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afa06a-fc1d-4f50-9c81-ae6614625cac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 2: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ebf4cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # 確保導入 pandas\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import json\n",
    "# from tqdm import tqdm # tqdm 在 Dask 的直接 compute 中不那麼直觀\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = './data/' \n",
    "TRAIN_FILE = 'KDDTrain+_20Percent.txt' \n",
    "TEST_FILE = 'KDDTest+.txt'      \n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_large/'\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata.json')\n",
    "\n",
    "HIDDEN_DIM = 256  # Define HIDDEN_DIM for TGAT\n",
    "\n",
    "# --- NEW Parameters for Smarter Sampling in TemporalNeighborLoader (add these) ---\n",
    "RECENCY_BIAS_FACTOR = 0.9                 # Example: Value between 0 (strong bias) and <1. 0 means no bias beyond sorting.\n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'   # Example: Column name from raw data for similarity. Set to None to disable.\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3           # Example: Weight for similarity (0 to 1). 0 means no similarity bias.\n",
    "EARLY_STOPPING_PATIENCE = 20              # Example: If you moved this from train_pipeline to global\n",
    "\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = 128  # Example\n",
    "SEQUENCE_LENGTH = 15            # Example: Number of events in a sequence\n",
    "STEP_SIZE = 5                   # Example: Sliding window step\n",
    "SEQ_LABEL_MODE = 'any_attack'     # 'any_attack', 'all_attack', 'majority_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64       # Example\n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4  # Example\n",
    "EPOCHS_SEQ_MODEL = 30           # Example\n",
    "SEQ_MODEL_EMBEDDING_DIM = HIDDEN_DIM # This should be the dimension of embeddings from TGAT\n",
    "                                     # For example, if TGAT's last hidden layer before MLP is HIDDEN_DIM\n",
    "SEQ_MODEL_HIDDEN_DIM = 128       # Example\n",
    "SEQ_MODEL_NUM_LAYERS = 2          # Example\n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'        # 'GRU' or 'LSTM'\n",
    "SEQ_MODEL_DROPOUT = 0.3           # Example\n",
    "\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score'\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = ['protocol_type', 'service', 'flag']\n",
    "NUMERICAL_COLS = [col for col in COL_NAMES if col not in CATEGORICAL_COLS + ['attack_type', 'difficulty_score']]\n",
    "LABEL_COL = 'attack_type'\n",
    "NORMAL_TAG = 'normal'\n",
    "\n",
    "ATTACK_MAP_MULTI_CLASS = { \n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos', \n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe', \n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l', \n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r' \n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5b30e",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "171476e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Label Preprocessing Function\n",
    "def preprocess_labels_event_node_dask(df_chunk: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Preprocesses labels for a chunk of data (Pandas DataFrame). \"\"\"\n",
    "    df_chunk['label_binary'] = df_chunk[LABEL_COL].apply(lambda x: 0 if x == NORMAL_TAG else 1)\n",
    "    \n",
    "    def map_to_general_cat_id(attack_name):\n",
    "        if attack_name == NORMAL_TAG:\n",
    "            return ATTACK_MAP_MULTI_CLASS[NORMAL_TAG]\n",
    "        general_category = KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP.get(attack_name)\n",
    "        if general_category:\n",
    "            return ATTACK_MAP_MULTI_CLASS.get(general_category, UNKNOWN_ATTACK_CATEGORY_ID)\n",
    "        return UNKNOWN_ATTACK_CATEGORY_ID\n",
    "\n",
    "    df_chunk['label_multiclass_id'] = df_chunk[LABEL_COL].apply(map_to_general_cat_id)\n",
    "    return df_chunk[['label_binary', 'label_multiclass_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "custom_loader_cell",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Feature Scaler Fitting and Category Info (Minor refinement in comment/consistency)\n",
    "def fit_scalers_and_get_categories_info(ddf: dd.DataFrame, numerical_cols: list, categorical_cols: list):\n",
    "    \"\"\"\n",
    "    Computes means/stds for numerical columns and gets categorical feature names after one-hot encoding.\n",
    "    Assumes ddf[numerical_cols] contains numeric data and ddf[categorical_cols] has been categorized.\n",
    "    \"\"\"\n",
    "    print(\"Fitting scalers and determining categorical feature names...\")\n",
    "    # Numerical part remains the same\n",
    "    computed_means = ddf[numerical_cols].mean().compute()\n",
    "    computed_stds = ddf[numerical_cols].std().compute()\n",
    "    computed_stds = computed_stds.where(computed_stds != 0, 1.0) \n",
    "\n",
    "    # Categorical part: ddf[categorical_cols] should already have 'category' dtype with known categories\n",
    "    # from the .categorize() call in the main preprocessing function.\n",
    "    # So, ddf_cat_casted is essentially ddf[categorical_cols]\n",
    "    ddf_cat_subset = ddf[categorical_cols] \n",
    "    \n",
    "    # Get schema of dummy columns from a small sample for consistency.\n",
    "    # Since categories are known, head(1) or head(2) should be sufficient for schema.\n",
    "    # Compute=True is needed as head() is lazy.\n",
    "    sample_for_schema = ddf_cat_subset.head(max(2, ddf_cat_subset.npartitions if ddf_cat_subset.npartitions > 0 else 2), compute=True) \n",
    "    if sample_for_schema.empty and not ddf_cat_subset.known_divisions: # If dataframe is empty or structure is unknown after categorize\n",
    "        print(\"Warning: Categorical subset for dummy schema is empty or has unknown divisions. Using predefined columns for schema.\")\n",
    "        # Fallback to creating an empty DataFrame with expected columns if sample is problematic\n",
    "        # This might happen if the initial ddf was empty.\n",
    "        # This part might need more robust handling depending on how empty Dask DFs behave with categorize\n",
    "        categorical_feature_names_fitted = [] # Or load from a predefined schema if truly empty\n",
    "        if not ddf[categorical_cols].head(1).empty: # try again just in case.\n",
    "            dummy_ddf_schema = dd.get_dummies(ddf[categorical_cols].head(1), columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "            categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "\n",
    "    elif not sample_for_schema.empty:\n",
    "         dummy_ddf_schema = pd.get_dummies(sample_for_schema, columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "         categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "    else: # Fallback if sample_for_schema is empty but ddf_cat_subset was not entirely empty\n",
    "        print(\"Warning: Could not reliably determine dummy schema from sample. Categorical feature names might be incomplete.\")\n",
    "        categorical_feature_names_fitted = [f\"{col}_{cat}\" for col in categorical_cols for cat in ddf_cat_subset[col].cat.categories]\n",
    "\n",
    "\n",
    "    print(f\"Scalers determined. Categorical feature names derived: {len(categorical_feature_names_fitted)} features.\")\n",
    "    return computed_means, computed_stds, categorical_feature_names_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab3fa3-da28-43c8-88b8-3e7c552b743c",
   "metadata": {},
   "source": [
    "## 6. Main Preprocessing Orchestration (Function Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "562b4365-33ba-4ffc-bb1f-b38cf41c5520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Main Preprocessing Logic Function (CORRECTED for Warnings)\n",
    "def preprocess_and_save_temporal_data(raw_file_path: str, output_file_path: str,\n",
    "                                      numerical_cols_original_config: list,\n",
    "                                      categorical_cols: list, label_col: str,\n",
    "                                      is_training_set: bool = False,\n",
    "                                      fitted_scalers_and_cats_info: dict = None,\n",
    "                                      recent_window_size: int = 50):\n",
    "    \"\"\" Reads, preprocesses, and saves temporal data components. \"\"\"\n",
    "    print(f\"Starting preprocessing for: {raw_file_path}\")\n",
    "\n",
    "    current_numerical_cols = list(numerical_cols_original_config)\n",
    "    dtype_initial_read = {col: 'object' for col in COL_NAMES}\n",
    "\n",
    "    try:\n",
    "        ddf = dd.read_csv(raw_file_path, header=None, names=COL_NAMES, dtype=dtype_initial_read, blocksize='256MB', usecols=COL_NAMES)\n",
    "    except Exception as e:\n",
    "        print(f\"Dask read_csv error for {raw_file_path}: {e}. Attempting Pandas fallback.\")\n",
    "        df_chunks_list = []\n",
    "        for chunk_pd in pd.read_csv(raw_file_path, header=None, names=COL_NAMES, chunksize=100000, low_memory=False, dtype=str, usecols=COL_NAMES):\n",
    "             df_chunks_list.append(chunk_pd)\n",
    "        if not df_chunks_list:\n",
    "            raise ValueError(f\"Pandas fallback failed: No data read from {raw_file_path}\")\n",
    "        full_df_pandas = pd.concat(df_chunks_list, ignore_index=True)\n",
    "        nparts = max(1, int(np.ceil(len(full_df_pandas) / 500000)))\n",
    "        ddf = dd.from_pandas(full_df_pandas, npartitions=nparts)\n",
    "        print(f\"Pandas fallback to Dask DF successful with {nparts} partitions.\")\n",
    "\n",
    "    print(\"Converting original numerical columns to numeric type...\")\n",
    "    for col in numerical_cols_original_config:\n",
    "        if col in ddf.columns:\n",
    "            ddf[col] = dd.to_numeric(ddf[col], errors='coerce').fillna(0)\n",
    "        else:\n",
    "            print(f\"Warning: Original numerical column '{col}' not found in ddf during initial conversion for {raw_file_path}.\")\n",
    "\n",
    "    if 'temp_event_timestamp' not in ddf.columns:\n",
    "        ddf['temp_event_timestamp'] = ddf.index.astype(np.int64)\n",
    "    else:\n",
    "        ddf['temp_event_timestamp'] = dd.to_numeric(ddf['temp_event_timestamp'], errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "    print(\"Resetting index to prepare for setting a known, sorted index...\")\n",
    "    ddf = ddf.reset_index()\n",
    "    index_col_name_after_reset = 'index'\n",
    "    if index_col_name_after_reset not in ddf.columns and 'level_0' in ddf.columns:\n",
    "        index_col_name_after_reset = 'level_0'\n",
    "    elif index_col_name_after_reset not in ddf.columns and 0 in ddf.columns and ddf.columns[0] == 0 :\n",
    "        ddf = ddf.rename(columns={0: index_col_name_after_reset})\n",
    "    if index_col_name_after_reset not in ddf.columns:\n",
    "        if ddf.columns[0] not in COL_NAMES and ddf.columns[0] not in categorical_cols and ddf.columns[0] not in numerical_cols_original_config:\n",
    "            print(f\"Warning: Reset index column name '{index_col_name_after_reset}' not found. Trying to use first column '{ddf.columns[0]}' as index.\")\n",
    "            index_col_name_after_reset = ddf.columns[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not identify the reset index column. Columns are: {ddf.columns}\")\n",
    "    print(f\"Setting '{index_col_name_after_reset}' as new sorted index...\")\n",
    "    ddf = ddf.set_index(index_col_name_after_reset, drop=True, sorted=True)\n",
    "\n",
    "    print(\"Persisting ddf after setting new index...\")\n",
    "    ddf = ddf.persist()\n",
    "    print(f\"After set_index & persist: ddf npartitions: {ddf.npartitions}, divisions known: {ddf.known_divisions}, divisions: {ddf.divisions}\")\n",
    "    if not ddf.known_divisions:\n",
    "         print(\"CRITICAL WARNING: Base ddf still has unknown divisions after set_index(sorted=True) and persist.\")\n",
    "\n",
    "    print(f\"Ensuring specified categorical columns ({categorical_cols}) are 'category' dtype...\")\n",
    "    actual_categorical_cols_in_ddf = []\n",
    "    for col in categorical_cols:\n",
    "        if col in ddf.columns:\n",
    "            # MODIFICATION: Replace deprecated is_categorical_dtype\n",
    "            if not isinstance(ddf[col].dtype, pd.CategoricalDtype):\n",
    "                 ddf[col] = ddf[col].astype('category')\n",
    "            actual_categorical_cols_in_ddf.append(col)\n",
    "        else:\n",
    "            print(f\"Warning: Categorical column '{col}' not found in ddf for {raw_file_path}.\")\n",
    "\n",
    "    print(f\"Categorizing columns: {actual_categorical_cols_in_ddf}\")\n",
    "    if actual_categorical_cols_in_ddf:\n",
    "        ddf = ddf.categorize(columns=actual_categorical_cols_in_ddf)\n",
    "    else:\n",
    "        print(\"Warning: No specified categorical columns found in ddf to categorize.\")\n",
    "\n",
    "    print(\"Persisting ddf after categorization...\")\n",
    "    ddf = ddf.persist()\n",
    "    print(f\"After categorize & persist: ddf npartitions: {ddf.npartitions}, divisions known: {ddf.known_divisions}, divisions: {ddf.divisions}\")\n",
    "\n",
    "    print(f\"Starting enhanced feature engineering with window size: {recent_window_size}...\")\n",
    "    newly_engineered_feature_cols = []\n",
    "\n",
    "    PROXY_SRC_IP_COL = 'service'\n",
    "    PROXY_DST_IP_COL = 'dst_host_srv_count'\n",
    "    PROXY_DST_PORT_COL = 'service'\n",
    "    TIMESTAMP_COL = 'temp_event_timestamp'\n",
    "    DURATION_COL = 'duration'\n",
    "\n",
    "    if not all(c in ddf.columns for c in [PROXY_SRC_IP_COL, TIMESTAMP_COL]):\n",
    "        print(f\"Skipping 'time_since_last_event...' due to missing required columns: {PROXY_SRC_IP_COL} or {TIMESTAMP_COL}\")\n",
    "    else:\n",
    "        new_feat_time_since_last_src_proxy = f'time_since_last_event_same_{PROXY_SRC_IP_COL}_proxy'\n",
    "        # MODIFICATION: Change meta for ddf.groupby.transform to be a Pandas Series\n",
    "        meta_time_since = pd.Series(name=new_feat_time_since_last_src_proxy, dtype=np.int64) # Or float64 if diff can be float\n",
    "        ddf[new_feat_time_since_last_src_proxy] = ddf.groupby(PROXY_SRC_IP_COL, observed=True)[TIMESTAMP_COL].transform(\n",
    "            lambda x: x.diff().fillna(0),\n",
    "            meta=meta_time_since # Use Pandas Series for meta\n",
    "        ).astype(np.float32)\n",
    "        newly_engineered_feature_cols.append(new_feat_time_since_last_src_proxy)\n",
    "        print(f\"Engineered feature: {new_feat_time_since_last_src_proxy}\")\n",
    "\n",
    "    group_cols_for_avg_duration = [PROXY_DST_PORT_COL, PROXY_DST_IP_COL]\n",
    "    if not all(col in ddf.columns for col in group_cols_for_avg_duration) or DURATION_COL not in ddf.columns:\n",
    "        print(f\"Skipping 'avg_duration_recent...' due to missing columns for grouping or value ({group_cols_for_avg_duration}, {DURATION_COL}).\")\n",
    "    else:\n",
    "        new_feat_avg_duration_proxy = f'avg_duration_recent_same_{PROXY_DST_PORT_COL}_{PROXY_DST_IP_COL}_proxy'\n",
    "        if PROXY_DST_IP_COL in ddf.columns and pd.api.types.is_float_dtype(ddf[PROXY_DST_IP_COL].dtype):\n",
    "            ddf[PROXY_DST_IP_COL] = ddf[PROXY_DST_IP_COL].astype(int)\n",
    "\n",
    "        def expanding_avg_duration_partition(df_partition, group_cols_list_internal, val_col_internal, new_col_name_internal):\n",
    "            if not df_partition.empty and all(c in df_partition.columns for c in group_cols_list_internal) and val_col_internal in df_partition.columns:\n",
    "                for group_col_check in group_cols_list_internal:\n",
    "                     if pd.api.types.is_numeric_dtype(df_partition[group_col_check]) and df_partition[group_col_check].nunique() > 200 and len(df_partition) > 1000:\n",
    "                        print(f\"Warning: Grouping by high-cardinality numeric column '{group_col_check}' in expanding_avg_duration_partition within a partition.\")\n",
    "                try:\n",
    "                    df_partition[new_col_name_internal] = df_partition.groupby(group_cols_list_internal, observed=True)[val_col_internal].transform(\n",
    "                        lambda x: x.expanding().mean().fillna(0)\n",
    "                    )\n",
    "                except Exception as e_gb_transform:\n",
    "                    print(f\"Error in expanding_avg_duration_partition's groupby/transform: {e_gb_transform}. Filling with 0.\")\n",
    "                    df_partition[new_col_name_internal] = pd.Series(0, index=df_partition.index, dtype=np.float32)\n",
    "            else:\n",
    "                df_partition[new_col_name_internal] = pd.Series(0, index=df_partition.index, dtype=np.float32)\n",
    "            return df_partition[new_col_name_internal]\n",
    "\n",
    "        meta_avg_duration = pd.Series(name=new_feat_avg_duration_proxy, dtype=np.float32)\n",
    "        ddf[new_feat_avg_duration_proxy] = ddf.map_partitions(\n",
    "            expanding_avg_duration_partition,\n",
    "            group_cols_list_internal=group_cols_for_avg_duration,\n",
    "            val_col_internal=DURATION_COL,\n",
    "            new_col_name_internal=new_feat_avg_duration_proxy,\n",
    "            meta=meta_avg_duration\n",
    "        ).astype(np.float32)\n",
    "        newly_engineered_feature_cols.append(new_feat_avg_duration_proxy)\n",
    "        print(f\"Engineered feature: {new_feat_avg_duration_proxy}\")\n",
    "\n",
    "    if PROXY_SRC_IP_COL not in ddf.columns:\n",
    "        print(f\"Skipping 'count_recent_same_service_cum_proxy' as {PROXY_SRC_IP_COL} is missing.\")\n",
    "    else:\n",
    "        new_feat_count_recent_src_proxy = f'count_recent_same_{PROXY_SRC_IP_COL}_cum_proxy'\n",
    "        ddf[new_feat_count_recent_src_proxy] = ddf.groupby(PROXY_SRC_IP_COL, observed=True).cumcount().astype(np.float32)\n",
    "        newly_engineered_feature_cols.append(new_feat_count_recent_src_proxy)\n",
    "        print(f\"Engineered feature: {new_feat_count_recent_src_proxy}\")\n",
    "\n",
    "    ddf = ddf.persist()\n",
    "    print(f\"Finished enhanced feature engineering. Successfully added columns: {newly_engineered_feature_cols}\")\n",
    "\n",
    "    if label_col in ddf.columns:\n",
    "        meta_labels_df = pd.DataFrame({'label_binary': pd.Series(dtype='int'), 'label_multiclass_id': pd.Series(dtype='int')})\n",
    "        processed_labels_ddf = ddf.map_partitions(preprocess_labels_event_node_dask, meta=meta_labels_df)\n",
    "    else:\n",
    "        print(f\"Warning: Label column '{label_col}' not found in ddf for {raw_file_path}. Creating dummy labels.\")\n",
    "        num_rows_approx = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "        dummy_labels_data = {'label_binary': np.zeros(num_rows_approx, dtype=int),\n",
    "                             'label_multiclass_id': np.zeros(num_rows_approx, dtype=int)}\n",
    "        processed_labels_ddf = dd.from_pandas(pd.DataFrame(dummy_labels_data), npartitions=ddf.npartitions if ddf.npartitions > 0 else 1)\n",
    "\n",
    "    print(\"Preprocessing features...\")\n",
    "    current_numerical_cols.extend([col for col in newly_engineered_feature_cols if col in ddf.columns and col not in current_numerical_cols])\n",
    "    print(f\"Final numerical_cols for scaling consideration: {current_numerical_cols}\")\n",
    "\n",
    "    scaler_params_to_return_or_use = {}\n",
    "    cat_feat_names_final = []\n",
    "\n",
    "    if is_training_set:\n",
    "        actual_numerical_cols_for_fit = [col for col in current_numerical_cols if col in ddf.columns]\n",
    "        actual_categorical_cols_for_dummies = [col for col in categorical_cols if col in ddf.columns] # For get_dummies\n",
    "        \n",
    "        # fit_scalers_and_get_categories_info expects categorized columns.\n",
    "        # actual_categorical_cols_in_ddf are the ones that have been .astype('category') and ddf.categorize'd\n",
    "        \n",
    "        if not actual_numerical_cols_for_fit:\n",
    "            print(\"Warning: No numerical columns available for fitting scalers during training. Scalers will be empty.\")\n",
    "            fitted_means = pd.Series(dtype=float)\n",
    "            fitted_stds = pd.Series(dtype=float)\n",
    "        else:\n",
    "            fitted_means, fitted_stds, cat_feat_names_from_scaler_func = fit_scalers_and_get_categories_info(\n",
    "                ddf,\n",
    "                actual_numerical_cols_for_fit,\n",
    "                actual_categorical_cols_in_ddf # These are already categorized\n",
    "            )\n",
    "        cat_feat_names_final = cat_feat_names_from_scaler_func\n",
    "\n",
    "        scaler_params_to_return_or_use = {\n",
    "            'means': fitted_means.to_dict(), 'stds': fitted_stds.to_dict(),\n",
    "            'categorical_feature_names': cat_feat_names_final,\n",
    "            'all_numerical_cols_scaled': list(actual_numerical_cols_for_fit)\n",
    "        }\n",
    "    else: # Test set\n",
    "        if fitted_scalers_and_cats_info is None:\n",
    "            raise ValueError(\"fitted_scalers_and_cats_info must be provided for non-training sets.\")\n",
    "        fitted_means = pd.Series(fitted_scalers_and_cats_info['means'])\n",
    "        fitted_stds = pd.Series(fitted_scalers_and_cats_info['stds'])\n",
    "        cat_feat_names_final = fitted_scalers_and_cats_info['categorical_feature_names']\n",
    "        numerical_cols_scaled_during_training = fitted_scalers_and_cats_info.get('all_numerical_cols_scaled', [])\n",
    "        current_numerical_cols = [col for col in numerical_cols_scaled_during_training if col in ddf.columns]\n",
    "        missing_from_test_ddf = [col for col in numerical_cols_scaled_during_training if col not in ddf.columns]\n",
    "        if missing_from_test_ddf:\n",
    "            print(f\"Warning: Numerical columns scaled during training are missing from test ddf: {missing_from_test_ddf}.\")\n",
    "            for col_m in missing_from_test_ddf:\n",
    "                if col_m not in fitted_means: fitted_means[col_m] = 0.0\n",
    "                if col_m not in fitted_stds: fitted_stds[col_m] = 1.0\n",
    "        scaler_params_to_return_or_use = fitted_scalers_and_cats_info\n",
    "\n",
    "    numerical_cols_to_scale_in_ddf = [col for col in current_numerical_cols if col in ddf.columns]\n",
    "    if not numerical_cols_to_scale_in_ddf:\n",
    "        print(\"Warning: No numerical columns to scale found in current ddf. Creating empty scaled_numerical_ddf.\")\n",
    "        num_rows_for_empty_df = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "        scaled_numerical_ddf = dd.from_pandas(pd.DataFrame(index=pd.RangeIndex(num_rows_for_empty_df)),\n",
    "                                              npartitions=ddf.npartitions if ddf.npartitions > 0 else 1).persist()\n",
    "    else:\n",
    "        numerical_df_slice = ddf[numerical_cols_to_scale_in_ddf]\n",
    "        print(f\"Persisting numerical_df_slice (cols: {numerical_cols_to_scale_in_ddf}) before map_partitions for scaling...\")\n",
    "        numerical_df_slice = numerical_df_slice.persist()\n",
    "        print(f\"numerical_df_slice persisted: npart={numerical_df_slice.npartitions}, known_div={numerical_df_slice.known_divisions}, div={numerical_df_slice.divisions}\")\n",
    "\n",
    "        def scale_partition_func(partition_pd_df, means_pd_series, stds_pd_series):\n",
    "            cols_to_scale = partition_pd_df.columns\n",
    "            aligned_means = means_pd_series.reindex(cols_to_scale).fillna(0)\n",
    "            aligned_stds = stds_pd_series.reindex(cols_to_scale).fillna(1.0)\n",
    "            aligned_stds[aligned_stds == 0] = 1.0\n",
    "            return ((partition_pd_df - aligned_means) / aligned_stds).fillna(0)\n",
    "\n",
    "        # Ensure meta_scaled_numerical is a pandas DataFrame matching the output structure\n",
    "        # Use _meta_nonempty if available and non-empty, otherwise use _meta\n",
    "        if hasattr(numerical_df_slice, '_meta_nonempty') and not numerical_df_slice._meta_nonempty.empty:\n",
    "            meta_scaled_numerical = numerical_df_slice._meta_nonempty.copy().astype(float) # Ensure float for scaled output\n",
    "        elif not numerical_df_slice._meta.empty:\n",
    "            meta_scaled_numerical = numerical_df_slice._meta.copy().astype(float)\n",
    "        else: # Fallback if meta is empty (e.g., slice was empty)\n",
    "             meta_scaled_numerical = pd.DataFrame(columns=numerical_df_slice.columns, dtype=float)\n",
    "\n",
    "\n",
    "        print(\"Applying scaling via map_partitions...\")\n",
    "        scaled_numerical_ddf = numerical_df_slice.map_partitions(\n",
    "            scale_partition_func,\n",
    "            means_pd_series=fitted_means,\n",
    "            stds_pd_series=fitted_stds,\n",
    "            meta=meta_scaled_numerical\n",
    "        ).persist()\n",
    "\n",
    "    print(f\"scaled_numerical_ddf persisted: npart={scaled_numerical_ddf.npartitions}, known_div={scaled_numerical_ddf.known_divisions}, div={scaled_numerical_ddf.divisions}\")\n",
    "\n",
    "    if not actual_categorical_cols_in_ddf or not cat_feat_names_final:\n",
    "        print(\"Warning: No categorical columns to process or no cat_feat_names defined. Creating empty aligned_processed_features_ddf_cat.\")\n",
    "        num_rows_for_empty_df = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "        # Create an empty DataFrame with the correct index for alignment\n",
    "        empty_cat_df_pd = pd.DataFrame(columns=cat_feat_names_final if cat_feat_names_final else [],\n",
    "                                       index=pd.RangeIndex(num_rows_for_empty_df), dtype=np.int8)\n",
    "        aligned_processed_features_ddf_cat = dd.from_pandas(empty_cat_df_pd,\n",
    "                                                            npartitions=ddf.npartitions if ddf.npartitions > 0 else 1)\n",
    "        if ddf.npartitions > 0 and num_rows_for_empty_df > 0 and ddf.index.name is not None: # Check if index is valid\n",
    "            try:\n",
    "                aligned_processed_features_ddf_cat = aligned_processed_features_ddf_cat.set_index(ddf.index)\n",
    "            except Exception as e_set_index_empty:\n",
    "                print(f\"Could not set index for empty categorical df: {e_set_index_empty}. Proceeding with default index.\")\n",
    "\n",
    "        aligned_processed_features_ddf_cat = aligned_processed_features_ddf_cat.persist()\n",
    "    else:\n",
    "        # Use actual_categorical_cols_in_ddf which are confirmed to exist and are categorized\n",
    "        processed_features_ddf_cat_raw = dd.get_dummies(ddf[actual_categorical_cols_in_ddf],\n",
    "                                                        prefix=actual_categorical_cols_in_ddf, dummy_na=False)\n",
    "        def align_partition_columns_func(partition_df, target_columns_list):\n",
    "            aligned_partition = pd.DataFrame(0, index=partition_df.index, columns=target_columns_list)\n",
    "            common_cols_in_partition = [col for col in partition_df.columns if col in target_columns_list]\n",
    "            if common_cols_in_partition:\n",
    "                aligned_partition[common_cols_in_partition] = partition_df[common_cols_in_partition]\n",
    "            return aligned_partition.astype(np.int8)\n",
    "\n",
    "        meta_for_aligned_cat = pd.DataFrame(columns=cat_feat_names_final, dtype=np.int8)\n",
    "        aligned_processed_features_ddf_cat = processed_features_ddf_cat_raw.map_partitions(\n",
    "            align_partition_columns_func, target_columns_list=cat_feat_names_final, meta=meta_for_aligned_cat\n",
    "        ).persist()\n",
    "\n",
    "    if ddf.known_divisions:\n",
    "        print(f\"Base ddf has known divisions: {ddf.divisions}. Enforcing these divisions on derived DFs.\")\n",
    "        if scaled_numerical_ddf.divisions != ddf.divisions :\n",
    "             if not (scaled_numerical_ddf.npartitions == 1 and scaled_numerical_ddf.divisions[0] is None and scaled_numerical_ddf.divisions[1] is None):\n",
    "                print(f\"Aligning scaled_numerical_ddf divisions from ({scaled_numerical_ddf.divisions}) to base ddf ({ddf.divisions}).\")\n",
    "                scaled_numerical_ddf = scaled_numerical_ddf.repartition(divisions=ddf.divisions).persist()\n",
    "        if aligned_processed_features_ddf_cat.divisions != ddf.divisions:\n",
    "            if not (aligned_processed_features_ddf_cat.npartitions == 1 and aligned_processed_features_ddf_cat.divisions[0] is None and aligned_processed_features_ddf_cat.divisions[1] is None):\n",
    "                print(f\"Aligning aligned_cat_ddf divisions from ({aligned_processed_features_ddf_cat.divisions}) to base ddf ({ddf.divisions}).\")\n",
    "                aligned_processed_features_ddf_cat = aligned_processed_features_ddf_cat.repartition(divisions=ddf.divisions).persist()\n",
    "    \n",
    "    print(f\"Before concat: Numerical npart={scaled_numerical_ddf.npartitions}, known_div={scaled_numerical_ddf.known_divisions}, div={scaled_numerical_ddf.divisions}, cols={len(scaled_numerical_ddf.columns)}\")\n",
    "    print(f\"Before concat: Categorical npart={aligned_processed_features_ddf_cat.npartitions}, known_div={aligned_processed_features_ddf_cat.known_divisions}, div={aligned_processed_features_ddf_cat.divisions}, cols={len(aligned_processed_features_ddf_cat.columns)}\")\n",
    "\n",
    "    is_numerical_effectively_empty = len(scaled_numerical_ddf.columns) == 0 or (scaled_numerical_ddf.map_partitions(len).compute().sum() == 0)\n",
    "    is_categorical_effectively_empty = len(aligned_processed_features_ddf_cat.columns) == 0 or (aligned_processed_features_ddf_cat.map_partitions(len).compute().sum() == 0)\n",
    "    \n",
    "    num_original_rows = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "\n",
    "    if is_numerical_effectively_empty and is_categorical_effectively_empty:\n",
    "        print(\"Both numerical and categorical feature sets are effectively empty. Resulting features will be zero array.\")\n",
    "        x_np = np.zeros((num_original_rows, 1 if num_original_rows > 0 else 0), dtype=np.float32)\n",
    "    elif is_numerical_effectively_empty:\n",
    "        print(\"Numerical features are effectively empty. Using only categorical features.\")\n",
    "        final_features_ddf = aligned_processed_features_ddf_cat.persist()\n",
    "        x_np = final_features_ddf.compute().to_numpy(dtype=np.float32)\n",
    "    elif is_categorical_effectively_empty:\n",
    "        print(\"Categorical features are effectively empty. Using only numerical features.\")\n",
    "        final_features_ddf = scaled_numerical_ddf.persist()\n",
    "        x_np = final_features_ddf.compute().to_numpy(dtype=np.float32)\n",
    "    else:\n",
    "        try:\n",
    "            if not (scaled_numerical_ddf.known_divisions and aligned_processed_features_ddf_cat.known_divisions and scaled_numerical_ddf.divisions == aligned_processed_features_ddf_cat.divisions):\n",
    "                 print(\"Divisions mismatch or unknown before concat, attempting repartition to base ddf divisions or npartitions.\")\n",
    "                 if ddf.known_divisions:\n",
    "                    if scaled_numerical_ddf.divisions != ddf.divisions: scaled_numerical_ddf = scaled_numerical_ddf.repartition(divisions=ddf.divisions).persist()\n",
    "                    if aligned_processed_features_ddf_cat.divisions != ddf.divisions: aligned_processed_features_ddf_cat = aligned_processed_features_ddf_cat.repartition(divisions=ddf.divisions).persist()\n",
    "                 else:\n",
    "                     target_nparts = ddf.npartitions if ddf.npartitions > 0 else 1\n",
    "                     if scaled_numerical_ddf.npartitions != target_nparts: scaled_numerical_ddf = scaled_numerical_ddf.repartition(npartitions=target_nparts).persist()\n",
    "                     if aligned_processed_features_ddf_cat.npartitions != target_nparts: aligned_processed_features_ddf_cat = aligned_processed_features_ddf_cat.repartition(npartitions=target_nparts).persist()\n",
    "\n",
    "            if (scaled_numerical_ddf.known_divisions and\n",
    "                aligned_processed_features_ddf_cat.known_divisions and\n",
    "                scaled_numerical_ddf.divisions == aligned_processed_features_ddf_cat.divisions):\n",
    "                print(\"Attempting dd.concat with known and matching divisions.\")\n",
    "                final_features_ddf = dd.concat([scaled_numerical_ddf, aligned_processed_features_ddf_cat], axis=1, interleave_partitions=False) # Try False for interleave\n",
    "            else:\n",
    "                print(\"Divisions still unknown or mismatching for concat. Falling back to dd.merge on index after reset.\")\n",
    "                df1_indexed = scaled_numerical_ddf.reset_index()\n",
    "                df2_indexed = aligned_processed_features_ddf_cat.reset_index()\n",
    "                merge_on_col = 'index'\n",
    "                if merge_on_col not in df1_indexed.columns and 'level_0' in df1_indexed.columns: df1_indexed = df1_indexed.rename(columns={'level_0': merge_on_col})\n",
    "                if merge_on_col not in df2_indexed.columns and 'level_0' in df2_indexed.columns: df2_indexed = df2_indexed.rename(columns={'level_0': merge_on_col})\n",
    "                if merge_on_col not in df1_indexed.columns: raise ValueError(f\"Merge column '{merge_on_col}' not found in df1_indexed. Cols: {df1_indexed.columns}\")\n",
    "                if merge_on_col not in df2_indexed.columns: raise ValueError(f\"Merge column '{merge_on_col}' not found in df2_indexed. Cols: {df2_indexed.columns}\")\n",
    "                final_features_ddf = dd.merge(df1_indexed, df2_indexed, on=merge_on_col, how='inner')\n",
    "                if merge_on_col in final_features_ddf.columns: final_features_ddf = final_features_ddf.set_index(merge_on_col, drop=True, sorted=True)\n",
    "                print(\"Used dd.merge with reset_index as a fallback.\")\n",
    "            \n",
    "            final_features_ddf = final_features_ddf.persist()\n",
    "            x_np = final_features_ddf.compute().to_numpy(dtype=np.float32)\n",
    "        except Exception as e_final_combine:\n",
    "            print(f\"Final combination (concat or merge) failed: {e_final_combine}. Creating dummy x_np.\")\n",
    "            num_feat_dim_est = (len(scaled_numerical_ddf.columns) if not is_numerical_effectively_empty else 0) + \\\n",
    "                               (len(aligned_processed_features_ddf_cat.columns) if not is_categorical_effectively_empty else 0)\n",
    "            num_feat_dim_est = num_feat_dim_est if num_feat_dim_est > 0 else 1\n",
    "            x_np = np.zeros((num_original_rows, num_feat_dim_est), dtype=np.float32)\n",
    "\n",
    "    if len(x_np) != num_original_rows:\n",
    "        print(f\"Warning: x_np row count {len(x_np)} mismatch with original data {num_original_rows} after combination.\")\n",
    "        if len(x_np) == 0 and num_original_rows > 0:\n",
    "            print(\"x_np is empty, creating dummy zero features.\")\n",
    "            num_feat_dim_est = (len(scaled_numerical_ddf.columns) if hasattr(scaled_numerical_ddf, 'columns') and scaled_numerical_ddf.columns is not None else 0) + \\\n",
    "                               (len(aligned_processed_features_ddf_cat.columns) if hasattr(aligned_processed_features_ddf_cat, 'columns') and aligned_processed_features_ddf_cat.columns is not None else 0)\n",
    "            num_feat_dim_est = num_feat_dim_est if num_feat_dim_est > 0 else 1\n",
    "            x_np = np.zeros((num_original_rows, num_feat_dim_est), dtype=np.float32)\n",
    "\n",
    "    node_feat_dim = x_np.shape[1] if x_np.ndim == 2 and x_np.shape[0] > 0 else 0\n",
    "    print(f\"Node feature dimension: {node_feat_dim}\")\n",
    "\n",
    "    labels_computed_df = processed_labels_ddf.compute()\n",
    "    if len(labels_computed_df) != num_original_rows:\n",
    "        print(f\"Warning: Label count {len(labels_computed_df)} mismatch with original data {num_original_rows}. Adjusting labels.\")\n",
    "        if num_original_rows == 0:\n",
    "            y_binary_np = np.array([], dtype=np.int64)\n",
    "            y_multiclass_np = np.array([], dtype=np.int64)\n",
    "        elif len(labels_computed_df) == 0 and num_original_rows > 0:\n",
    "            y_binary_np = np.zeros(num_original_rows, dtype=np.int64)\n",
    "            y_multiclass_np = np.zeros(num_original_rows, dtype=np.int64)\n",
    "        elif len(labels_computed_df) > num_original_rows:\n",
    "            y_binary_np = labels_computed_df['label_binary'].to_numpy(dtype=np.int64)[:num_original_rows]\n",
    "            y_multiclass_np = labels_computed_df['label_multiclass_id'].to_numpy(dtype=np.int64)[:num_original_rows]\n",
    "        else:\n",
    "            y_binary_np = np.pad(labels_computed_df['label_binary'].to_numpy(dtype=np.int64), (0, num_original_rows - len(labels_computed_df)), 'edge')\n",
    "            y_multiclass_np = np.pad(labels_computed_df['label_multiclass_id'].to_numpy(dtype=np.int64), (0, num_original_rows - len(labels_computed_df)), 'edge')\n",
    "    else:\n",
    "        y_binary_np = labels_computed_df['label_binary'].to_numpy(dtype=np.int64)\n",
    "        y_multiclass_np = labels_computed_df['label_multiclass_id'].to_numpy(dtype=np.int64)\n",
    "    \n",
    "    print(\"Conversion to NumPy arrays complete.\")\n",
    "\n",
    "    num_nodes = len(x_np)\n",
    "    x_tensor = torch.from_numpy(x_np).float()\n",
    "    edge_index_tensor = torch.empty((2,0)).long()\n",
    "    if num_nodes > 1:\n",
    "        edge_src = torch.arange(0, num_nodes - 1)\n",
    "        edge_dst = torch.arange(1, num_nodes)\n",
    "        edge_index_tensor = torch.stack([edge_src, edge_dst], dim=0).long()\n",
    "\n",
    "    ts_tensor = torch.arange(0, num_nodes).long()\n",
    "    y_binary_tensor = torch.from_numpy(y_binary_np).float().unsqueeze(1) if len(y_binary_np)>0 else torch.empty((0,1)).float()\n",
    "    y_multiclass_tensor = torch.from_numpy(y_multiclass_np).long() if len(y_multiclass_np)>0 else torch.empty(0).long()\n",
    "\n",
    "    data_to_save = {\n",
    "        'x': x_tensor, 'edge_index': edge_index_tensor, 'ts': ts_tensor,\n",
    "        'y_binary': y_binary_tensor, 'y_multiclass': y_multiclass_tensor, 'num_nodes': num_nodes\n",
    "    }\n",
    "    torch.save(data_to_save, output_file_path)\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "\n",
    "    current_set_metadata = {\n",
    "        'node_feat_dim': node_feat_dim, 'num_nodes': num_nodes,\n",
    "        'labels_binary_unique_count': len(np.unique(y_binary_np)) if len(y_binary_np) > 0 else 0,\n",
    "        'labels_multiclass_unique_count': len(np.unique(y_multiclass_np)) if len(y_multiclass_np) > 0 else 0,\n",
    "        'engineered_feature_cols': newly_engineered_feature_cols\n",
    "    }\n",
    "\n",
    "    if is_training_set:\n",
    "        pos_weight_binary = 1.0\n",
    "        if len(y_binary_np) > 0 :\n",
    "            sum_y_binary = np.sum(y_binary_np)\n",
    "            if sum_y_binary > 0 and sum_y_binary < len(y_binary_np):\n",
    "                neg_count = len(y_binary_np) - sum_y_binary\n",
    "                pos_count = sum_y_binary\n",
    "                pos_weight_binary = neg_count / (pos_count + 1e-7)\n",
    "            elif sum_y_binary == len(y_binary_np):\n",
    "                 print(\"Warning: All labels are positive in training set for pos_weight calculation.\")\n",
    "                 pos_weight_binary = 0.01\n",
    "            else:\n",
    "                 print(\"Warning: No positive labels in training set for pos_weight calculation.\")\n",
    "                 pos_weight_binary = 1.0\n",
    "        current_set_metadata['pos_weight_binary'] = pos_weight_binary\n",
    "    \n",
    "    return current_set_metadata, scaler_params_to_return_or_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49628f-5666-47cd-bc29-0d3933214633",
   "metadata": {},
   "source": [
    "## 7. Execute Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25eb960d-6302-4bb5-afda-e09ce17923a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preprocessing Pipeline ---\n",
      "Starting preprocessing for: ./data/KDDTrain+_20Percent.txt\n",
      "Converting original numerical columns to numeric type...\n",
      "Resetting index to prepare for setting a known, sorted index...\n",
      "Setting 'index' as new sorted index...\n",
      "Persisting ddf after setting new index...\n",
      "After set_index & persist: ddf npartitions: 1, divisions known: True, divisions: (0, 25191)\n",
      "Ensuring specified categorical columns (['protocol_type', 'service', 'flag']) are 'category' dtype...\n",
      "Categorizing columns: ['protocol_type', 'service', 'flag']\n",
      "Persisting ddf after categorization...\n",
      "After categorize & persist: ddf npartitions: 1, divisions known: True, divisions: (0, 25191)\n",
      "Starting enhanced feature engineering with window size: 50...\n",
      "Engineered feature: time_since_last_event_same_service_proxy\n",
      "Engineered feature: avg_duration_recent_same_service_dst_host_srv_count_proxy\n",
      "Engineered feature: count_recent_same_service_cum_proxy\n",
      "Finished enhanced feature engineering. Successfully added columns: ['time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "Preprocessing features...\n",
      "Final numerical_cols for scaling consideration: ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "Fitting scalers and determining categorical feature names...\n",
      "Scalers determined. Categorical feature names derived: 80 features.\n",
      "Persisting numerical_df_slice (cols: ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']) before map_partitions for scaling...\n",
      "numerical_df_slice persisted: npart=1, known_div=True, div=(0, 25191)\n",
      "Applying scaling via map_partitions...\n",
      "scaled_numerical_ddf persisted: npart=1, known_div=True, div=(0, 25191)\n",
      "Base ddf has known divisions: (0, 25191). Enforcing these divisions on derived DFs.\n",
      "Before concat: Numerical npart=1, known_div=True, div=(0, 25191), cols=41\n",
      "Before concat: Categorical npart=1, known_div=True, div=(0, 25191), cols=80\n",
      "Attempting dd.concat with known and matching divisions.\n",
      "Node feature dimension: 121\n",
      "Conversion to NumPy arrays complete.\n",
      "Processed data saved to ./processed_data_large/train_temporal_data.pt\n",
      "\n",
      "--- Training Data Preprocessing Summary ---\n",
      "node_feat_dim: 121\n",
      "num_nodes: 25192\n",
      "labels_binary_unique_count: 2\n",
      "labels_multiclass_unique_count: 5\n",
      "engineered_feature_cols: ['time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "pos_weight_binary: 1.1452780379703202\n",
      "Starting preprocessing for: ./data/KDDTest+.txt\n",
      "Converting original numerical columns to numeric type...\n",
      "Resetting index to prepare for setting a known, sorted index...\n",
      "Setting 'index' as new sorted index...\n",
      "Persisting ddf after setting new index...\n",
      "After set_index & persist: ddf npartitions: 1, divisions known: True, divisions: (0, 22543)\n",
      "Ensuring specified categorical columns (['protocol_type', 'service', 'flag']) are 'category' dtype...\n",
      "Categorizing columns: ['protocol_type', 'service', 'flag']\n",
      "Persisting ddf after categorization...\n",
      "After categorize & persist: ddf npartitions: 1, divisions known: True, divisions: (0, 22543)\n",
      "Starting enhanced feature engineering with window size: 50...\n",
      "Engineered feature: time_since_last_event_same_service_proxy\n",
      "Engineered feature: avg_duration_recent_same_service_dst_host_srv_count_proxy\n",
      "Engineered feature: count_recent_same_service_cum_proxy\n",
      "Finished enhanced feature engineering. Successfully added columns: ['time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "Preprocessing features...\n",
      "Final numerical_cols for scaling consideration: ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "Persisting numerical_df_slice (cols: ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']) before map_partitions for scaling...\n",
      "numerical_df_slice persisted: npart=1, known_div=True, div=(0, 22543)\n",
      "Applying scaling via map_partitions...\n",
      "scaled_numerical_ddf persisted: npart=1, known_div=True, div=(0, 22543)\n",
      "Base ddf has known divisions: (0, 22543). Enforcing these divisions on derived DFs.\n",
      "Before concat: Numerical npart=1, known_div=True, div=(0, 22543), cols=41\n",
      "Before concat: Categorical npart=1, known_div=True, div=(0, 22543), cols=80\n",
      "Attempting dd.concat with known and matching divisions.\n",
      "Node feature dimension: 121\n",
      "Conversion to NumPy arrays complete.\n",
      "Processed data saved to ./processed_data_large/test_temporal_data.pt\n",
      "\n",
      "--- Test Data Preprocessing Summary ---\n",
      "node_feat_dim: 121\n",
      "num_nodes: 22544\n",
      "labels_binary_unique_count: 2\n",
      "labels_multiclass_unique_count: 5\n",
      "engineered_feature_cols: ['time_since_last_event_same_service_proxy', 'avg_duration_recent_same_service_dst_host_srv_count_proxy', 'count_recent_same_service_cum_proxy']\n",
      "\n",
      "Global metadata saved to ./processed_data_large/metadata.json\n",
      "--- Data Preprocessing Pipeline Finished ---\n"
     ]
    }
   ],
   "source": [
    "# Cell: Main execution block\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting Data Preprocessing Pipeline ---\")\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    if not os.path.exists(RAW_DATA_DIR):\n",
    "        os.makedirs(RAW_DATA_DIR)\n",
    "        print(f\"Created directory: {RAW_DATA_DIR}\")\n",
    "        print(f\"Please place '{TRAIN_FILE}' and '{TEST_FILE}' in this directory.\")\n",
    "        # As a placeholder, create dummy files if they are missing, so the script can run\n",
    "        if not os.path.exists(os.path.join(RAW_DATA_DIR, TRAIN_FILE)):\n",
    "            with open(os.path.join(RAW_DATA_DIR, TRAIN_FILE), 'w') as f:\n",
    "                f.write(\"0,tcp,http,SF,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,normal,0\\n\")\n",
    "                f.write(\"0,udp,domain,SF,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,normal,0\\n\")\n",
    "                f.write(\"1,tcp,ftp,SF,100,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,1,0,0,2,2,0.5,0,0,0,0,0,0,0,neptune,0\\n\")\n",
    "\n",
    "        if not os.path.exists(os.path.join(RAW_DATA_DIR, TEST_FILE)):\n",
    "            with open(os.path.join(RAW_DATA_DIR, TEST_FILE), 'w') as f:\n",
    "                f.write(\"0,tcp,telnet,SF,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,normal,0\\n\")\n",
    "                f.write(\"0,tcp,http,SF,200,500,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,1,0,1,0,0,0,0,0,back,0\\n\")\n",
    "\n",
    "\n",
    "    train_raw_path = os.path.join(RAW_DATA_DIR, TRAIN_FILE)\n",
    "    train_set_metadata, fitted_scalers_and_categories = preprocess_and_save_temporal_data(\n",
    "        raw_file_path=train_raw_path, output_file_path=PROCESSED_TRAIN_FILE,\n",
    "        numerical_cols_original_config=NUMERICAL_COLS, \n",
    "        categorical_cols=CATEGORICAL_COLS, label_col=LABEL_COL,\n",
    "        is_training_set=True\n",
    "    )\n",
    "\n",
    "    if train_set_metadata and fitted_scalers_and_categories:\n",
    "        print(\"\\n--- Training Data Preprocessing Summary ---\")\n",
    "        for key, val in train_set_metadata.items(): print(f\"{key}: {val}\")\n",
    "\n",
    "        test_raw_path = os.path.join(RAW_DATA_DIR, TEST_FILE)\n",
    "        test_set_metadata, _ = preprocess_and_save_temporal_data(\n",
    "            raw_file_path=test_raw_path, output_file_path=PROCESSED_TEST_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS, \n",
    "            categorical_cols=CATEGORICAL_COLS, label_col=LABEL_COL,\n",
    "            is_training_set=False, fitted_scalers_and_cats_info=fitted_scalers_and_categories\n",
    "        )\n",
    "\n",
    "        if test_set_metadata:\n",
    "            print(\"\\n--- Test Data Preprocessing Summary ---\")\n",
    "            for key, val in test_set_metadata.items(): print(f\"{key}: {val}\")\n",
    "\n",
    "            global_metadata_to_save = {\n",
    "                'NODE_FEAT_DIM': train_set_metadata['node_feat_dim'],\n",
    "                'NUM_CLASSES_BINARY': 2,\n",
    "                'NUM_CLASSES_MULTI': len(ATTACK_MAP_MULTI_CLASS) + (1 if UNKNOWN_ATTACK_CATEGORY_ID > max(ATTACK_MAP_MULTI_CLASS.values()) else 0) ,\n",
    "                'POS_WEIGHT_BINARY': train_set_metadata.get('pos_weight_binary', 1.0),\n",
    "                'train_num_nodes': train_set_metadata['num_nodes'],\n",
    "                'test_num_nodes': test_set_metadata['num_nodes'],\n",
    "                'categorical_feature_names': fitted_scalers_and_categories.get('categorical_feature_names', []),\n",
    "                'numerical_cols_list': fitted_scalers_and_categories.get('all_numerical_cols_scaled', NUMERICAL_COLS),\n",
    "                'engineered_feature_cols_list': train_set_metadata.get('engineered_feature_cols', [])\n",
    "            }\n",
    "            \n",
    "            with open(METADATA_FILE, 'w') as f:\n",
    "                json.dump(global_metadata_to_save, f, indent=4)\n",
    "            print(f\"\\nGlobal metadata saved to {METADATA_FILE}\")\n",
    "    else:\n",
    "        print(\"Training data processing failed. Aborting subsequent steps.\")\n",
    "    print(\"--- Data Preprocessing Pipeline Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21455837-2372-429b-9682-953c9e6cfc6b",
   "metadata": {},
   "source": [
    "## 8. Notes on Preprocessing\n",
    "- **Memory for `.compute()`**: The step `final_features_ddf.compute().to_numpy(dtype=np.float32)` will load all processed features into memory. For extremely large datasets where even the processed feature matrix doesn't fit, this part needs to be re-written to save the Dask DataFrame to a format like Parquet and then load it in chunks in the training script, or process Dask Arrays partition by partition into tensors.\n",
    "- **Dask `get_dummies` Consistency**: Ensuring `dd.get_dummies` on the test set produces columns consistent with the training set is critical. The `aligned_processed_features_ddf_cat` logic attempts to handle this by reindexing partitions based on `cat_feat_names` derived from the training set.\n",
    "- **Timestamps (`ts`)**: Currently, event indices are used as timestamps. If your data has actual timestamps, they should be used and appropriately scaled/normalized if necessary for the time encoder in TGAT.\n",
    "- **Error Handling & Robustness**: More error handling can be added, especially around file I/O and Dask computations. The KDD fallback is one example.\n",
    "- **Dask Performance**: `blocksize` in `dd.read_csv` and `npartitions` in `dd.from_pandas` can significantly affect Dask performance. These may need tuning based on your specific dataset size and system resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd438c-e086-44fb-817c-947e7a5936dc",
   "metadata": {},
   "source": [
    "# train_tgat_from_processed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747aa7d6-50d9-4365-bb99-77626ea95781",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Model Training from Preprocessed Data\n",
    "This notebook loads preprocessed temporal graph data and trains the TGAT model for network intrusion detection.\n",
    "**Prerequisites**:\n",
    "- Run `preprocess_kdd_large.ipynb` first to generate the `processed_data_large` directory with training/testing data and metadata.\n",
    "**Steps**:\n",
    "1. Configure paths and hyperparameters.\n",
    "2. Define utility functions, TGAT model, and TemporalNeighborLoader.\n",
    "3. Implement data loading function for preprocessed files.\n",
    "4. Implement training and evaluation functions.\n",
    "5. Orchestrate the training process.\n",
    "6. Plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12fa2200-b4b2-455e-b18f-e2133bb9dc90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import TemporalData \n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, \n",
    "                             confusion_matrix, roc_auc_score, classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.auto import tqdm \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import pandas as pd \n",
    "\n",
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "# --- Configuration ---\n",
    "# ** CRITICAL: ENSURE THESE PATHS AND FILENAMES ARE CORRECT FOR YOUR SYSTEM **\n",
    "RAW_DATA_DIR = './data/'  # Path to the directory containing original KDD .txt files\n",
    "TRAIN_FILE = 'KDDTrain+_20Percent.txt' # Original KDD training data file name\n",
    "TEST_FILE = 'KDDTest+.txt'              # Original KDD testing data file name\n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_large/' \n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata.json')\n",
    "\n",
    "MODEL_SAVE_DIR = './saved_models_large/'\n",
    "BEST_MODEL_NAME = 'best_tgat_model.pth' \n",
    "\n",
    "DEFAULT_DEVICE_ID = 0 \n",
    "DEVICE = torch.device(f'cuda:{DEFAULT_DEVICE_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- TGAT Model Hyperparameters ---\n",
    "EPOCHS = 1 \n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.0005\n",
    "HIDDEN_DIM = 256 \n",
    "TIME_DIM = 64   \n",
    "N_HEADS = 4      \n",
    "N_LAYERS = 2     \n",
    "DROPOUT = 0.3   \n",
    "NUM_NEIGHBORS = [10, 5] \n",
    "CLIP_GRAD_NORM = 1.0 \n",
    "WEIGHT_DECAY = 1e-5 \n",
    "USE_FOCAL_LOSS = True \n",
    "CLASSIFICATION_MODE = 'binary'\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "# --- Parameters for Smarter Sampling in TemporalNeighborLoader ---\n",
    "RECENCY_BIAS_FACTOR = 0.9                 \n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'   # Column from raw data for similarity\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3           \n",
    "\n",
    "# --- Parameters for Sequence Modeling ---\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE \n",
    "SEQUENCE_LENGTH = 10            \n",
    "STEP_SIZE = 5                   \n",
    "SEQ_LABEL_MODE = 'any_attack'   \n",
    "BATCH_SIZE_SEQ_MODEL = 64       \n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4  \n",
    "EPOCHS_SEQ_MODEL = 20         \n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM \n",
    "SEQ_MODEL_HIDDEN_DIM = 128      \n",
    "SEQ_MODEL_NUM_LAYERS = 1      \n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'      \n",
    "SEQ_MODEL_DROPOUT = 0.2     \n",
    "\n",
    "# --- KDD Dataset Specific Column Names ---\n",
    "# ** CRITICAL: This MUST match the column order in your RAW KDD .txt files **\n",
    "# ** AND the COL_NAMES used in preprocess_kdd_large.ipynb **\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score' \n",
    "]\n",
    "ATTACK_MAP_MULTI_CLASS = { \n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos', \n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe', \n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l', \n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r' \n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "def get_device(): \n",
    "    return DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038487d2-dd90-435a-8a7f-c40d56a9158e",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19be5024-d6af-4536-8e83-b6b141e46d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell：Utility Functions & Custom Loss\n",
    "\n",
    "def get_device():\n",
    "    return DEVICE\n",
    "\n",
    "def plot_confusion_matrix_custom(y_true, y_pred, class_names, title='Confusion Matrix'):\n",
    "    if not y_true or not y_pred or len(y_true) != len(y_pred) or len(y_true) == 0:\n",
    "        print(f\"Cannot plot confusion matrix for {title}: y_true or y_pred is empty or mismatched.\")\n",
    "        return\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title); plt.xlabel('Predicted Label'); plt.ylabel('True Label'); plt.show()\n",
    "\n",
    "def print_metrics(epoch_str, loss, accuracy, precision, recall, f1, auc=None, phase='Train', class_report=None):\n",
    "    loss_str = f\"{loss:.4f}\" if loss is not None and not np.isnan(loss) else \"N/A\"\n",
    "    acc_str = f\"{accuracy:.4f}\" if accuracy is not None and not np.isnan(accuracy) else \"N/A\"\n",
    "    prec_str = f\"{precision:.4f}\" if precision is not None and not np.isnan(precision) else \"N/A\"\n",
    "    rec_str = f\"{recall:.4f}\" if recall is not None and not np.isnan(recall) else \"N/A\"\n",
    "    f1_str = f\"{f1:.4f}\" if f1 is not None and not np.isnan(f1) else \"N/A\"\n",
    "    \n",
    "    print(f\"{epoch_str} | {phase} Loss: {loss_str} | Acc: {acc_str} | Prec: {prec_str} | Rec: {rec_str} | F1: {f1_str}\", end=\"\")\n",
    "    if auc is not None and not np.isnan(auc):\n",
    "        print(f\" | AUC: {auc:.4f}\", end=\"\")\n",
    "    print() # Newline\n",
    "    if class_report:\n",
    "        if isinstance(class_report, str): # If it's already a formatted string\n",
    "            print(class_report)\n",
    "        elif isinstance(class_report, dict): # If it's a dict from classification_report\n",
    "            print(\"Classification Report (Dict):\\n\", json.dumps(class_report, indent=2))\n",
    "\n",
    "class FocalLoss(nn.Module): # Keep for future use\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', pos_weight_for_bce=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight_for_bce = pos_weight_for_bce\n",
    "\n",
    "    def forward(self, inputs, targets): \n",
    "        if self.pos_weight_for_bce is not None:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none', pos_weight=self.pos_weight_for_bce)\n",
    "        else:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none')\n",
    "        \n",
    "        pt = torch.exp(-bce_loss) \n",
    "        \n",
    "        alpha_t = self.alpha\n",
    "        if self.alpha is not None: \n",
    "            if isinstance(self.alpha, (float, int)): \n",
    "                alpha_tensor = torch.tensor([self.alpha], device=inputs.device, dtype=inputs.dtype)\n",
    "                alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            elif isinstance(self.alpha, torch.Tensor) and self.alpha.ndim == 0: \n",
    "                 alpha_tensor = self.alpha.to(inputs.device, dtype=inputs.dtype)\n",
    "                 alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            if alpha_t.ndim == 1 and targets.ndim > 1 and alpha_t.shape[0] == targets.shape[0] and targets.shape[1] == 1: # Ensure broadcasting for [B,1] targets\n",
    "                alpha_t = alpha_t.unsqueeze(1)\n",
    "            \n",
    "        if alpha_t is None: \n",
    "            focal_loss_unreduced = (1 - pt)**self.gamma * bce_loss\n",
    "        else:\n",
    "            focal_loss_unreduced = alpha_t * (1 - pt)**self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss_unreduced)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss_unreduced)\n",
    "        else: \n",
    "            return focal_loss_unreduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f4492-75ff-4946-adf0-e9db1cbcc6ad",
   "metadata": {},
   "source": [
    "## 4. Model Definition (TGAT & TemporalGraphAttentionLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be45cea8-e5db-468c-8489-7ddb6581e434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Model Definition (TGAT class forward method MODIFIED for sliced data)\n",
    "class FunctionalTimeEncoder(nn.Module):\n",
    "    def __init__(self, D_in_emb, D_time_emb, D_out_emb):\n",
    "        super(FunctionalTimeEncoder, self).__init__()\n",
    "        self.time_emb_layer = nn.Linear(1, D_time_emb)\n",
    "        self.output_layer = nn.Linear(D_in_emb + D_time_emb, D_out_emb)\n",
    "\n",
    "    def forward(self, x_feat, delta_t):\n",
    "        if delta_t.ndim == 1: delta_t = delta_t.unsqueeze(-1)\n",
    "        time_embedding_input = torch.tanh(self.time_emb_layer(delta_t.float())) \n",
    "        time_emb = torch.cos(time_embedding_input) \n",
    "        output_concat = torch.cat([x_feat, time_emb], dim=-1)\n",
    "        return self.output_layer(output_concat)\n",
    "\n",
    "class TemporalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, n_feat_dim_input, n_time_emb_dim, n_out_dim_layer, n_head=2, dropout=0.1):\n",
    "        super(TemporalGraphAttentionLayer, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.n_out_dim_head = n_out_dim_layer // n_head\n",
    "        if self.n_out_dim_head == 0: \n",
    "            raise ValueError(f\"Output dimension per head is 0. n_out_dim_layer ({n_out_dim_layer}) must be >= n_head ({n_head}).\")\n",
    "        self.time_encoder = FunctionalTimeEncoder(n_feat_dim_input, n_time_emb_dim, n_feat_dim_input) \n",
    "        self.W_q = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head) \n",
    "        self.W_k = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_v = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_out = nn.Linear(self.n_out_dim_head * n_head, n_out_dim_layer)\n",
    "        self.dropout_m = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(n_out_dim_layer)\n",
    "\n",
    "    def forward(self, target_node_feat_input, target_node_ts, neighbor_feats_input_list, neighbor_ts_list, neighbor_masks):\n",
    "        B, N_max_neighbors, D_feat_input = neighbor_feats_input_list.shape\n",
    "        if target_node_feat_input.shape[-1] != D_feat_input:\n",
    "            raise ValueError(f\"Mismatched feature dimensions for target ({target_node_feat_input.shape[-1]}) and_neighbors ({D_feat_input}) in TemporalGraphAttentionLayer\")\n",
    "\n",
    "        Q = self.W_q(target_node_feat_input).view(B, self.n_head, self.n_out_dim_head)\n",
    "        neighbor_feats_flat = neighbor_feats_input_list.reshape(-1, D_feat_input)\n",
    "        neighbor_ts_flat = neighbor_ts_list.reshape(-1)\n",
    "        target_node_ts_expanded = target_node_ts.unsqueeze(1).expand(-1, N_max_neighbors).reshape(-1)\n",
    "        delta_t_neighbors = target_node_ts_expanded - neighbor_ts_flat\n",
    "        \n",
    "        time_aware_neighbor_feats_flat = self.time_encoder(neighbor_feats_flat, delta_t_neighbors)\n",
    "        K = self.W_k(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        V = self.W_v(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        K_t = K.permute(0, 2, 3, 1) \n",
    "        \n",
    "        attn_scores = torch.matmul(Q.unsqueeze(2), K_t) / np.sqrt(self.n_out_dim_head + 1e-9) \n",
    "        attn_scores = attn_scores.squeeze(2) \n",
    "        attn_scores = torch.clamp(attn_scores, min=-10.0, max=10.0) \n",
    "        attn_scores = attn_scores.masked_fill(~neighbor_masks.unsqueeze(1), float('-inf'))\n",
    "        all_masked = torch.all(attn_scores == float('-inf'), dim=-1, keepdim=True)\n",
    "        attn_scores_safe = torch.where(all_masked, torch.zeros_like(attn_scores), attn_scores)\n",
    "        attn_probs = torch.softmax(attn_scores_safe, dim=-1) \n",
    "        attn_probs = torch.where(all_masked, torch.zeros_like(attn_probs), attn_probs)\n",
    "        attn_probs = self.dropout_m(attn_probs) \n",
    "        output = torch.matmul(attn_probs.unsqueeze(2), V.permute(0, 2, 1, 3)) \n",
    "        output = output.squeeze(2).reshape(B, self.n_head * self.n_out_dim_head)\n",
    "        output = self.W_out(output)\n",
    "        output = self.dropout_m(output)\n",
    "        output = self.layer_norm(output)\n",
    "        return output\n",
    "\n",
    "class TGAT(nn.Module):\n",
    "    def __init__(self, node_feat_dim, time_emb_dim, n_head, n_layers, hidden_dim_per_layer, num_classes, dropout=0.1):\n",
    "        super(TGAT, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.node_feat_dim = node_feat_dim \n",
    "        self.attn_layers = nn.ModuleList()\n",
    "        self.neighbor_feat_projectors = nn.ModuleList()\n",
    "\n",
    "        current_dim_of_h = node_feat_dim\n",
    "        for i in range(n_layers):\n",
    "            self.attn_layers.append(\n",
    "                TemporalGraphAttentionLayer(\n",
    "                    n_feat_dim_input=current_dim_of_h, \n",
    "                    n_time_emb_dim=time_emb_dim,      \n",
    "                    n_out_dim_layer=hidden_dim_per_layer, \n",
    "                    n_head=n_head, \n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "            if i > 0: \n",
    "                self.neighbor_feat_projectors.append(\n",
    "                    nn.Linear(self.node_feat_dim, current_dim_of_h) # Project from original dim\n",
    "                )\n",
    "            else: \n",
    "                self.neighbor_feat_projectors.append(None) \n",
    "            current_dim_of_h = hidden_dim_per_layer\n",
    "\n",
    "        mlp_input_dim = current_dim_of_h\n",
    "        mlp_hidden_dim = mlp_input_dim // 2 if mlp_input_dim // 2 > 0 else 1\n",
    "        if mlp_hidden_dim == 0 : mlp_hidden_dim = 1\n",
    "\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_input_dim, mlp_hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, num_classes)\n",
    "        )\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "    # MODIFIED: forward now takes batch_node_features and batch_node_timestamps (sliced data)\n",
    "    # target_node_indices and neighbor_node_indices are now batch-local\n",
    "    def forward(self, target_node_indices_local, \n",
    "                batch_node_features, batch_node_timestamps, \n",
    "                neighbor_info_batches_all_layers_local, return_embedding=False):\n",
    "        \n",
    "        h = batch_node_features[target_node_indices_local] \n",
    "        target_ts_for_attn = batch_node_timestamps[target_node_indices_local]\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            layer_input_h_target = h \n",
    "            if i >= len(neighbor_info_batches_all_layers_local):\n",
    "                print(f\"Warning: Not enough neighbor_info_batches for layer {i}.\")\n",
    "                break \n",
    "            \n",
    "            # These are batch-local indices now\n",
    "            neighbor_node_indices_padded_local, neighbor_ts_padded, neighbor_masks = neighbor_info_batches_all_layers_local[i]\n",
    "            \n",
    "            # Fetch neighbor features using batch-local indices from batch_node_features\n",
    "            # Important: The dimension of batch_node_features is self.node_feat_dim (original)\n",
    "            original_neighbor_features = batch_node_features[neighbor_node_indices_padded_local.reshape(-1)].reshape(\n",
    "                neighbor_node_indices_padded_local.shape[0], \n",
    "                neighbor_node_indices_padded_local.shape[1], \n",
    "                self.node_feat_dim # Neighbors are always fetched with original feature dim\n",
    "            )\n",
    "            \n",
    "            projector = self.neighbor_feat_projectors[i]\n",
    "            if projector is not None:\n",
    "                # Project original neighbor features to match current_dim_of_h (which is layer_input_h_target.shape[-1])\n",
    "                B_Nmax_shape = original_neighbor_features.shape[:2]\n",
    "                flat_original_neighbor_features = original_neighbor_features.reshape(-1, self.node_feat_dim)\n",
    "                projected_flat_neighbor_features = projector(flat_original_neighbor_features)\n",
    "                input_neighbor_features_for_attn = projected_flat_neighbor_features.reshape(*B_Nmax_shape, -1)\n",
    "            else: \n",
    "                # First layer: layer_input_h_target is original_node_feat_dim, so original_neighbor_features match\n",
    "                input_neighbor_features_for_attn = original_neighbor_features\n",
    "            \n",
    "            input_neighbor_features_for_attn[~neighbor_masks] = 0 \n",
    "\n",
    "            h = self.attn_layers[i](\n",
    "                layer_input_h_target, \n",
    "                target_ts_for_attn, # These are absolute timestamps, but fetched for batch nodes\n",
    "                input_neighbor_features_for_attn, \n",
    "                neighbor_ts_padded, # These are absolute timestamps for neighbors\n",
    "                neighbor_masks\n",
    "            )\n",
    "            h = self.activation(h) \n",
    "        \n",
    "        output_logits = self.output_mlp(h)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return output_logits, h \n",
    "        else:\n",
    "            return output_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15103a6-15ef-437a-ba84-705d2d960555",
   "metadata": {},
   "source": [
    "## 5. Custom TemporalNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e8936df-f7a4-4c4d-92a8-742d3b72819c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: TemporalNeighborLoader Class (MODIFIED for Smarter Neighbor Sampling)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm # Ensure tqdm is imported if used within the class\n",
    "\n",
    "class TemporalNeighborLoader:\n",
    "    def __init__(self, temporal_data_cpu, batch_size, num_neighbors_per_layer_list, device,\n",
    "                 shuffle=True, \n",
    "                 recency_bias_factor=0.8, \n",
    "                 feature_similarity_col_name='service', \n",
    "                 feature_similarity_weight=0.5, \n",
    "                 raw_data_file_path_for_ids=None, # Default is None\n",
    "                 col_names_list=None # Parameter to pass COL_NAMES for reading raw file\n",
    "                ):\n",
    "        self.temporal_data_cpu = temporal_data_cpu\n",
    "        self.x_cpu = temporal_data_cpu.x\n",
    "        self.ts_cpu = temporal_data_cpu.ts\n",
    "        self.y_cpu = temporal_data_cpu.y\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_neighbors_per_layer_list = num_neighbors_per_layer_list\n",
    "        self.shuffle = shuffle\n",
    "        self.device = device\n",
    "        self.N = temporal_data_cpu.num_nodes if temporal_data_cpu.num_nodes is not None else 0\n",
    "        self.node_indices_global = torch.arange(self.N) if self.N > 0 else torch.empty(0, dtype=torch.long)\n",
    "\n",
    "        self.adj = [[] for _ in range(self.N)]\n",
    "        if self.N > 0 and hasattr(temporal_data_cpu, 'edge_index') and temporal_data_cpu.edge_index is not None:\n",
    "            edge_index_cpu = temporal_data_cpu.edge_index.cpu() \n",
    "            src, dst = edge_index_cpu\n",
    "            \n",
    "            for i in range(len(src)):\n",
    "                s, d = src[i].item(), dst[i].item()\n",
    "                if s < self.N and d < self.N and self.ts_cpu[s] < self.ts_cpu[d]: # Bounds check\n",
    "                    self.adj[d].append(s)\n",
    "            \n",
    "            for i in range(self.N):\n",
    "                self.adj[i].sort(key=lambda pred_idx: self.ts_cpu[pred_idx], reverse=True)\n",
    "\n",
    "        self.recency_bias_factor = recency_bias_factor\n",
    "        self.feature_similarity_col_name = feature_similarity_col_name\n",
    "        self.feature_similarity_weight = feature_similarity_weight\n",
    "        self.raw_data_file_path_for_ids = raw_data_file_path_for_ids \n",
    "        self.original_feature_for_similarity_cpu = None\n",
    "        self._col_names_for_raw_read = col_names_list \n",
    "\n",
    "        if self.feature_similarity_col_name and self.raw_data_file_path_for_ids:\n",
    "            if not os.path.exists(self.raw_data_file_path_for_ids):\n",
    "                print(f\"Warning: 'raw_data_file_path_for_ids' ('{self.raw_data_file_path_for_ids}') provided but file does not exist. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self._col_names_for_raw_read is None or not isinstance(self._col_names_for_raw_read, list) or len(self._col_names_for_raw_read) == 0:\n",
    "                print(f\"Warning: 'col_names_list' not provided or invalid to TemporalNeighborLoader. Disabling feature similarity sampling for '{self.feature_similarity_col_name}'.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self.feature_similarity_col_name not in self._col_names_for_raw_read:\n",
    "                print(f\"Warning: feature_similarity_col_name '{self.feature_similarity_col_name}' not found in provided col_names_list. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            else:\n",
    "                try:\n",
    "                    print(f\"Loading '{self.feature_similarity_col_name}' from {self.raw_data_file_path_for_ids} for similarity sampling...\")\n",
    "                    df_ids = pd.read_csv(self.raw_data_file_path_for_ids, header=None, names=self._col_names_for_raw_read, usecols=[self.feature_similarity_col_name], low_memory=False)\n",
    "                    self.original_feature_for_similarity_cpu = df_ids[self.feature_similarity_col_name].values\n",
    "                    print(f\"Successfully loaded '{self.feature_similarity_col_name}' for {len(self.original_feature_for_similarity_cpu)} nodes.\")\n",
    "                    if self.N > 0 and len(self.original_feature_for_similarity_cpu) != self.N:\n",
    "                        print(f\"Warning: Length mismatch for similarity feature. Expected {self.N}, got {len(self.original_feature_for_similarity_cpu)}. Disabling feature similarity.\")\n",
    "                        self.original_feature_for_similarity_cpu = None\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not load feature '{self.feature_similarity_col_name}' for similarity sampling from '{self.raw_data_file_path_for_ids}': {e}. Disabling.\")\n",
    "                    self.original_feature_for_similarity_cpu = None\n",
    "        elif self.feature_similarity_col_name: \n",
    "             print(f\"Warning: 'feature_similarity_col_name' ('{self.feature_similarity_col_name}') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\")\n",
    "             self.original_feature_for_similarity_cpu = None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.N == 0 : \n",
    "            self.node_indices_permuted_global = torch.empty(0, dtype=torch.long)\n",
    "        elif self.shuffle:\n",
    "            self.node_indices_permuted_global = self.node_indices_global[torch.randperm(self.N)]\n",
    "        else:\n",
    "            self.node_indices_permuted_global = self.node_indices_global\n",
    "        self.current_idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_idx >= self.N or self.N == 0: \n",
    "            raise StopIteration\n",
    "        \n",
    "        end_idx = min(self.current_idx + self.batch_size, self.N)\n",
    "        target_node_indices_batch_global_cpu = self.node_indices_permuted_global[self.current_idx:end_idx]\n",
    "        self.current_idx = end_idx\n",
    "        \n",
    "        unique_global_indices_for_batch_set = set(target_node_indices_batch_global_cpu.tolist())\n",
    "        neighbor_info_for_model_layers_global_cpu = []\n",
    "        \n",
    "        for k_neighbors_this_layer in self.num_neighbors_per_layer_list:\n",
    "            batch_neigh_idx_padded_global_cpu, batch_neigh_ts_padded_cpu, batch_neigh_masks_cpu = [], [], []\n",
    "            for node_idx_val_global in target_node_indices_batch_global_cpu.tolist():\n",
    "                if node_idx_val_global >= self.N: \n",
    "                    preds_global = []\n",
    "                else:\n",
    "                    preds_global = self.adj[node_idx_val_global]\n",
    "                actual_k_candidates = len(preds_global)\n",
    "                \n",
    "                sampled_pred_indices_global_np = np.array([], dtype=np.int64)\n",
    "                if actual_k_candidates > 0:\n",
    "                    weights = np.ones(actual_k_candidates, dtype=float) \n",
    "                    \n",
    "                    if self.recency_bias_factor > 0 and self.recency_bias_factor < 1 and actual_k_candidates > 1:\n",
    "                        recency_weights = np.array([self.recency_bias_factor**i for i in range(actual_k_candidates)], dtype=float)\n",
    "                        weights *= recency_weights\n",
    "                    \n",
    "                    if self.original_feature_for_similarity_cpu is not None and \\\n",
    "                       self.feature_similarity_weight > 0 and \\\n",
    "                       node_idx_val_global < len(self.original_feature_for_similarity_cpu): \n",
    "                        \n",
    "                        target_feature_value = self.original_feature_for_similarity_cpu[node_idx_val_global]\n",
    "                        valid_preds_for_sim_indices = [p for p in preds_global if p < len(self.original_feature_for_similarity_cpu)]\n",
    "                        \n",
    "                        if valid_preds_for_sim_indices:\n",
    "                            pred_to_valid_idx_map = {pred_val: i for i, pred_val in enumerate(valid_preds_for_sim_indices)}\n",
    "                            neighbor_feature_values = self.original_feature_for_similarity_cpu[valid_preds_for_sim_indices]\n",
    "                            similarity_scores_for_valid_preds = np.array([1.0 if nf == target_feature_value else (1.0 - self.feature_similarity_weight) for nf in neighbor_feature_values], dtype=float)\n",
    "                            \n",
    "                            for i, pred_original_idx in enumerate(preds_global):\n",
    "                                if pred_original_idx in pred_to_valid_idx_map:\n",
    "                                    weights[i] *= similarity_scores_for_valid_preds[pred_to_valid_idx_map[pred_original_idx]]\n",
    "\n",
    "                    sum_weights = np.sum(weights)\n",
    "                    p_dist = None\n",
    "                    if sum_weights > 1e-9: \n",
    "                        p_dist = weights / sum_weights\n",
    "                    elif actual_k_candidates > 0 : \n",
    "                        pass # p=None in np.random.choice means uniform\n",
    "\n",
    "                    actual_k_to_sample = min(actual_k_candidates, k_neighbors_this_layer)\n",
    "                    \n",
    "                    try:\n",
    "                        if actual_k_candidates > 0:\n",
    "                            sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False, p=p_dist\n",
    "                            )\n",
    "                    except ValueError as e_choice: \n",
    "                        if actual_k_candidates > 0: # Ensure preds_global is not empty before trying uniform sampling\n",
    "                             # print(f\"Warning: np.random.choice ValueError ({e_choice}). Sum_w: {np.sum(p_dist) if p_dist is not None else 'None (uniform)'}. N_cand: {actual_k_candidates}, k_sample: {actual_k_to_sample}. Uniform sampling for node {node_idx_val_global}.\")\n",
    "                             sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False\n",
    "                            )\n",
    "                actual_k = len(sampled_pred_indices_global_np)\n",
    "                sampled_pred_indices_global_torch = torch.from_numpy(sampled_pred_indices_global_np).long()\n",
    "                \n",
    "                sampled_pred_ts_cpu = torch.empty(0, dtype=torch.long)\n",
    "                if actual_k > 0:\n",
    "                    # Ensure sampled indices are valid before fetching from ts_cpu\n",
    "                    valid_ts_indices = sampled_pred_indices_global_torch[(sampled_pred_indices_global_torch >= 0) & (sampled_pred_indices_global_torch < self.N)]\n",
    "                    if len(valid_ts_indices) > 0: \n",
    "                        sampled_pred_ts_cpu = self.ts_cpu[valid_ts_indices]\n",
    "                    \n",
    "                    # Pad if some indices became invalid (should be rare if preds_global are valid)\n",
    "                    if len(valid_ts_indices) != actual_k:\n",
    "                         # print(f\"Warning: Timestamp fetch mismatch for node {node_idx_val_global}. Expected {actual_k}, got {len(valid_ts_indices)}. Padded with zeros.\")\n",
    "                         sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.zeros(actual_k - len(valid_ts_indices), dtype=torch.long)])\n",
    "\n",
    "                unique_global_indices_for_batch_set.update(sampled_pred_indices_global_torch.tolist())\n",
    "                \n",
    "                padding_needed = k_neighbors_this_layer - actual_k\n",
    "                mask_cpu = torch.ones(actual_k, dtype=torch.bool)\n",
    "                \n",
    "                if padding_needed > 0:\n",
    "                    pad_idx_val = 0 \n",
    "                    if self.N > 0 and pad_idx_val not in unique_global_indices_for_batch_set: \n",
    "                         unique_global_indices_for_batch_set.add(pad_idx_val)\n",
    "                    \n",
    "                    sampled_pred_indices_global_torch = torch.cat([sampled_pred_indices_global_torch, torch.full((padding_needed,), pad_idx_val, dtype=torch.long)])\n",
    "                    pad_ts_val = self.ts_cpu[pad_idx_val].item() if self.N > 0 and pad_idx_val < self.N else 0\n",
    "                    sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.full((padding_needed,), pad_ts_val, dtype=torch.long)])\n",
    "                    mask_cpu = torch.cat([mask_cpu, torch.zeros(padding_needed, dtype=torch.bool)])\n",
    "                \n",
    "                batch_neigh_idx_padded_global_cpu.append(sampled_pred_indices_global_torch)\n",
    "                batch_neigh_ts_padded_cpu.append(sampled_pred_ts_cpu)\n",
    "                batch_neigh_masks_cpu.append(mask_cpu)\n",
    "            \n",
    "            if not batch_neigh_idx_padded_global_cpu: # If target_node_indices_batch_global_cpu was empty or led to no neighbors\n",
    "                 dummy_shape_neighbors = (0, k_neighbors_this_layer)\n",
    "                 neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.bool)))\n",
    "            else:\n",
    "                neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.stack(batch_neigh_idx_padded_global_cpu),\n",
    "                    torch.stack(batch_neigh_ts_padded_cpu),\n",
    "                    torch.stack(batch_neigh_masks_cpu)))\n",
    "\n",
    "        unique_global_indices_list_cpu = sorted(list(unique_global_indices_for_batch_set))\n",
    "        if not unique_global_indices_list_cpu : # If, after all processing, the set is empty\n",
    "            if self.N > 0 : # If dataset has nodes, but this batch yielded no unique indices (e.g. only padded 0s and 0 was already there)\n",
    "                unique_global_indices_list_cpu = [0] # Add 0 to fetch its features at least\n",
    "                # print(\"Warning: unique_global_indices_list_cpu was empty after processing neighbors, defaulting to [0].\")\n",
    "            else: # Dataset itself is empty\n",
    "                 # print(\"Error: Dataset has no nodes (self.N=0). Returning empty batch from loader.\")\n",
    "                 x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "                 y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                 return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                         torch.empty(0, x_dim).to(self.device), \n",
    "                         torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                         torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "\n",
    "        global_to_batch_local_idx_map = {global_idx: local_idx for local_idx, global_idx in enumerate(unique_global_indices_list_cpu)}\n",
    "        \n",
    "        valid_fetch_indices_tensor = torch.tensor(unique_global_indices_list_cpu, dtype=torch.long)\n",
    "        # Filter out-of-bounds indices, though ideally, unique_global_indices_list_cpu should only contain valid global indices < self.N\n",
    "        # (or index 0 if used for padding and N > 0)\n",
    "        valid_fetch_indices_tensor = valid_fetch_indices_tensor[valid_fetch_indices_tensor < self.N] \n",
    "        \n",
    "        if valid_fetch_indices_tensor.numel() == 0 : # If no valid indices after filtering (e.g., unique_global_indices_list_cpu was empty or only contained invalid indices)\n",
    "             if self.N > 0: # If dataset has nodes, but no valid indices were collected\n",
    "                # print(\"Warning: No valid indices to fetch features/timestamps after filtering. Using node 0 if N > 0.\")\n",
    "                valid_fetch_indices_tensor = torch.tensor([0], dtype=torch.long) # Default to fetching node 0\n",
    "                if 0 not in global_to_batch_local_idx_map: # Ensure mapping exists for node 0 if we defaulted to it\n",
    "                    global_to_batch_local_idx_map[0] = len(global_to_batch_local_idx_map) \n",
    "            \n",
    "        if valid_fetch_indices_tensor.numel() == 0: # Still no valid indices (e.g. self.N=0 or above fallback failed)\n",
    "             x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                     torch.empty(0, x_dim).to(self.device), \n",
    "                     torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                     torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "        batch_node_features_dev = self.x_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "        batch_node_timestamps_dev = self.ts_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "\n",
    "        target_node_indices_batch_local_dev_list = []\n",
    "        for global_idx_tensor in target_node_indices_batch_global_cpu:\n",
    "            global_idx = global_idx_tensor.item()\n",
    "            local_idx = global_to_batch_local_idx_map.get(global_idx)\n",
    "            if local_idx is None: # Should not happen if unique_global_indices_for_batch_set was built from targets\n",
    "                # print(f\"Critical Warning: Target node global index {global_idx} not in local map! Using local index of global 0 as fallback.\")\n",
    "                local_idx = global_to_batch_local_idx_map.get(0,0) # Default to local index of global 0 if something went wrong\n",
    "            target_node_indices_batch_local_dev_list.append(local_idx)\n",
    "        \n",
    "        target_node_indices_batch_local_dev = torch.tensor(\n",
    "            target_node_indices_batch_local_dev_list, dtype=torch.long\n",
    "        ).to(self.device)\n",
    "\n",
    "        neighbor_info_for_model_layers_local_dev = []\n",
    "        for global_indices_layer, global_ts_layer, masks_layer in neighbor_info_for_model_layers_global_cpu:\n",
    "            if global_indices_layer.numel() > 0: \n",
    "                remapped_indices_list = []\n",
    "                for row_idx in range(global_indices_layer.shape[0]):\n",
    "                    row = global_indices_layer[row_idx]\n",
    "                    remapped_row = [global_to_batch_local_idx_map.get(x.item(), global_to_batch_local_idx_map.get(0,0)) for x in row]\n",
    "                    remapped_indices_list.append(remapped_row)\n",
    "                \n",
    "                if not remapped_indices_list: \n",
    "                     batch_local_indices_layer = torch.empty_like(global_indices_layer) \n",
    "                else:\n",
    "                     batch_local_indices_layer = torch.tensor(remapped_indices_list, dtype=torch.long)\n",
    "\n",
    "                neighbor_info_for_model_layers_local_dev.append((\n",
    "                    batch_local_indices_layer.to(self.device),\n",
    "                    global_ts_layer.to(self.device),\n",
    "                    masks_layer.to(self.device)\n",
    "                ))\n",
    "            else: \n",
    "                 k_this_layer = global_indices_layer.shape[1] if global_indices_layer.ndim ==2 and global_indices_layer.shape[1] > 0 else (self.num_neighbors_per_layer_list[0] if self.num_neighbors_per_layer_list and len(self.num_neighbors_per_layer_list)>0 else 0)\n",
    "                 dummy_shape_layer_neighbors = (len(target_node_indices_batch_global_cpu), k_this_layer) # Ensure batch dim matches target nodes\n",
    "                 if len(target_node_indices_batch_global_cpu) == 0: dummy_shape_layer_neighbors = (0, k_this_layer)\n",
    "\n",
    "                 neighbor_info_for_model_layers_local_dev.append((\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.bool).to(self.device)\n",
    "                 ))\n",
    "        \n",
    "        if target_node_indices_batch_global_cpu.numel() > 0:\n",
    "             # Ensure indices are valid for y_cpu before fetching\n",
    "             valid_y_indices = target_node_indices_batch_global_cpu[target_node_indices_batch_global_cpu < self.N]\n",
    "             if valid_y_indices.numel() > 0:\n",
    "                 batch_labels_dev = self.y_cpu[valid_y_indices].to(self.device)\n",
    "                 if len(batch_labels_dev) != len(target_node_indices_batch_local_dev): # If filtering changed size\n",
    "                     print(f\"Warning: Label batch size mismatch after filtering valid y_indices. This might cause issues.\")\n",
    "                     # Fallback: create dummy labels matching target_node_indices_batch_local_dev size\n",
    "                     y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                     batch_labels_dev = torch.empty(len(target_node_indices_batch_local_dev), *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "             else: # No valid indices left for y_cpu\n",
    "                y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        else: # target_node_indices_batch_global_cpu was empty\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        return (target_node_indices_batch_local_dev,\n",
    "                batch_node_features_dev,\n",
    "                batch_node_timestamps_dev,\n",
    "                neighbor_info_for_model_layers_local_dev,\n",
    "                batch_labels_dev)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.N == 0: return 0\n",
    "        return (self.N + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292f589-fce4-4496-a455-a3620769bf62",
   "metadata": {},
   "source": [
    "## 6. Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbbae281-216c-46ee-a595-681fbe6d6065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: load_processed_data function\n",
    "def load_processed_data(data_file_path: str, metadata_file_path: str, classification_mode: str = 'binary'):\n",
    "    print(f\"Loading data from: {data_file_path}\")\n",
    "    data_dict = torch.load(data_file_path, map_location='cpu') \n",
    "    \n",
    "    print(f\"Loading metadata from: {metadata_file_path}\")\n",
    "    with open(metadata_file_path, 'r') as f: metadata = json.load(f)\n",
    "\n",
    "    y_labels = data_dict['y_binary'] if classification_mode == 'binary' else data_dict['y_multiclass'].squeeze() # Ensure y_multiclass is 1D\n",
    "    num_classes = metadata['NUM_CLASSES_BINARY'] if classification_mode == 'binary' else metadata['NUM_CLASSES_MULTI']\n",
    "    \n",
    "    pos_weight_tensor = None\n",
    "    if classification_mode == 'binary':\n",
    "        pos_weight_val = metadata.get('POS_WEIGHT_BINARY', 1.0)\n",
    "        pos_weight_tensor = torch.tensor([pos_weight_val], dtype=torch.float32) \n",
    "\n",
    "    temporal_data_obj = TemporalData(x=data_dict['x'], edge_index=data_dict['edge_index'], \n",
    "                                     ts=data_dict['ts'], y=y_labels)\n",
    "    \n",
    "    print(f\"Data loaded: Nodes={temporal_data_obj.num_nodes}, Edges={temporal_data_obj.num_edges}\")\n",
    "    print(f\"Metadata: NodeFeatDim={metadata['NODE_FEAT_DIM']}, NumClasses({classification_mode})={num_classes}, PosWeight={pos_weight_tensor.item() if pos_weight_tensor is not None and classification_mode == 'binary' else 'N/A_or_Multiclass'}\")\n",
    "    return temporal_data_obj, metadata, num_classes, pos_weight_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549ab9b-0cd9-4513-9fac-2498fb7b1299",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac9b2775-77b8-489a-8486-26dfcfc5d3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_epoch and evaluate_model functions (MODIFIED for new loader output)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, clip_grad_val=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list = [], []\n",
    "    valid_batches_for_loss = 0\n",
    "    pbar = tqdm(loader, desc=\"Train Epoch\")\n",
    "    # MODIFIED: Unpack new items from loader\n",
    "    for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                     neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                print(f\"Warning: Batch {batch_idx} has insufficient neighbor_info_batches for N_LAYERS. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # MODIFIED: Pass sliced data to model\n",
    "            output_logits = model(target_indices_local_dev, batch_features_dev, batch_ts_dev, neighbor_batches_local_dev)\n",
    "            \n",
    "            if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                print(f\"Batch {batch_idx}: NaNs/Infs in model output_logits! Skipping.\")\n",
    "                continue \n",
    "            \n",
    "            # batch_labels_dev are already on device and correspond to target_indices_local_dev\n",
    "            true_labels_dev = batch_labels_dev \n",
    "            if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "            elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "            \n",
    "            loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "            \n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Batch {batch_idx}: Loss is NaN or Inf! Skipping backward. Logits: {output_logits.flatten()[:3]}, Labels: {true_labels_dev.flatten()[:3]}\")\n",
    "                continue \n",
    "            \n",
    "            loss.backward()\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and (param.grad.isnan().any() or param.grad.isinf().any()):\n",
    "                    print(f\"Batch {batch_idx}: NaNs/Infs in gradients of {name}! Zeroing grad.\")\n",
    "                    param.grad = torch.zeros_like(param.grad) \n",
    "            if clip_grad_val:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_val)\n",
    "            optimizer.step()\n",
    "            \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.isnan().any() or param.isinf().any():\n",
    "                    print(f\"CRITICAL: Batch {batch_idx}: NaNs/Infs in param {name} AFTER step!\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            valid_batches_for_loss += 1\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = (torch.sigmoid(output_logits.detach()) > 0.5).cpu().numpy() if CLASSIFICATION_MODE == 'binary' else torch.argmax(output_logits.detach(), dim=1).cpu().numpy()\n",
    "            all_preds_list.extend(preds.flatten().tolist())\n",
    "            all_true_list.extend(true_labels_dev.cpu().numpy().flatten().tolist()) # Use true_labels_dev which is already processed\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        except RuntimeError as e:\n",
    "            if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                print(f\"RuntimeError involving NaN/Inf in train batch {batch_idx}: {e}. Skipping.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Unexpected RuntimeError in train batch {batch_idx}: {e}\")\n",
    "                raise e\n",
    "                \n",
    "    if valid_batches_for_loss == 0: return float('nan'),0,0,0,0,None\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list): return avg_loss,0,0,0,0,None\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_val = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, pos_label=pos_label_val, zero_division=0)\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, zero_division=0)\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(np.unique(all_true_list)) >= 2:\n",
    "        # For AUC with 0/1 preds, it's equivalent to accuracy if preds are hard labels.\n",
    "        # If output_logits were probabilities, this would be more meaningful.\n",
    "        # The current `all_preds_list` are hard 0/1 predictions.\n",
    "        try:\n",
    "            auc = roc_auc_score(all_true_list, all_preds_list) \n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute train AUC (0/1 preds): {e}. True unique: {np.unique(all_true_list)}\")\n",
    "            \n",
    "    return avg_loss, accuracy, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, phase='Validation', return_embeddings_and_ids=False, entity_id_col_name=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list, all_probs_binary_list = [], [], []\n",
    "    \n",
    "    all_node_embeddings_list = []\n",
    "    all_target_node_indices_global_list = [] # Store GLOBAL indices if needed for post-hoc\n",
    "    all_entity_ids_list = []\n",
    "\n",
    "    valid_batches_for_loss = 0\n",
    "    class_report_dict = None\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        # MODIFIED: Unpack new items from loader\n",
    "        for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                         neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "            try:\n",
    "                if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                    print(f\"Warning: Batch {batch_idx} in {phase} has insufficient neighbor_info_batches. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                if return_embeddings_and_ids:\n",
    "                    # MODIFIED: Pass sliced data to model\n",
    "                    output_logits, node_embeddings = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=True\n",
    "                    )\n",
    "                    all_node_embeddings_list.append(node_embeddings.cpu())\n",
    "                    # To get global indices for post-hoc, we need the loader to also provide the original global indices for the batch\n",
    "                    # The current modified loader does not explicitly return target_node_indices_batch_global_cpu in the tuple.\n",
    "                    # For now, if we need global indices, this part needs adjustment in loader output.\n",
    "                    # Assuming target_indices_local_dev can be mapped back if necessary, or loader provides mapping.\n",
    "                    # For simplicity, let's say we store local indices for now, or acknowledge this limitation for post-hoc.\n",
    "                    # If loader.current_idx and batch_size are used, we can reconstruct global indices if not shuffled.\n",
    "                    # Placeholder:\n",
    "                    # all_target_node_indices_global_list.append(target_indices_local_dev.cpu()) # This is NOT global yet\n",
    "                    \n",
    "                else:\n",
    "                    output_logits = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=False\n",
    "                    )\n",
    "\n",
    "                if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                    print(f\"Batch {batch_idx} in {phase}: NaNs or Infs in model output_logits! Skipping metrics for this batch.\")\n",
    "                    continue\n",
    "                \n",
    "                true_labels_dev = batch_labels_dev # Already on device\n",
    "                if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                    true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "                elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                    true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "                \n",
    "                loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "                if not (loss.isnan() or loss.isinf()):\n",
    "                    total_loss += loss.item()\n",
    "                    valid_batches_for_loss +=1\n",
    "                else:\n",
    "                    print(f\"Batch {batch_idx} in {phase}: Loss is NaN or Inf! Logits: {output_logits.flatten()[:5]}\")\n",
    "                \n",
    "                current_batch_true_labels = true_labels_dev.cpu().numpy().flatten().tolist()\n",
    "                current_batch_preds_np, current_batch_probs_np = np.array([]), np.array([])\n",
    "                \n",
    "                if CLASSIFICATION_MODE == 'binary':\n",
    "                    probs = torch.sigmoid(output_logits)\n",
    "                    if probs.isnan().any() or probs.isinf().any():\n",
    "                        print(f\"Batch {batch_idx} in {phase}: Sigmoid probs NaN/Inf.\")\n",
    "                        current_batch_preds_np = np.zeros(len(current_batch_true_labels), dtype=int) \n",
    "                        current_batch_probs_np = np.full(len(current_batch_true_labels), 0.5, dtype=float)\n",
    "                    else:\n",
    "                        current_batch_probs_np = probs.cpu().numpy().flatten()\n",
    "                        current_batch_preds_np = (probs > 0.5).cpu().numpy().flatten()\n",
    "                    all_probs_binary_list.extend(current_batch_probs_np.tolist())\n",
    "                else:\n",
    "                    current_batch_preds_np = torch.argmax(output_logits, dim=1).cpu().numpy().flatten()\n",
    "                \n",
    "                all_preds_list.extend(current_batch_preds_np.tolist())\n",
    "                all_true_list.extend(current_batch_true_labels) \n",
    "                pbar.set_postfix({'loss': loss.item() if not (loss.isnan() or loss.isinf()) else float('nan')})\n",
    "            except RuntimeError as e:\n",
    "                if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                    print(f\"RuntimeError involving NaN/Inf in {phase} batch {batch_idx}: {e}. Skipping.\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Unexpected RuntimeError in {phase} batch {batch_idx}: {e}\")\n",
    "                    raise e\n",
    "\n",
    "    if valid_batches_for_loss == 0: \n",
    "        empty_return = (float('nan'),0,0,0,0, None, [], [], None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list):\n",
    "        print(f\"Warning: Mismatch/empty metric lists in {phase}. True: {len(all_true_list)}, Pred: {len(all_preds_list)}\")\n",
    "        empty_return = (avg_loss,0,0,0,0,None,all_true_list,all_preds_list, None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode_overall = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_overall = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    \n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, pos_label=pos_label_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            target_names = ['Normal (0)', 'Attack (1)']\n",
    "            try: \n",
    "                class_report_dict = classification_report(all_true_list, all_preds_list, target_names=target_names, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    else: \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            try: class_report_dict = classification_report(all_true_list, all_preds_list, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(all_true_list) > 0 :\n",
    "        valid_pairs = [(t, p) for t, p in zip(all_true_list, all_probs_binary_list) if not (isinstance(p, (float, np.floating)) and (np.isnan(p) or np.isinf(p)))]\n",
    "        if len(valid_pairs) > 1:\n",
    "            vt, vp = [p[0] for p in valid_pairs], [p[1] for p in valid_pairs]\n",
    "            if len(np.unique(vt)) >= 2:\n",
    "                try: auc = roc_auc_score(vt, vp)\n",
    "                except ValueError as e: print(f\"Could not compute AUC in {phase} (filtered): {e}. Unique true: {np.unique(vt)}\")\n",
    "            else: print(f\"Not enough unique classes in valid_true_for_auc ({np.unique(vt)}) for AUC in {phase}.\")\n",
    "        else: print(f\"Not enough valid (non-NaN prob) points ({len(valid_pairs)}) for AUC in {phase}.\")\n",
    "    \n",
    "    if return_embeddings_and_ids:\n",
    "        final_embeddings = torch.cat(all_node_embeddings_list, dim=0) if all_node_embeddings_list else torch.empty(0)\n",
    "        # final_indices below would be local if all_target_node_indices_global_list is not populated with global indices\n",
    "        final_indices = torch.cat(all_target_node_indices_global_list, dim=0) if all_target_node_indices_global_list else torch.empty(0) \n",
    "        final_entity_ids = [] # Placeholder, not populated in this version\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict, final_embeddings, final_indices, final_entity_ids\n",
    "    else:\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae711d39-282f-4cda-bb68-276e8cd4306c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW/MODIFIED - Prepare Sequences from Event Embeddings\n",
    "\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size, num_neighbors, device):\n",
    "    \"\"\"\n",
    "    Gets TGAT embeddings for all events in data_cpu.\n",
    "    Assumes model_tgat is already trained and on the correct device.\n",
    "    \"\"\"\n",
    "    model_tgat.eval()\n",
    "    loader = TemporalNeighborLoader(data_cpu, batch_size, num_neighbors, device, shuffle=False) # No shuffle\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    # We also need the original global indices to ensure correct order if loader shuffles (even if we set to False)\n",
    "    # And corresponding labels for sequence labeling\n",
    "    all_global_indices_list = [] # To store the original global indices\n",
    "    all_original_labels_list = [] # Store original event labels\n",
    "\n",
    "    # Store the global indices that the loader processes in each batch\n",
    "    # The modified loader in previous step returns local indices, features, ts, local_neighbors, batch_labels\n",
    "    # We need to reconstruct the global indices of target_nodes if not directly returned\n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 # Keep track of how many nodes we've processed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data # Unpack based on previous loader modification\n",
    "\n",
    "            # To get global indices:\n",
    "            # If loader is not shuffled and processes sequentially:\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "\n",
    "            _, node_embeddings = model_tgat(\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu()) # Store global indices\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu()) # Store corresponding labels\n",
    "\n",
    "    if not all_embeddings_list:\n",
    "        return torch.empty(0), torch.empty(0, dtype=torch.long), torch.empty(0)\n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    # Sort by global index to ensure original temporal order\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels # Return sorted labels as well\n",
    "\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', # 'any_attack', 'all_attack', 'majority_attack'\n",
    "                               classification_mode='binary'): # For KDD, labels are binary or multiclass event-wise\n",
    "    \"\"\"\n",
    "    Creates sequences of embeddings and corresponding sequence labels.\n",
    "    event_labels should be for binary classification (0 for normal, 1 for attack event).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length]\n",
    "        seq_event_labels = event_labels[i : i + sequence_length] # These are event-level labels\n",
    "\n",
    "        if classification_mode == 'binary':\n",
    "            # Determine sequence label based on event labels within the sequence\n",
    "            if label_mode == 'any_attack':\n",
    "                # If any event in the sequence is an attack, the sequence is an attack\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                # Only if all events in sequence are attacks\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                # If majority of events are attacks\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: # Default to 'any_attack'\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # Multiclass - how to define sequence label? For now, let's assume binary sequence target.\n",
    "            # Or, one could try to predict the dominant attack type in the sequence, or a multi-label output.\n",
    "            # This part needs more sophisticated handling for multiclass sequence labeling.\n",
    "            # For simplicity, we'll stick to binary sequence classification (attack vs. normal sequence).\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is not deeply implemented. Defaulting to binary 'any_attack'.\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal in multiclass too\n",
    "\n",
    "        sequences.append(seq)\n",
    "        sequence_labels.append(label)\n",
    "    \n",
    "    if not sequences:\n",
    "        # Return empty tensors with expected structure if no sequences are generated\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "\n",
    "    # For PackedSequence, we need lengths of sequences before padding\n",
    "    # In this sliding window approach, all sequences have the same length `sequence_length`\n",
    "    lengths = [sequence_length] * len(sequences)\n",
    "    \n",
    "    # Pad sequences to the max length (which is sequence_length here)\n",
    "    # `sequences` is a list of Tensors [ (seq_len, embed_dim), ... ]\n",
    "    # Need to stack them and then pad if lengths were variable. Here they are fixed.\n",
    "    padded_sequences = torch.stack(sequences) # (num_sequences, sequence_length, embedding_dim)\n",
    "    \n",
    "    return sequences, sequence_labels, padded_sequences, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32) # For BCEWithLogitsLoss\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return sequence, its actual length, and its label\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed(batch):\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already padded to the same length `sequence_length`\n",
    "    padded_sequences = torch.stack(sequences) # (batch_size, sequence_length, embedding_dim)\n",
    "    \n",
    "    # Create PackedSequence\n",
    "    # Sort by lengths in descending order for pack_padded_sequence\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    sorted_lengths, sorted_idx = lengths.sort(descending=True)\n",
    "    sorted_sequences = padded_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Also sort labels according to sorted_idx\n",
    "    labels = torch.stack(labels)[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d9075d7-1512-48d5-bfa9-2f543572affa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW - Training and Evaluation for Sequence Aggregator Model\n",
    "\n",
    "def train_sequence_epoch(seq_model, loader, optimizer, criterion_seq, device):\n",
    "    seq_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "        if loss.isnan() or loss.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds.extend(preds.flatten().tolist())\n",
    "        all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true, all_seq_probs = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds = (probs > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds.extend(preds.flatten().tolist())\n",
    "            all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs.extend(probs.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    \n",
    "    auc = None\n",
    "    if all_seq_true and all_seq_probs and len(np.unique(all_seq_true)) >= 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_seq_true, all_seq_probs)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(phase, avg_loss, accuracy, precision, recall, f1, auc, phase=f\"{phase} Results\")\n",
    "    return avg_loss, accuracy, precision, recall, f1, auc, all_seq_true, all_seq_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb9261f6-ce2d-418d-a83c-c16c952b719c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Sequence Modeling Additions and Modified Pipeline (Conceptual)\n",
    "# Ensure all necessary imports from the original notebook are present\n",
    "# e.g., torch, nn, optim, tqdm, sklearn.metrics, plt, np, os, json, time, Dataset, DataLoader, F\n",
    "# from torch.utils.data import Dataset, DataLoader # Add if not already imported globally\n",
    "\n",
    "\n",
    "# 1. EventSequenceAggregator Model Definition\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class EventSequenceAggregator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, num_classes, dropout=0.1, rnn_type='GRU'):\n",
    "        super(EventSequenceAggregator, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.rnn_type = rnn_type.upper()\n",
    "\n",
    "        if self.rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type. Choose 'GRU' or 'LSTM'.\")\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout_layer = nn.Dropout(dropout) # Renamed to avoid conflict\n",
    "\n",
    "    def forward(self, packed_event_embeddings):\n",
    "        # packed_event_embeddings is a PackedSequence object\n",
    "        if self.rnn_type == 'GRU':\n",
    "            # output is (batch, seq_len, hidden_dim) for packed sequence\n",
    "            # hidden is (num_layers, batch_size, hidden_dim)\n",
    "            _, hidden = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = hidden[-1, :, :] \n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            # output is (batch, seq_len, hidden_dim)\n",
    "            # h_n is (num_layers, batch_size, hidden_dim)\n",
    "            # c_n is (num_layers, batch_size, hidden_dim)\n",
    "            _, (h_n, _) = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = h_n[-1, :, :]\n",
    "        \n",
    "        out = self.dropout_layer(last_hidden)\n",
    "        out = self.fc(out) \n",
    "        return out\n",
    "\n",
    "# 2. Functions to Prepare Sequences from Event Embeddings\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat):\n",
    "    model_tgat.eval()\n",
    "    # Use the modified TemporalNeighborLoader that handles sliced data loading\n",
    "    loader = TemporalNeighborLoader(data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat, shuffle=False)\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    all_global_indices_list = [] \n",
    "    all_original_labels_list = [] \n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data\n",
    "\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            # Assuming non-shuffled loader gives sequential global indices\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "            _, node_embeddings = model_tgat( # Assuming TGAT forward returns (logits, embeddings)\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu())\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu())\n",
    "\n",
    "    if not all_embeddings_list:\n",
    "        # Determine embedding_dim from model or data if possible, else use a placeholder\n",
    "        emb_dim_placeholder = model_tgat.attn_layers[-1].n_out_dim_layer if hasattr(model_tgat, 'attn_layers') and model_tgat.attn_layers else 128 # Fallback\n",
    "        return torch.empty(0, emb_dim_placeholder), torch.empty(0, dtype=torch.long), torch.empty(0)\n",
    "\n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels\n",
    "\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', classification_mode='binary'):\n",
    "    sequences_as_tensors = [] # Store list of tensors directly\n",
    "    sequence_labels_list = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length] # (sequence_length, embedding_dim)\n",
    "        seq_event_labels = event_labels[i : i + sequence_length]\n",
    "\n",
    "        label = 0 # Default to normal\n",
    "        if classification_mode == 'binary': # Ensure event_labels are binary (0 or 1)\n",
    "            if label_mode == 'any_attack':\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: \n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # For multiclass event labels, defining sequence label needs care\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is complex. Defaulting to binary 'any_attack' (event_label > 0 is attack).\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal\n",
    "\n",
    "        sequences_as_tensors.append(seq)\n",
    "        sequence_labels_list.append(label)\n",
    "    \n",
    "    if not sequences_as_tensors:\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    padded_sequences = torch.stack(sequences_as_tensors) # (num_sequences, sequence_length, embedding_dim)\n",
    "    lengths = torch.full((len(sequences_as_tensors),), sequence_length, dtype=torch.long) # All sequences have same length\n",
    "    \n",
    "    return sequence_labels_list, padded_sequences, lengths\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        # Ensure sequence_labels is a tensor\n",
    "        if isinstance(sequence_labels, list):\n",
    "            self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32)\n",
    "        elif isinstance(sequence_labels, torch.Tensor):\n",
    "            self.sequence_labels = sequence_labels.float()\n",
    "        else:\n",
    "            raise TypeError(f\"sequence_labels must be a list or Tensor, got {type(sequence_labels)}\")\n",
    "\n",
    "        self.sequence_lengths = sequence_lengths # This is a tensor of lengths for each sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed_fixed_length(batch): # Simplified for fixed length sequences from sliding window\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already Tensors of shape (sequence_length, embedding_dim)\n",
    "    # Stack them to create (batch_size, sequence_length, embedding_dim)\n",
    "    stacked_sequences = torch.stack(sequences)\n",
    "    \n",
    "    # lengths are all the same (SEQUENCE_LENGTH), but pack_padded_sequence still needs them\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.long) \n",
    "    \n",
    "    # Sort by lengths in descending order (though here all are same)\n",
    "    sorted_lengths, sorted_idx = lengths_tensor.sort(descending=True)\n",
    "    sorted_sequences = stacked_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Sort labels\n",
    "    labels_tensor = torch.stack([l if isinstance(l, torch.Tensor) else torch.tensor(l) for l in labels])\n",
    "    sorted_labels = labels_tensor[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, sorted_labels\n",
    "\n",
    "\n",
    "# 3. Training and Evaluation Functions for Sequence Model\n",
    "def train_sequence_epoch(seq_model, loader, optimizer_seq, criterion_seq, device_seq):\n",
    "    seq_model.train()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_epoch, all_seq_true_epoch = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "        labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer_seq.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "        if loss_seq.isnan() or loss_seq.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Logits: {output_logits_seq.flatten()[:3]}, Labels: {labels_batch_seq.flatten()[:3]}. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss_seq.backward()\n",
    "        optimizer_seq.step()\n",
    "        \n",
    "        total_loss_seq += loss_seq.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds_seq = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds_epoch.extend(preds_seq.flatten().tolist())\n",
    "        all_seq_true_epoch.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss_seq.item()})\n",
    "        \n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    # Ensure all_seq_true_epoch is not empty before calculating metrics\n",
    "    if not all_seq_true_epoch:\n",
    "        print(\"Warning: No true labels collected in sequence training epoch.\")\n",
    "        return avg_loss_seq, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    accuracy_seq = accuracy_score(all_seq_true_epoch, all_seq_preds_epoch)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_epoch, all_seq_preds_epoch, average='binary', zero_division=0)\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device_seq, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_eval, all_seq_true_eval, all_seq_probs_eval = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "            labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "            if loss_seq.isnan() or loss_seq.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss_seq += loss_seq.item()\n",
    "            \n",
    "            probs_seq = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds_seq = (probs_seq > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds_eval.extend(preds_seq.flatten().tolist())\n",
    "            all_seq_true_eval.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs_eval.extend(probs_seq.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss_seq.item()})\n",
    "\n",
    "    if not all_seq_true_eval: # Check if any data was processed\n",
    "        print(f\"Warning: No true labels collected in sequence evaluation phase {phase}.\")\n",
    "        return float('nan'), 0.0, 0.0, 0.0, 0.0, None, [], []\n",
    "\n",
    "\n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy_seq = accuracy_score(all_seq_true_eval, all_seq_preds_eval)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_eval, all_seq_preds_eval, average='binary', zero_division=0)\n",
    "    \n",
    "    auc_seq = None\n",
    "    if all_seq_probs_eval and len(np.unique(all_seq_true_eval)) >= 2:\n",
    "        try:\n",
    "            auc_seq = roc_auc_score(all_seq_true_eval, all_seq_probs_eval)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(f\"{phase} Seq Aggregator\", avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, phase=f\"{phase} Seq Results\")\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, all_seq_true_eval, all_seq_preds_eval\n",
    "\n",
    "\n",
    "# 4. Modified train_pipeline (Conceptual - integrate stage 2)\n",
    "# This is a high-level sketch. The original train_pipeline needs to be carefully refactored.\n",
    "# For now, I will keep the original train_pipeline as is, and the sequence training\n",
    "# will be a separate set of calls in the __main__ block after TGAT training.\n",
    "\n",
    "# --- Keeping original train_pipeline for TGAT ---\n",
    "# The original train_pipeline in cell \"d6727e62-27d4-4ac9-8ffa-2563c1be7743\"\n",
    "# will train and save the best TGAT model. We will use that saved model.\n",
    "\n",
    "# --- Add these to your global configuration (e.g., Cell 2 of the notebook) ---\n",
    "# Make sure these are defined if you haven't already\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE # Use TGAT's batch size for consistency or define separately\n",
    "SEQUENCE_LENGTH = 10 \n",
    "STEP_SIZE = 5      \n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64  \n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 20 # Fewer epochs for the sequence model might be sufficient\n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM # This is the output dim of TGAT's attention layers, used as input to its MLP\n",
    "                                          # and thus the dimension of embeddings `h` returned by TGAT\n",
    "SEQ_MODEL_HIDDEN_DIM = 128   \n",
    "SEQ_MODEL_NUM_LAYERS = 1 # GRU/LSTM layers   \n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'        \n",
    "SEQ_MODEL_DROPOUT = 0.2\n",
    "\n",
    "# Ensure DEVICE is defined globally\n",
    "# DEVICE = get_device() \n",
    "\n",
    "# It's better to run sequence model training as a separate step after TGAT training is complete.\n",
    "# So, the `train_pipeline` function itself will not be massively changed to include stage 2.\n",
    "# Instead, the __main__ block will call TGAT training, then sequence model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebd06a-8c64-4583-a08b-08be53e7298e",
   "metadata": {},
   "source": [
    "## 8. Main Training Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6727e62-27d4-4ac9-8ffa-2563c1be7743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_pipeline function (MODIFIED Loader Instantiation)\n",
    "def train_pipeline():\n",
    "    # --- STAGE 1: Train TGAT Event-Level Model ---\n",
    "    print(\"--- Stage 1: TGAT Event-Level Model Training ---\")\n",
    "    stage1_start_time = time.time()\n",
    "    \n",
    "    # Safely access global configurations or use defaults\n",
    "    # These should be defined in your global configuration cell (usually Cell 2)\n",
    "    processed_train_file_path = globals().get('PROCESSED_TRAIN_FILE', './processed_data_large/train_temporal_data.pt')\n",
    "    processed_test_file_path = globals().get('PROCESSED_TEST_FILE', './processed_data_large/test_temporal_data.pt') # [cite: 430]\n",
    "    metadata_file_path = globals().get('METADATA_FILE', './processed_data_large/metadata.json') # [cite: 430]\n",
    "    classification_mode_val = globals().get('CLASSIFICATION_MODE', 'binary') # [cite: 430]\n",
    "    \n",
    "    if not all(k in globals() for k in ['PROCESSED_TRAIN_FILE', 'METADATA_FILE', 'CLASSIFICATION_MODE', 'PROCESSED_TEST_FILE']):\n",
    "        print(\"Warning: Some essential global configuration variables for data loading might be missing. Using defaults.\") # [cite: 430]\n",
    "\n",
    "    train_data_cpu_tgat, metadata_tgat, num_classes_meta_tgat, pos_weight_cpu_tgat = load_processed_data(\n",
    "        processed_train_file_path, metadata_file_path, classification_mode_val\n",
    "    ) # [cite: 431]\n",
    "    test_data_cpu_tgat, _, _, _ = load_processed_data( \n",
    "        processed_test_file_path, metadata_file_path, classification_mode_val\n",
    "    ) # [cite: 431]\n",
    "\n",
    "    NODE_FEAT_DIM_RUNTIME_TGAT = metadata_tgat['NODE_FEAT_DIM'] # [cite: 431]\n",
    "    \n",
    "    device_val = globals().get('DEVICE', torch.device('cuda' if torch.cuda.is_available() else 'cpu')) # [cite: 432]\n",
    "    use_focal_loss_val = globals().get('USE_FOCAL_LOSS', False)  # [cite: 432]\n",
    "    if 'USE_FOCAL_LOSS' not in globals(): print(f\"Warning: Global 'USE_FOCAL_LOSS' not set, defaulted to {use_focal_loss_val}.\") # [cite: 432]\n",
    "\n",
    "\n",
    "    if classification_mode_val == 'binary':\n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = 1 \n",
    "        if use_focal_loss_val: \n",
    "            criterion_tgat = FocalLoss(gamma=2.0, \n",
    "                                       pos_weight_for_bce=pos_weight_cpu_tgat.to(device_val) if pos_weight_cpu_tgat is not None else None, \n",
    "                                       alpha=None) # [cite: 433]\n",
    "        else: \n",
    "            criterion_tgat = nn.BCEWithLogitsLoss(pos_weight=pos_weight_cpu_tgat.to(device_val) if pos_weight_cpu_tgat is not None else None) # [cite: 434]\n",
    "    else: \n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = metadata_tgat.get('NUM_CLASSES_MULTI', num_classes_meta_tgat) # [cite: 434]\n",
    "        criterion_tgat = nn.CrossEntropyLoss() # [cite: 434]\n",
    "\n",
    "    # Load TGAT Hyperparameters safely\n",
    "    epochs_val = globals().get('EPOCHS', 70) # [cite: 435]\n",
    "    batch_size_val = globals().get('BATCH_SIZE', 256) # [cite: 435]\n",
    "    learning_rate_val = globals().get('LEARNING_RATE', 0.0005) # [cite: 435]\n",
    "    hidden_dim_val = globals().get('HIDDEN_DIM', 256) # [cite: 435]\n",
    "    time_dim_val = globals().get('TIME_DIM', 64) # [cite: 435]\n",
    "    n_layers_val = globals().get('N_LAYERS', 2) # [cite: 435]\n",
    "    n_heads_val = globals().get('N_HEADS', 4) # [cite: 435]\n",
    "    dropout_val = globals().get('DROPOUT', 0.3) # [cite: 435]\n",
    "    weight_decay_val = globals().get('WEIGHT_DECAY', 1e-5) # [cite: 435]\n",
    "\n",
    "    print(f\"\\n--- TGAT Training Configuration ---\") # [cite: 436]\n",
    "    print(f\"Device: {device_val}, Epochs: {epochs_val}, Batch Size: {batch_size_val}, LR: {learning_rate_val}\") # [cite: 436]\n",
    "    print(f\"Node Feat Dim: {NODE_FEAT_DIM_RUNTIME_TGAT}, Hidden Dim: {hidden_dim_val}, Time Emb: {time_dim_val}\") # [cite: 436]\n",
    "    print(f\"TGAT Layers: {n_layers_val}, Heads: {n_heads_val}, Dropout: {dropout_val}\") # [cite: 436]\n",
    "    print(f\"TGAT Output Dim: {ACTUAL_NUM_OUTPUT_CLASSES_TGAT}, Mode: {classification_mode_val}\") # [cite: 436]\n",
    "    print(f\"TGAT Loss: {type(criterion_tgat).__name__} (FocalLoss used: {use_focal_loss_val})\") # [cite: 436]\n",
    "    print(f\"----------------------------\\n\") # [cite: 436]\n",
    "\n",
    "    tgat_model = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT, time_emb_dim=time_dim_val, n_head=n_heads_val, \n",
    "        n_layers=n_layers_val, hidden_dim_per_layer=hidden_dim_val, \n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT, dropout=dropout_val\n",
    "    ).to(device_val) # [cite: 437]\n",
    "    \n",
    "    optimizer_tgat = optim.Adam(tgat_model.parameters(), lr=learning_rate_val, weight_decay=weight_decay_val) # [cite: 437]\n",
    "    lr_scheduler_tgat = optim.lr_scheduler.ReduceLROnPlateau(optimizer_tgat, mode='max', factor=0.5, patience=7, verbose=True, min_lr=1e-7) # [cite: 437]\n",
    "\n",
    "    # Loader parameters\n",
    "    num_neighbors_val = globals().get('NUM_NEIGHBORS', [10,5]) # [cite: 438]\n",
    "    recency_bias_factor_val = globals().get('RECENCY_BIAS_FACTOR', 0.9) # [cite: 438]\n",
    "    feature_similarity_col_name_val = globals().get('FEATURE_SIMILARITY_COL_NAME', 'service') # [cite: 438]\n",
    "    feature_similarity_weight_val = globals().get('FEATURE_SIMILARITY_WEIGHT', 0.3) # [cite: 438]\n",
    "    col_names_val = globals().get('COL_NAMES') # [cite: 438]\n",
    "    raw_data_dir_val = globals().get('RAW_DATA_DIR', './data/') # [cite: 438]\n",
    "    train_file_val = globals().get('TRAIN_FILE', 'KDDTrain+_20Percent.txt') # [cite: 438]\n",
    "    test_file_val = globals().get('TEST_FILE', 'KDDTest+.txt') # [cite: 438]\n",
    "\n",
    "    if col_names_val is None:\n",
    "        print(\"Critical Warning: Global variable COL_NAMES is not defined. Feature similarity sampling in TemporalNeighborLoader will be disabled.\") # [cite: 439]\n",
    "        \n",
    "    train_raw_csv_path_to_check = None # [cite: 440]\n",
    "    if raw_data_dir_val and train_file_val: # Check if base path components are strings # [cite: 440]\n",
    "        path_candidate_train = os.path.join(str(raw_data_dir_val), str(train_file_val)) # [cite: 440]\n",
    "        if os.path.exists(path_candidate_train): # [cite: 440]\n",
    "            train_raw_csv_path_to_check = path_candidate_train # [cite: 440]\n",
    "            print(f\"Train raw data file for loader's feature similarity FOUND at: {os.path.abspath(path_candidate_train)}\") # [cite: 441]\n",
    "        else:\n",
    "            print(f\"Warning: Train raw data file for loader's feature similarity NOT FOUND at: {os.path.abspath(path_candidate_train)}\") # [cite: 441]\n",
    "    else:\n",
    "        print(\"Warning: RAW_DATA_DIR or TRAIN_FILE not defined correctly. Cannot set path for train raw data for loader.\") # [cite: 441]\n",
    "\n",
    "    test_raw_csv_path_to_check = None # [cite: 442]\n",
    "    if raw_data_dir_val and test_file_val: # Check if base path components are strings # [cite: 442]\n",
    "        path_candidate_test = os.path.join(str(raw_data_dir_val), str(test_file_val)) # [cite: 442]\n",
    "        if os.path.exists(path_candidate_test): # [cite: 442]\n",
    "            test_raw_csv_path_to_check = path_candidate_test # [cite: 442]\n",
    "            print(f\"Test raw data file for loader's feature similarity FOUND at: {os.path.abspath(path_candidate_test)}\") # [cite: 442]\n",
    "        else:\n",
    "            print(f\"Warning: Test raw data file for loader's feature similarity NOT FOUND at: {os.path.abspath(path_candidate_test)}\") # [cite: 443]\n",
    "    else:\n",
    "        print(\"Warning: RAW_DATA_DIR or TEST_FILE not defined correctly. Cannot set path for test raw data for loader.\") # [cite: 443]\n",
    "    \n",
    "    train_loader_tgat = TemporalNeighborLoader(\n",
    "        train_data_cpu_tgat, batch_size_val, num_neighbors_val, device_val, shuffle=True,\n",
    "        recency_bias_factor=recency_bias_factor_val, \n",
    "        feature_similarity_col_name=feature_similarity_col_name_val, \n",
    "        feature_similarity_weight=feature_similarity_weight_val,\n",
    "        raw_data_file_path_for_ids=train_raw_csv_path_to_check,\n",
    "        col_names_list=col_names_val \n",
    "    ) # [cite: 444]\n",
    "    test_loader_tgat = TemporalNeighborLoader(\n",
    "        test_data_cpu_tgat, batch_size_val, num_neighbors_val, device_val, shuffle=False,\n",
    "        recency_bias_factor=recency_bias_factor_val,\n",
    "        feature_similarity_col_name=feature_similarity_col_name_val,\n",
    "        feature_similarity_weight=feature_similarity_weight_val,\n",
    "        raw_data_file_path_for_ids=test_raw_csv_path_to_check,\n",
    "        col_names_list=col_names_val \n",
    "    ) # [cite: 445]\n",
    "    \n",
    "    best_val_f1_attack_tgat = -1.0 \n",
    "    history_tgat = {k: [] for k in ['train_loss', 'train_acc', 'train_f1', 'train_auc', \n",
    "                                   'val_loss', 'val_acc', 'val_f1', 'val_f1_attack', 'val_auc']} # [cite: 446]\n",
    "    epochs_without_improvement_tgat = 0 # [cite: 446]\n",
    "    \n",
    "    early_stopping_patience_val = globals().get('EARLY_STOPPING_PATIENCE', 20) # [cite: 447]\n",
    "    clip_grad_norm_val = globals().get('CLIP_GRAD_NORM', 1.0) # [cite: 447]\n",
    "    model_save_dir_val = globals().get('MODEL_SAVE_DIR', './saved_models_large/') # [cite: 447]\n",
    "    best_model_name_val = globals().get('BEST_MODEL_NAME', 'best_tgat_model.pth') # [cite: 447]\n",
    "\n",
    "    for epoch_tgat in range(epochs_val):\n",
    "        epoch_str_display_tgat = f\"TGAT Epoch {epoch_tgat+1}/{epochs_val}\" # [cite: 447]\n",
    "        print(f\"--- {epoch_str_display_tgat} ---\") # [cite: 447]\n",
    "        \n",
    "        train_loss, train_acc, train_prec, train_rec, train_f1, train_auc = train_epoch(\n",
    "            tgat_model, train_loader_tgat, optimizer_tgat, criterion_tgat, clip_grad_norm_val\n",
    "        ) # [cite: 448]\n",
    "        print_metrics(epoch_str_display_tgat, train_loss, train_acc, train_prec, train_rec, train_f1, train_auc, phase='Train TGAT') # [cite: 448]\n",
    "        for k,v_val_hist in zip(['loss', 'acc', 'f1', 'auc'],[train_loss, train_acc, train_f1, train_auc]): history_tgat[f'train_{k}'].append(v_val_hist if v_val_hist is not None and not np.isnan(v_val_hist) else np.nan) # [cite: 448]\n",
    "\n",
    "        eval_output_tgat = evaluate_model(tgat_model, test_loader_tgat, criterion_tgat, phase='Validation TGAT', return_embeddings_and_ids=False) # [cite: 449]\n",
    "        val_loss, val_acc, val_prec, val_rec, val_f1, val_auc, _, _, val_class_report_dict_tgat = eval_output_tgat # [cite: 449]\n",
    "        \n",
    "        val_f1_attack_current_tgat = np.nan # [cite: 449]\n",
    "        if classification_mode_val == 'binary' and val_class_report_dict_tgat and isinstance(val_class_report_dict_tgat, dict): # [cite: 449]\n",
    "            attack_label_str = 'Attack (1)' if 'Attack (1)' in val_class_report_dict_tgat else ('1' if '1' in val_class_report_dict_tgat else None) # [cite: 450]\n",
    "            if attack_label_str:  # [cite: 450]\n",
    "                f1_score_val_metric = val_class_report_dict_tgat[attack_label_str].get('f1-score') # [cite: 450]\n",
    "                if f1_score_val_metric is not None:  # [cite: 450]\n",
    "                    val_f1_attack_current_tgat = f1_score_val_metric # [cite: 451]\n",
    "        elif val_f1 is not None and not np.isnan(val_f1):  # [cite: 451]\n",
    "             val_f1_attack_current_tgat = val_f1  # [cite: 451]\n",
    "        \n",
    "        print_metrics(epoch_str_display_tgat, val_loss, val_acc, val_prec, val_rec, val_f1, val_auc, phase='Validation TGAT', class_report=str(val_class_report_dict_tgat if val_class_report_dict_tgat else \"N/A\")) # [cite: 451]\n",
    "        history_tgat[f'val_f1_attack'].append(val_f1_attack_current_tgat if not np.isnan(val_f1_attack_current_tgat) else np.nan) # [cite: 452]\n",
    "        for k,v_val_hist in zip(['loss', 'acc', 'f1', 'auc'],[val_loss, val_acc, val_f1, val_auc]): history_tgat[f'val_{k}'].append(v_val_hist if v_val_hist is not None and not np.isnan(v_val_hist) else np.nan) # [cite: 452]\n",
    "        \n",
    "        current_lr_tgat = optimizer_tgat.param_groups[0]['lr'] # [cite: 452]\n",
    "        print(f\"TGAT Current LR: {current_lr_tgat}\") # [cite: 452]\n",
    "        \n",
    "        scheduler_metric = np.nan # [cite: 453]\n",
    "        if not np.isnan(val_f1_attack_current_tgat): # [cite: 453]\n",
    "            scheduler_metric = val_f1_attack_current_tgat # [cite: 453]\n",
    "        elif val_loss is not None and not np.isnan(val_loss) :  # [cite: 453]\n",
    "            scheduler_metric = -val_loss  # [cite: 453]\n",
    "        \n",
    "        if not np.isnan(scheduler_metric): # [cite: 454]\n",
    "            lr_scheduler_tgat.step(scheduler_metric) # [cite: 454]\n",
    "        else:\n",
    "            print(f\"{epoch_str_display_tgat}: Both Val F1 (Attack) and Val Loss are NaN, scheduler not stepped.\") # [cite: 454]\n",
    "\n",
    "        if not np.isnan(val_f1_attack_current_tgat) and val_f1_attack_current_tgat > best_val_f1_attack_tgat:\n",
    "            best_val_f1_attack_tgat = val_f1_attack_current_tgat # [cite: 455]\n",
    "            if not os.path.exists(model_save_dir_val): os.makedirs(model_save_dir_val) # [cite: 455]\n",
    "            torch.save(tgat_model.state_dict(), os.path.join(model_save_dir_val, best_model_name_val)) # [cite: 455]\n",
    "            print(f\"{epoch_str_display_tgat}: New best TGAT model saved! Val F1 (Attack): {best_val_f1_attack_tgat:.4f}\") # [cite: 455]\n",
    "            epochs_without_improvement_tgat = 0 # [cite: 456]\n",
    "        else: \n",
    "            epochs_without_improvement_tgat += 1 # [cite: 456]\n",
    "            current_f1_display = f\"{val_f1_attack_current_tgat:.4f}\" if not np.isnan(val_f1_attack_current_tgat) else \"NaN\" # [cite: 456]\n",
    "            best_f1_display = f\"{best_val_f1_attack_tgat:.4f}\" if best_val_f1_attack_tgat != -1.0 and not np.isnan(best_val_f1_attack_tgat) else \"N/A\" # [cite: 456]\n",
    "            print(f\"{epoch_str_display_tgat}: No improvement count: {epochs_without_improvement_tgat} (Current F1 Attack: {current_f1_display}, Best F1 Attack: {best_f1_display}).\") # [cite: 457]\n",
    "        \n",
    "        if epochs_without_improvement_tgat >= early_stopping_patience_val: # [cite: 457]\n",
    "            print(f\"TGAT Early stopping triggered after {early_stopping_patience_val} epochs without improvement.\") # [cite: 457]\n",
    "            break # [cite: 457]\n",
    "        print(f\"---------------------------------\\n\") # [cite: 458]\n",
    "\n",
    "    stage1_time = time.time() - stage1_start_time # [cite: 458]\n",
    "    best_val_f1_attack_tgat_str = f\"{best_val_f1_attack_tgat:.4f}\" if best_val_f1_attack_tgat != -1.0 and not np.isnan(best_val_f1_attack_tgat) else \"N/A\" # [cite: 458]\n",
    "    print(f\"--- TGAT Training (Stage 1) Finished in {stage1_time:.2f}s. Best Val F1 (Attack): {best_val_f1_attack_tgat_str} ---\") # [cite: 458]\n",
    "\n",
    "    # --- STAGE 2: Train Sequence Aggregator Model ---\n",
    "    print(\"\\n\\n--- Stage 2: Sequence Aggregator Model Training ---\") # [cite: 459]\n",
    "    stage2_start_time = time.time() # [cite: 459]\n",
    "\n",
    "    best_tgat_model_path = os.path.join(model_save_dir_val, best_model_name_val) # [cite: 459]\n",
    "    if not os.path.exists(best_tgat_model_path): # [cite: 459]\n",
    "        print(f\"Error: Best TGAT model not found at {best_tgat_model_path} from Stage 1. Cannot proceed with Stage 2.\") # [cite: 459]\n",
    "        return history_tgat, None # [cite: 460]\n",
    "\n",
    "    tgat_model_for_embeddings = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT, time_emb_dim=time_dim_val, n_head=n_heads_val,\n",
    "        n_layers=n_layers_val, hidden_dim_per_layer=hidden_dim_val, \n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT, dropout=dropout_val\n",
    "    ).to(device_val) # [cite: 460]\n",
    "    tgat_model_for_embeddings.load_state_dict(torch.load(best_tgat_model_path, map_location=device_val)) # [cite: 460]\n",
    "    tgat_model_for_embeddings.eval() # [cite: 460]\n",
    "\n",
    "    batch_size_seq_embed_gen_val = globals().get('BATCH_SIZE_SEQ_EMBED_GEN', batch_size_val) # [cite: 461]\n",
    "    \n",
    "    train_event_embeddings, train_event_labels_tgat = get_all_event_embeddings(\n",
    "        tgat_model_for_embeddings, train_data_cpu_tgat, batch_size_seq_embed_gen_val, num_neighbors_val, device_val\n",
    "    ) # [cite: 461]\n",
    "    test_event_embeddings, test_event_labels_tgat = get_all_event_embeddings(\n",
    "        tgat_model_for_embeddings, test_data_cpu_tgat, batch_size_seq_embed_gen_val, num_neighbors_val, device_val\n",
    "    ) # [cite: 461]\n",
    "\n",
    "    if train_event_embeddings.numel() == 0: # [cite: 462]\n",
    "        print(\"Error: Failed to generate train event embeddings for Stage 2. Aborting Stage 2.\") # [cite: 462]\n",
    "        return history_tgat, None # [cite: 462]\n",
    "\n",
    "    if classification_mode_val == 'binary':\n",
    "        train_event_labels_binary_for_seq = train_event_labels_tgat.squeeze().long() if train_event_labels_tgat.numel() > 0 else torch.empty(0, dtype=torch.long) # [cite: 462]\n",
    "        test_event_labels_binary_for_seq = test_event_labels_tgat.squeeze().long() if test_event_labels_tgat.numel() > 0 else torch.empty(0, dtype=torch.long) # [cite: 462]\n",
    "    else: \n",
    "        train_event_labels_binary_for_seq = (train_event_labels_tgat.squeeze() > 0).long() if train_event_labels_tgat.numel() > 0 else torch.empty(0, dtype=torch.long) # [cite: 463]\n",
    "        test_event_labels_binary_for_seq = (test_event_labels_tgat.squeeze() > 0).long() if test_event_labels_tgat.numel() > 0 else torch.empty(0, dtype=torch.long) # [cite: 463]\n",
    "\n",
    "    sequence_length_val = globals().get('SEQUENCE_LENGTH', 10) # [cite: 463]\n",
    "    step_size_val = globals().get('STEP_SIZE', 5) # [cite: 463]\n",
    "    seq_label_mode_val = globals().get('SEQ_LABEL_MODE', 'any_attack') # [cite: 463]\n",
    "\n",
    "    print(f\"Creating training sequences (Length: {sequence_length_val}, Step: {step_size_val}, Label Mode: {seq_label_mode_val})...\") # [cite: 464]\n",
    "    train_seq_labels_list, train_padded_sequences, train_seq_lengths = create_embedding_sequences(\n",
    "        train_event_embeddings, train_event_labels_binary_for_seq, \n",
    "        sequence_length_val, step_size_val, seq_label_mode_val, 'binary'\n",
    "    ) # [cite: 464]\n",
    "    if train_padded_sequences.numel() == 0: # [cite: 464]\n",
    "        print(\"No training sequences generated. Aborting Stage 2 training.\") # [cite: 464]\n",
    "        return history_tgat, None # [cite: 465]\n",
    "    \n",
    "    train_sequence_dataset = EmbeddingSequenceDataset(train_padded_sequences, train_seq_labels_list, train_seq_lengths) # [cite: 465]\n",
    "    batch_size_seq_model_val = globals().get('BATCH_SIZE_SEQ_MODEL', 64) # [cite: 465]\n",
    "    train_sequence_loader = DataLoader(train_sequence_dataset, batch_size=batch_size_seq_model_val, shuffle=True, collate_fn=collate_fn_packed_fixed_length) # [cite: 465]\n",
    "    print(f\"Created {len(train_sequence_dataset)} training sequences.\") # [cite: 465]\n",
    "\n",
    "    test_sequence_loader = None # [cite: 465]\n",
    "    if test_event_embeddings.numel() > 0 and test_event_labels_binary_for_seq.numel() > 0 : # [cite: 465]\n",
    "        print(f\"Creating test sequences (Length: {sequence_length_val}, Step: {step_size_val}, Label Mode: {seq_label_mode_val})...\") # [cite: 466]\n",
    "        test_seq_labels_list, test_padded_sequences, test_seq_lengths = create_embedding_sequences(\n",
    "            test_event_embeddings, test_event_labels_binary_for_seq, \n",
    "            sequence_length_val, step_size_val, seq_label_mode_val, 'binary'\n",
    "        ) # [cite: 466]\n",
    "        if test_padded_sequences.numel() > 0: # [cite: 467]\n",
    "            test_sequence_dataset = EmbeddingSequenceDataset(test_padded_sequences, test_seq_labels_list, test_seq_lengths) # [cite: 467]\n",
    "            test_sequence_loader = DataLoader(test_sequence_dataset, batch_size=batch_size_seq_model_val, shuffle=False, collate_fn=collate_fn_packed_fixed_length) # [cite: 467]\n",
    "            print(f\"Created {len(test_sequence_dataset)} test sequences.\") # [cite: 467]\n",
    "        else:\n",
    "            print(\"No test sequences generated for sequence model evaluation.\") # [cite: 467]\n",
    "    else:\n",
    "        print(\"No test event embeddings or labels available for creating test sequences.\") # [cite: 468]\n",
    "    \n",
    "    seq_model_input_dim = train_event_embeddings.shape[1] if train_event_embeddings.numel() > 0 else hidden_dim_val # [cite: 468]\n",
    "    \n",
    "    seq_model_hidden_dim_val = globals().get('SEQ_MODEL_HIDDEN_DIM', 128) # [cite: 468]\n",
    "    seq_model_num_layers_val = globals().get('SEQ_MODEL_NUM_LAYERS', 1) # [cite: 468]\n",
    "    seq_model_dropout_val = globals().get('SEQ_MODEL_DROPOUT', 0.2) # [cite: 468]\n",
    "    seq_model_rnn_type_val = globals().get('SEQ_MODEL_RNN_TYPE', 'GRU') # [cite: 469]\n",
    "\n",
    "    sequence_model = EventSequenceAggregator(\n",
    "        embedding_dim=seq_model_input_dim,\n",
    "        hidden_dim=seq_model_hidden_dim_val,\n",
    "        num_layers=seq_model_num_layers_val,\n",
    "        num_classes=1, \n",
    "        dropout=seq_model_dropout_val,\n",
    "        rnn_type=seq_model_rnn_type_val\n",
    "    ).to(device_val) # [cite: 469]\n",
    "\n",
    "    lr_seq_model_val = globals().get('LEARNING_RATE_SEQ_MODEL', 1e-4) # [cite: 470]\n",
    "    criterion_seq = nn.BCEWithLogitsLoss()  # [cite: 470]\n",
    "    optimizer_seq = optim.Adam(sequence_model.parameters(), lr=lr_seq_model_val) # [cite: 470]\n",
    "    \n",
    "    epochs_seq_model_val = globals().get('EPOCHS_SEQ_MODEL', 20) # [cite: 470]\n",
    "    print(f\"\\n--- Training Sequence Aggregator Model ({seq_model_rnn_type_val}) ---\") # [cite: 470]\n",
    "    print(f\"Input Embedding Dim: {seq_model_input_dim}, Sequence Length: {sequence_length_val}\") # [cite: 470]\n",
    "    print(f\"Seq Model: Hidden={seq_model_hidden_dim_val}, Layers={seq_model_num_layers_val}, Dropout={seq_model_dropout_val}\") # [cite: 470]\n",
    "    print(f\"Optimizer: Adam, LR={lr_seq_model_val}. Epochs: {epochs_seq_model_val}\") # [cite: 471]\n",
    "\n",
    "    history_sequence_model = {'train_loss': [], 'train_acc': [], 'train_f1': [], \n",
    "                              'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_auc': []} # [cite: 471]\n",
    "\n",
    "    for epoch_seq in range(epochs_seq_model_val):\n",
    "        print(f\"Sequence Model Epoch {epoch_seq+1}/{epochs_seq_model_val}\") # [cite: 471]\n",
    "        if len(train_sequence_loader) == 0: # Check if loader has any batches # [cite: 472]\n",
    "            print(\"  Skipping sequence training epoch as train_sequence_loader is empty.\") # [cite: 472]\n",
    "            for k_train_s in ['train_loss', 'train_acc', 'train_f1']: history_sequence_model[k_train_s].append(float('nan')) # [cite: 472]\n",
    "        else:\n",
    "            train_loss_s, train_acc_s, _, _, train_f1_s = train_sequence_epoch(\n",
    "                sequence_model, train_sequence_loader, optimizer_seq, criterion_seq, device_val\n",
    "            ) # [cite: 473]\n",
    "            history_sequence_model['train_loss'].append(train_loss_s) # [cite: 473]\n",
    "            history_sequence_model['train_acc'].append(train_acc_s) # [cite: 473]\n",
    "            history_sequence_model['train_f1'].append(train_f1_s) # [cite: 473]\n",
    "            \n",
    "            train_loss_s_str = f\"{train_loss_s:.4f}\" if train_loss_s is not None and not np.isnan(train_loss_s) else \"N/A\" # [cite: 474]\n",
    "            train_acc_s_str = f\"{train_acc_s:.4f}\" if train_acc_s is not None and not np.isnan(train_acc_s) else \"N/A\" # [cite: 474]\n",
    "            train_f1_s_str = f\"{train_f1_s:.4f}\" if train_f1_s is not None and not np.isnan(train_f1_s) else \"N/A\" # [cite: 474]\n",
    "            print(f\"  Seq Train: Loss={train_loss_s_str}, Acc={train_acc_s_str}, F1={train_f1_s_str}\") # [cite: 475]\n",
    "\n",
    "        if test_sequence_loader and len(test_sequence_loader) > 0: # Check if loader has any batches # [cite: 475]\n",
    "            val_loss_s, val_acc_s, _, _, val_f1_s, val_auc_s, _, _ = evaluate_sequence_model(\n",
    "                sequence_model, test_sequence_loader, criterion_seq, device_val, phase=\"Val Seq Agg\"\n",
    "            ) # [cite: 475]\n",
    "            history_sequence_model['val_loss'].append(val_loss_s) # [cite: 476]\n",
    "            history_sequence_model['val_acc'].append(val_acc_s) # [cite: 476]\n",
    "            history_sequence_model['val_f1'].append(val_f1_s) # [cite: 476]\n",
    "            history_sequence_model['val_auc'].append(val_auc_s if val_auc_s is not None and not np.isnan(val_auc_s) else np.nan) # Store NaN for AUC if None # [cite: 476]\n",
    "            \n",
    "            # ** CORRECTED PRINT STATEMENT for Seq Val **\n",
    "            val_loss_s_str = f\"{val_loss_s:.4f}\" if val_loss_s is not None and not np.isnan(val_loss_s) else \"N/A\" # [cite: 477]\n",
    "            val_acc_s_str = f\"{val_acc_s:.4f}\" if val_acc_s is not None and not np.isnan(val_acc_s) else \"N/A\" # [cite: 477]\n",
    "            val_f1_s_str = f\"{val_f1_s:.4f}\" if val_f1_s is not None and not np.isnan(val_f1_s) else \"N/A\" # [cite: 478]\n",
    "            val_auc_s_str = f\"{val_auc_s:.4f}\" if val_auc_s is not None and not np.isnan(val_auc_s) else \"N/A\" # [cite: 478]\n",
    "            print(f\"  Seq Val:   Loss={val_loss_s_str}, Acc={val_acc_s_str}, F1={val_f1_s_str}, AUC={val_auc_s_str}\") # [cite: 478]\n",
    "        else:\n",
    "            print(\"  No test data for sequence model validation this epoch.\") # [cite: 478]\n",
    "            for k_val_s in ['val_loss', 'val_acc', 'val_f1', 'val_auc']: history_sequence_model[k_val_s].append(float('nan')) # [cite: 479]\n",
    "    \n",
    "    stage2_time = time.time() - stage2_start_time # [cite: 479]\n",
    "    print(f\"--- Sequence Aggregator Training (Stage 2) Finished in {stage2_time:.2f}s ---\") # [cite: 479]\n",
    "    \n",
    "    seq_model_save_path = os.path.join(model_save_dir_val, \"sequence_aggregator_model.pth\") # [cite: 479]\n",
    "    if not os.path.exists(model_save_dir_val): os.makedirs(model_save_dir_val) # [cite: 479]\n",
    "    torch.save(sequence_model.state_dict(), seq_model_save_path) # [cite: 480]\n",
    "    print(f\"Sequence aggregator model saved to {seq_model_save_path}\") # [cite: 480]\n",
    "\n",
    "    combined_history = { # [cite: 480]\n",
    "        \"tgat\": history_tgat, # [cite: 480]\n",
    "        \"sequence_aggregator\": history_sequence_model # [cite: 480]\n",
    "    } # [cite: 480]\n",
    "    return combined_history, sequence_model # [cite: 480]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407f186-ed1d-43f2-951e-4b7994642995",
   "metadata": {},
   "source": [
    "## 9. Execute Training and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec9bf76e-e447-4a64-8797-e172ce67c977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stage 1: TGAT Model Training ---\n",
      "--- Stage 1: TGAT Event-Level Model Training ---\n",
      "Loading data from: ./processed_data_large/train_temporal_data.pt\n",
      "Loading metadata from: ./processed_data_large/metadata.json\n",
      "Data loaded: Nodes=25192, Edges=2\n",
      "Metadata: NodeFeatDim=121, NumClasses(binary)=2, PosWeight=1.1452780961990356\n",
      "Loading data from: ./processed_data_large/test_temporal_data.pt\n",
      "Loading metadata from: ./processed_data_large/metadata.json\n",
      "Data loaded: Nodes=22544, Edges=2\n",
      "Metadata: NodeFeatDim=121, NumClasses(binary)=2, PosWeight=1.1452780961990356\n",
      "\n",
      "--- TGAT Training Configuration ---\n",
      "Device: cuda:0, Epochs: 3, Batch Size: 256, LR: 0.0005\n",
      "Node Feat Dim: 121, Hidden Dim: 256, Time Emb: 64\n",
      "TGAT Layers: 2, Heads: 4, Dropout: 0.3\n",
      "TGAT Output Dim: 1, Mode: binary\n",
      "TGAT Loss: FocalLoss (FocalLoss used: True)\n",
      "----------------------------\n",
      "\n",
      "Train raw data file for loader's feature similarity FOUND at: /notebooks/TGAT_V2/data/KDDTrain+_20Percent.txt\n",
      "Test raw data file for loader's feature similarity FOUND at: /notebooks/TGAT_V2/data/KDDTest+.txt\n",
      "Loading 'service' from ./data/KDDTrain+_20Percent.txt for similarity sampling...\n",
      "Successfully loaded 'service' for 25192 nodes.\n",
      "Loading 'service' from ./data/KDDTest+.txt for similarity sampling...\n",
      "Successfully loaded 'service' for 22544 nodes.\n",
      "--- TGAT Epoch 1/3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6602844391da434ea16bd6bf178bacab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 1/3 | Train TGAT Loss: 0.2046 | Acc: 0.4760 | Prec: 0.4644 | Rec: 0.8084 | F1: 0.5899 | AUC: 0.4971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd32b74be3f471f9a4674ed1d1c1197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation TGAT Phase:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 1/3 | Validation TGAT Loss: 0.2057 | Acc: 0.5691 | Prec: 0.5692 | Rec: 0.9991 | F1: 0.7253 | AUC: 0.5032\n",
      "{'Normal (0)': {'precision': 0.42857142857142855, 'recall': 0.0009267840593141798, 'f1-score': 0.0018495684340320592, 'support': 9711.0}, 'Attack (1)': {'precision': 0.5692403321049594, 'recall': 0.9990649107769033, 'f1-score': 0.7252517253082928, 'support': 12833.0}, 'accuracy': 0.5691092973740242, 'macro avg': {'precision': 0.49890588033819394, 'recall': 0.49999584741810876, 'f1-score': 0.36355064687116245, 'support': 22544.0}, 'weighted avg': {'precision': 0.5086461286710471, 'recall': 0.5691092973740242, 'f1-score': 0.4136407270202363, 'support': 22544.0}}\n",
      "TGAT Current LR: 0.0005\n",
      "TGAT Epoch 1/3: New best TGAT model saved! Val F1 (Attack): 0.7253\n",
      "---------------------------------\n",
      "\n",
      "--- TGAT Epoch 2/3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c506923a6fe14ad7969f7551341c8a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 2/3 | Train TGAT Loss: 0.2032 | Acc: 0.4681 | Prec: 0.4655 | Rec: 0.9518 | F1: 0.6252 | AUC: 0.4988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3a1cea6a474150ab4b7a739e53d0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation TGAT Phase:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 2/3 | Validation TGAT Loss: 0.2064 | Acc: 0.5692 | Prec: 0.5693 | Rec: 0.9987 | F1: 0.7252 | AUC: 0.5006\n",
      "{'Normal (0)': {'precision': 0.5, 'recall': 0.0017505921120378953, 'f1-score': 0.00348896870189841, 'support': 9711.0}, 'Attack (1)': {'precision': 0.5693469569080408, 'recall': 0.9986752902672796, 'f1-score': 0.7252355487649605, 'support': 12833.0}, 'accuracy': 0.5692423704755145, 'macro avg': {'precision': 0.5346734784540204, 'recall': 0.5002129411896588, 'f1-score': 0.3643622587334295, 'support': 22544.0}, 'weighted avg': {'precision': 0.5394752261355966, 'recall': 0.5692423704755145, 'f1-score': 0.4143377028195916, 'support': 22544.0}}\n",
      "TGAT Current LR: 0.0005\n",
      "TGAT Epoch 2/3: No improvement count: 1 (Current F1 Attack: 0.7252, Best F1 Attack: 0.7253).\n",
      "---------------------------------\n",
      "\n",
      "--- TGAT Epoch 3/3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7e3a5396214887869b059f0014b2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 3/3 | Train TGAT Loss: 0.2030 | Acc: 0.4680 | Prec: 0.4663 | Rec: 0.9789 | F1: 0.6317 | AUC: 0.5004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0473472ecc4541ebb939649b41529768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation TGAT Phase:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGAT Epoch 3/3 | Validation TGAT Loss: 0.2049 | Acc: 0.5693 | Prec: 0.5694 | Rec: 0.9988 | F1: 0.7253 | AUC: 0.5033\n",
      "{'Normal (0)': {'precision': 0.5151515151515151, 'recall': 0.0017505921120378953, 'f1-score': 0.0034893267651888347, 'support': 9711.0}, 'Attack (1)': {'precision': 0.5693660876904625, 'recall': 0.9987532143692044, 'f1-score': 0.7252716161158896, 'support': 12833.0}, 'accuracy': 0.5692867281760113, 'macro avg': {'precision': 0.5422588014209888, 'recall': 0.5002519032406212, 'f1-score': 0.36438047144053926, 'support': 22544.0}, 'weighted avg': {'precision': 0.5460127469379022, 'recall': 0.5692867281760113, 'f1-score': 0.41435838812242554, 'support': 22544.0}}\n",
      "TGAT Current LR: 0.0005\n",
      "TGAT Epoch 3/3: New best TGAT model saved! Val F1 (Attack): 0.7253\n",
      "---------------------------------\n",
      "\n",
      "--- TGAT Training (Stage 1) Finished in 70.00s. Best Val F1 (Attack): 0.7253 ---\n",
      "\n",
      "\n",
      "--- Stage 2: Sequence Aggregator Model Training ---\n",
      "Warning: 'feature_similarity_col_name' ('service') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\n",
      "Generating TGAT embeddings for all events...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163091d1d021414296f6bc353ddf6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Embeddings:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 25192 event embeddings of dimension 256\n",
      "Warning: 'feature_similarity_col_name' ('service') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\n",
      "Generating TGAT embeddings for all events...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c5049e460a46efa891decf42ae54e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Embeddings:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 22544 event embeddings of dimension 256\n",
      "Creating training sequences (Length: 10, Step: 5, Label Mode: any_attack)...\n",
      "Created 5037 training sequences.\n",
      "Creating test sequences (Length: 10, Step: 5, Label Mode: any_attack)...\n",
      "Created 4507 test sequences.\n",
      "\n",
      "--- Training Sequence Aggregator Model (GRU) ---\n",
      "Input Embedding Dim: 256, Sequence Length: 10\n",
      "Seq Model: Hidden=128, Layers=1, Dropout=0.2\n",
      "Optimizer: Adam, LR=0.0001. Epochs: 20\n",
      "Sequence Model Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a73ad127b247869819a1084d85c557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.2443, Acc=0.9349, F1=0.9663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dbff88554e42b58dd1e5735b10e2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0464 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0464, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 2/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1eae3fd61a4c6fa07e20e4e024b8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0329, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b8a24a934d450b80eb42bc622100c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0148 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0148, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 3/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b05bbe077e4332bdac698fa0d04d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0185, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c37b4177d14ffaa0ef9bfc64e59f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0084 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0084, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 4/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d9dae609644766b1eddf7f53ccb9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0152, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51b2b50b0674b9999e1344121332845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0058 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0058, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 5/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c34d02abbc4a3aa2bbc8870e77eff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0138, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ba6cbdbc604d29abc549eaa0872323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0045 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0045, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 6/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2609e35ef0a5412eaf9f867e7fe78105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0129, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b7fada682a44afa6e42253b22ac796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0037 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0037, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 7/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7dd47abc7541fe87b08caff5cf1f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0125, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24522be581b74e5ba9bb9f711a0649a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0032 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0032, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 8/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac64feed1c4799a4f8638a89976f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0122, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161f3625dd7c46b2bd81427a78016606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0028 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0028, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 9/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f8528472dd42aca3cdc3efbabd6cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0127, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dac54c482554e41b2cd6a3d47f59d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0025 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0025, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 10/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66109253128440b19a030617fe86d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0117, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd0ea839a354921b5d740bade0b45ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0024 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0024, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 11/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86773640ed1d4cd792f89e20251ac657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0122, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4337cdcc0c1346ada3494073c7e0fbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0022 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0022, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 12/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c57eb80a2d44a78c34a5f607474a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0123, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23818ff3a94049b9a474c4b02e287786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0020 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0020, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 13/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5967e829c4ba4144b26bcf434222f1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0119, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591355a2f93343f6a53870374ab66be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0020 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0020, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 14/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cc60bad253482aa8f62d0dc1e535b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0120, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2075516429f41fe85e159425a647c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0019 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0019, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 15/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac93fa4de8d47818063ca25c364761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0116, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e7927d26314e059b3b8a4346abf256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0019 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0019, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 16/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b822d9d8aea455382f27cfe468af4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0118, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06af8fa6c544fbfac611a77512fb45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0018 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0018, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 17/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cad152f8c2c45cdbe84176636857d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0117, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ff245f0174459b944540ee60613dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0017 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0017, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 18/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e566097859a1484f9123444c02117fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0123, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56dba6437524f5ca8e970345f358b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0017 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0017, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 19/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803bfdea7604b1fa8cd4aa72896abdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0118, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b40cd7b4b6d4c4d8ff955feb8b2dacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0017 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0017, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "Sequence Model Epoch 20/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cecd9b201d4d1586ef06bcafbf1c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.0119, Acc=0.9984, F1=0.9992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff62a1f20d9f4f639f252dbb5fae574d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0016 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n",
      "  Seq Val:   Loss=0.0016, Acc=1.0000, F1=1.0000, AUC=N/A\n",
      "--- Sequence Aggregator Training (Stage 2) Finished in 57.17s ---\n",
      "Sequence aggregator model saved to ./saved_models_large/sequence_aggregator_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation of TGAT Model on Test Set (using best saved TGAT model) ---\n",
      "Loading data from: ./processed_data_large/test_temporal_data.pt\n",
      "Loading metadata from: ./processed_data_large/metadata.json\n",
      "Data loaded: Nodes=22544, Edges=2\n",
      "Metadata: NodeFeatDim=121, NumClasses(binary)=2, PosWeight=1.1452780961990356\n",
      "Warning: 'feature_similarity_col_name' ('service') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf4ee1bb678419c96fb379ca33699f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Final TGAT Test Phase:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TGAT Test | Final TGAT Test Results Loss: 0.2049 | Acc: 0.5693 | Prec: 0.5694 | Rec: 0.9988 | F1: 0.7253 | AUC: 0.5033\n",
      "{'Normal (0)': {'precision': 0.5151515151515151, 'recall': 0.0017505921120378953, 'f1-score': 0.0034893267651888347, 'support': 9711.0}, 'Attack (1)': {'precision': 0.5693660876904625, 'recall': 0.9987532143692044, 'f1-score': 0.7252716161158896, 'support': 12833.0}, 'accuracy': 0.5692867281760113, 'macro avg': {'precision': 0.5422588014209888, 'recall': 0.5002519032406212, 'f1-score': 0.36438047144053926, 'support': 22544.0}, 'weighted avg': {'precision': 0.5460127469379022, 'recall': 0.5692867281760113, 'f1-score': 0.41435838812242554, 'support': 22544.0}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Stage 2: Sequence Aggregator Model Training & Evaluation ---\n",
      "Loading data from: ./processed_data_large/train_temporal_data.pt\n",
      "Loading metadata from: ./processed_data_large/metadata.json\n",
      "Data loaded: Nodes=25192, Edges=2\n",
      "Metadata: NodeFeatDim=121, NumClasses(binary)=2, PosWeight=1.1452780961990356\n",
      "Loading data from: ./processed_data_large/test_temporal_data.pt\n",
      "Loading metadata from: ./processed_data_large/metadata.json\n",
      "Data loaded: Nodes=22544, Edges=2\n",
      "Metadata: NodeFeatDim=121, NumClasses(binary)=2, PosWeight=1.1452780961990356\n",
      "Warning: 'feature_similarity_col_name' ('service') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\n",
      "Generating TGAT embeddings for all events...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3c4f70662b4408bb450c091e404598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Embeddings:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 25192 event embeddings of dimension 256\n",
      "Warning: 'feature_similarity_col_name' ('service') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\n",
      "Generating TGAT embeddings for all events...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6769e733e5b94e5e874b5fabb8ae660b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Embeddings:   0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 22544 event embeddings of dimension 256\n",
      "\n",
      "--- Training Sequence Aggregator Model (GRU) ---\n",
      "Input Embedding Dim: 256, Sequence Length: 10, Step: 5\n",
      "Sequence Model: Hidden=128, Layers=1, Dropout=0.2\n",
      "Optimizer: Adam, LR=0.0001. Epochs: 20\n",
      "Sequence Model Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e50a9c878d4dbb9dfb7bf036d2bc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Sequence Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Seq Train: Loss=0.2284, Acc=0.9672, F1=0.9833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7a841786814928aa23986bd40ac171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Seq Agg Phase:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Seq Agg Seq Aggregator | Val Seq Agg Seq Results Loss: 0.0494 | Acc: 1.0000 | Prec: 1.0000 | Rec: 1.0000 | F1: 1.0000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 169\u001b[0m\n\u001b[1;32m    167\u001b[0m     history_seq_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_f1_s)\n\u001b[1;32m    168\u001b[0m     history_seq_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_auc_s \u001b[38;5;28;01mif\u001b[39;00m val_auc_s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Seq Val:   Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_f1_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_auc_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f if val_auc_s is not None else \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# No test data for sequence model\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k_val_s \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]: history_seq_agg[k_val_s]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "# Cell: Main execution block (MODIFIED to include Stage 2 Sequence Model Training)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    if not all(os.path.exists(f_path) for f_path in [PROCESSED_TRAIN_FILE, PROCESSED_TEST_FILE, METADATA_FILE]):\n",
    "        print(f\"Error: Preprocessed data files not found in '{PROCESSED_DATA_DIR}'.\")\n",
    "        print(\"Please run the `preprocess_kdd_large.ipynb` notebook first to generate these files.\")\n",
    "    else:\n",
    "        # --- STAGE 1: Train TGAT Model (as before) ---\n",
    "        print(\"--- Stage 1: TGAT Model Training ---\")\n",
    "        history_tgat, final_trained_tgat_model = train_pipeline() # This trains and saves best TGAT model\n",
    "        \n",
    "        if not history_tgat:\n",
    "            print(\"TGAT training failed. Aborting.\")\n",
    "        else:\n",
    "            # ... (Plotting code for TGAT history remains the same) ...\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            plot_metrics_map = [('Loss', 'loss'), ('Accuracy', 'acc'), ('F1-score', 'f1'), ('AUC', 'auc')]\n",
    "            for i, (title, key_metric) in enumerate(plot_metrics_map):\n",
    "                ax_current = axs[i//2, i%2]\n",
    "                train_values = [v for v in history_tgat.get(f'train_{key_metric}', []) if v is not None and not np.isnan(v)]\n",
    "                val_values = [v for v in history_tgat.get(f'val_{key_metric}', []) if v is not None and not np.isnan(v)]\n",
    "                epochs_train = [j for j,v in enumerate(history_tgat.get(f'train_{key_metric}', [])) if v is not None and not np.isnan(v)]\n",
    "                epochs_val = [j for j,v in enumerate(history_tgat.get(f'val_{key_metric}', [])) if v is not None and not np.isnan(v)]\n",
    "                if epochs_train and train_values: ax_current.plot(epochs_train, train_values, label=f'Train {title}')\n",
    "                if epochs_val and val_values: ax_current.plot(epochs_val, val_values, label=f'Validation {title}')\n",
    "                ax_current.set_title(f'TGAT {title} over Epochs'); ax_current.set_xlabel('Epoch'); ax_current.set_ylabel(title); ax_current.legend()\n",
    "            plt.tight_layout(); plt.show()\n",
    "\n",
    "            print(\"\\n--- Final Evaluation of TGAT Model on Test Set (using best saved TGAT model) ---\")\n",
    "            best_tgat_model_path = os.path.join(MODEL_SAVE_DIR, BEST_MODEL_NAME)\n",
    "            if os.path.exists(best_tgat_model_path):\n",
    "                with open(METADATA_FILE, 'r') as f_meta: meta_final_tgat = json.load(f_meta)\n",
    "                \n",
    "                tgat_output_dim = 1 if CLASSIFICATION_MODE == 'binary' else meta_final_tgat['NUM_CLASSES_MULTI']\n",
    "                tgat_display_classes = meta_final_tgat.get('NUM_CLASSES_BINARY', 2) if CLASSIFICATION_MODE == 'binary' else tgat_output_dim\n",
    "                tgat_node_feat_dim = meta_final_tgat['NODE_FEAT_DIM']\n",
    "                \n",
    "                tgat_model_for_eval = TGAT(\n",
    "                    node_feat_dim=tgat_node_feat_dim, time_emb_dim=TIME_DIM, n_head=N_HEADS, \n",
    "                    n_layers=N_LAYERS, hidden_dim_per_layer=HIDDEN_DIM, \n",
    "                    num_classes=tgat_output_dim, dropout=DROPOUT \n",
    "                ).to(DEVICE)\n",
    "                tgat_model_for_eval.load_state_dict(torch.load(best_tgat_model_path, map_location=DEVICE))\n",
    "                \n",
    "                tgat_test_data_cpu, _, _, tgat_pos_weight_cpu = load_processed_data(PROCESSED_TEST_FILE, METADATA_FILE, CLASSIFICATION_MODE)\n",
    "                tgat_test_loader = TemporalNeighborLoader(tgat_test_data_cpu, BATCH_SIZE, NUM_NEIGHBORS, DEVICE, shuffle=False) # Using BATCH_SIZE for TGAT\n",
    "                \n",
    "                tgat_criterion_args = {}\n",
    "                if CLASSIFICATION_MODE == 'binary':\n",
    "                    if USE_FOCAL_LOSS: \n",
    "                        tgat_criterion = FocalLoss(gamma=2.0, pos_weight_for_bce=tgat_pos_weight_cpu.to(DEVICE) if tgat_pos_weight_cpu is not None else None, alpha=None)\n",
    "                    else:\n",
    "                        if tgat_pos_weight_cpu is not None: tgat_criterion_args['pos_weight'] = tgat_pos_weight_cpu.to(DEVICE)\n",
    "                        tgat_criterion = nn.BCEWithLogitsLoss(**tgat_criterion_args)\n",
    "                else: \n",
    "                    tgat_criterion = nn.CrossEntropyLoss(**tgat_criterion_args)\n",
    "                \n",
    "                eval_results_tgat = evaluate_model( # This is the event-level evaluation\n",
    "                    tgat_model_for_eval, tgat_test_loader, tgat_criterion, \n",
    "                    phase='Final TGAT Test', return_embeddings_and_ids=True\n",
    "                )\n",
    "                # Unpack all, including embeddings for potential use (though we regenerate for sequence model for clarity)\n",
    "                _, _, _, _, _, _, eval_y_true_tgat, eval_y_pred_tgat, final_class_report_dict_tgat, _, _, _ = eval_results_tgat\n",
    "                # ... (Print TGAT's final metrics and confusion matrix as before) ...\n",
    "                print_metrics(\"Final TGAT Test\", eval_results_tgat[0], eval_results_tgat[1], eval_results_tgat[2], eval_results_tgat[3], eval_results_tgat[4], eval_results_tgat[5], phase='Final TGAT Test Results', class_report=str(final_class_report_dict_tgat))\n",
    "                cm_class_names_tgat = ['Normal', 'Attack'] if CLASSIFICATION_MODE == 'binary' else [str(i) for i in range(tgat_display_classes)]\n",
    "                if eval_y_true_tgat and eval_y_pred_tgat: \n",
    "                    plot_confusion_matrix_custom(eval_y_true_tgat, eval_y_pred_tgat, class_names=cm_class_names_tgat, title='Final TGAT Test Confusion Matrix')\n",
    "\n",
    "\n",
    "                # --- STAGE 2: Train and Evaluate Sequence Aggregator Model ---\n",
    "                print(\"\\n\\n--- Stage 2: Sequence Aggregator Model Training & Evaluation ---\")\n",
    "                \n",
    "                # 1. Load best TGAT model again (or use final_trained_tgat_model if train_pipeline returns it directly)\n",
    "                # We need it for generating embeddings.\n",
    "                tgat_model_for_embeddings_stage2 = TGAT( # Re-init for clarity, or use the one from eval\n",
    "                    node_feat_dim=tgat_node_feat_dim, time_emb_dim=TIME_DIM, n_head=N_HEADS,\n",
    "                    n_layers=N_LAYERS, hidden_dim_per_layer=HIDDEN_DIM,\n",
    "                    num_classes=tgat_output_dim, dropout=DROPOUT\n",
    "                ).to(DEVICE)\n",
    "                tgat_model_for_embeddings_stage2.load_state_dict(torch.load(best_tgat_model_path, map_location=DEVICE))\n",
    "                tgat_model_for_embeddings_stage2.eval()\n",
    "\n",
    "                # 2. Generate event embeddings\n",
    "                train_data_cpu_seq, _, _, _ = load_processed_data(PROCESSED_TRAIN_FILE, METADATA_FILE, CLASSIFICATION_MODE)\n",
    "                test_data_cpu_seq, _, _, _ = load_processed_data(PROCESSED_TEST_FILE, METADATA_FILE, CLASSIFICATION_MODE)\n",
    "\n",
    "                # Ensure event labels are binary for sequence task\n",
    "                train_event_embeddings, train_event_labels_for_seq = get_all_event_embeddings(\n",
    "                    tgat_model_for_embeddings_stage2, train_data_cpu_seq, BATCH_SIZE_SEQ_EMBED_GEN, NUM_NEIGHBORS, DEVICE\n",
    "                )\n",
    "                test_event_embeddings, test_event_labels_for_seq = get_all_event_embeddings(\n",
    "                    tgat_model_for_embeddings_stage2, test_data_cpu_seq, BATCH_SIZE_SEQ_EMBED_GEN, NUM_NEIGHBORS, DEVICE\n",
    "                )\n",
    "\n",
    "                if train_event_embeddings.numel() == 0:\n",
    "                    print(\"Failed to generate train event embeddings. Skipping sequence model training.\")\n",
    "                else:\n",
    "                    # Squeeze labels if they are (N,1) to (N) and ensure they are binary\n",
    "                    train_event_labels_binary_squeezed = (train_event_labels_for_seq.squeeze() > 0).long() if CLASSIFICATION_MODE == 'multiclass' else train_event_labels_for_seq.squeeze().long()\n",
    "                    test_event_labels_binary_squeezed = (test_event_labels_for_seq.squeeze() > 0).long() if CLASSIFICATION_MODE == 'multiclass' else test_event_labels_for_seq.squeeze().long()\n",
    "\n",
    "\n",
    "                    # 3. Create sequences\n",
    "                    train_seq_labels_list, train_padded_sequences, train_seq_lengths = create_embedding_sequences(\n",
    "                        train_event_embeddings, train_event_labels_binary_squeezed, \n",
    "                        SEQUENCE_LENGTH, STEP_SIZE, SEQ_LABEL_MODE, 'binary'\n",
    "                    )\n",
    "                    test_seq_labels_list, test_padded_sequences, test_seq_lengths = create_embedding_sequences(\n",
    "                        test_event_embeddings, test_event_labels_binary_squeezed, \n",
    "                        SEQUENCE_LENGTH, STEP_SIZE, SEQ_LABEL_MODE, 'binary'\n",
    "                    )\n",
    "\n",
    "                    if train_padded_sequences.numel() == 0:\n",
    "                        print(\"No training sequences generated. Skipping sequence model training.\")\n",
    "                    else:\n",
    "                        train_sequence_dataset = EmbeddingSequenceDataset(train_padded_sequences, train_seq_labels_list, train_seq_lengths)\n",
    "                        train_sequence_loader = DataLoader(train_sequence_dataset, batch_size=BATCH_SIZE_SEQ_MODEL, shuffle=True, collate_fn=collate_fn_packed_fixed_length)\n",
    "                        \n",
    "                        test_sequence_dataset = None\n",
    "                        test_sequence_loader = None\n",
    "                        if test_padded_sequences.numel() > 0:\n",
    "                            test_sequence_dataset = EmbeddingSequenceDataset(test_padded_sequences, test_seq_labels_list, test_seq_lengths)\n",
    "                            test_sequence_loader = DataLoader(test_sequence_dataset, batch_size=BATCH_SIZE_SEQ_MODEL, shuffle=False, collate_fn=collate_fn_packed_fixed_length)\n",
    "                        else:\n",
    "                            print(\"No test sequences generated for evaluation of sequence model.\")\n",
    "\n",
    "                        # 4. Define and train sequence model\n",
    "                        seq_model_input_dim = train_event_embeddings.shape[1] # Should match SEQ_MODEL_EMBEDDING_DIM_ACTUAL\n",
    "                        \n",
    "                        sequence_model = EventSequenceAggregator(\n",
    "                            embedding_dim=seq_model_input_dim,\n",
    "                            hidden_dim=SEQ_MODEL_HIDDEN_DIM,\n",
    "                            num_layers=SEQ_MODEL_NUM_LAYERS,\n",
    "                            num_classes=1, # Binary sequence classification\n",
    "                            dropout=SEQ_MODEL_DROPOUT,\n",
    "                            rnn_type=SEQ_MODEL_RNN_TYPE\n",
    "                        ).to(DEVICE)\n",
    "\n",
    "                        criterion_seq = nn.BCEWithLogitsLoss() # Add pos_weight if needed based on train_seq_labels_list balance\n",
    "                        optimizer_seq = optim.Adam(sequence_model.parameters(), lr=LEARNING_RATE_SEQ_MODEL)\n",
    "\n",
    "                        print(f\"\\n--- Training Sequence Aggregator Model ({SEQ_MODEL_RNN_TYPE}) ---\")\n",
    "                        print(f\"Input Embedding Dim: {seq_model_input_dim}, Sequence Length: {SEQUENCE_LENGTH}, Step: {STEP_SIZE}\")\n",
    "                        print(f\"Sequence Model: Hidden={SEQ_MODEL_HIDDEN_DIM}, Layers={SEQ_MODEL_NUM_LAYERS}, Dropout={SEQ_MODEL_DROPOUT}\")\n",
    "                        print(f\"Optimizer: Adam, LR={LEARNING_RATE_SEQ_MODEL}. Epochs: {EPOCHS_SEQ_MODEL}\")\n",
    "\n",
    "                        history_seq_agg = {'train_loss': [], 'train_acc': [], 'train_f1': [], \n",
    "                                           'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_auc': []}\n",
    "\n",
    "                        for epoch_seq in range(EPOCHS_SEQ_MODEL):\n",
    "                            print(f\"Sequence Model Epoch {epoch_seq+1}/{EPOCHS_SEQ_MODEL}\")\n",
    "                            train_loss_s, train_acc_s, _, _, train_f1_s = train_sequence_epoch(\n",
    "                                sequence_model, train_sequence_loader, optimizer_seq, criterion_seq, DEVICE\n",
    "                            )\n",
    "                            history_seq_agg['train_loss'].append(train_loss_s)\n",
    "                            history_seq_agg['train_acc'].append(train_acc_s)\n",
    "                            history_seq_agg['train_f1'].append(train_f1_s)\n",
    "                            print(f\"  Seq Train: Loss={train_loss_s:.4f}, Acc={train_acc_s:.4f}, F1={train_f1_s:.4f}\")\n",
    "\n",
    "                            if test_sequence_loader:\n",
    "                                val_loss_s, val_acc_s, _, _, val_f1_s, val_auc_s, _, _ = evaluate_sequence_model(\n",
    "                                    sequence_model, test_sequence_loader, criterion_seq, DEVICE, phase=\"Val Seq Agg\"\n",
    "                                )\n",
    "                                history_seq_agg['val_loss'].append(val_loss_s)\n",
    "                                history_seq_agg['val_acc'].append(val_acc_s)\n",
    "                                history_seq_agg['val_f1'].append(val_f1_s)\n",
    "                                history_seq_agg['val_auc'].append(val_auc_s if val_auc_s is not None else np.nan)\n",
    "                                # ** CORRECTED PRINT STATEMENT for Seq Val ** (這是您需要替換或插入的部分)\n",
    "                                val_loss_s_str = f\"{val_loss_s:.4f}\" if val_loss_s is not None and not np.isnan(val_loss_s) else \"N/A\" # [cite: 483]\n",
    "                                val_acc_s_str = f\"{val_acc_s:.4f}\" if val_acc_s is not None and not np.isnan(val_acc_s) else \"N/A\" # [cite: 483]\n",
    "                                val_f1_s_str = f\"{val_f1_s:.4f}\" if val_f1_s is not None and not np.isnan(val_f1_s) else \"N/A\" # [cite: 478]\n",
    "                                val_auc_s_str = f\"{val_auc_s:.4f}\" if val_auc_s is not None and not np.isnan(val_auc_s) else \"N/A\" # [cite: 478]\n",
    "                                print(f\"  Seq Val:   Loss={val_loss_s_str}, Acc={val_acc_s_str}, F1={val_f1_s_str}, AUC={val_auc_s_str}\") # [cite: 478]\n",
    "                            else: # No test data for sequence model\n",
    "                                for k_val_s in ['val_loss', 'val_acc', 'val_f1', 'val_auc']: history_seq_agg[k_val_s].append(float('nan'))\n",
    "                        \n",
    "                        print(\"--- Sequence Aggregator Training Finished ---\")\n",
    "\n",
    "                        # Plot sequence model training history\n",
    "                        fig_seq, axs_seq = plt.subplots(1, 3, figsize=(18, 5)) # Loss, Acc, F1\n",
    "                        plot_metrics_seq_map = [('Loss', 'loss'), ('Accuracy', 'acc'), ('F1-score', 'f1')]\n",
    "                        for i_seq, (title_s, key_metric_s) in enumerate(plot_metrics_seq_map):\n",
    "                            ax_s_current = axs_seq[i_seq]\n",
    "                            train_values_s = [v for v in history_seq_agg.get(f'train_{key_metric_s}', []) if v is not None and not np.isnan(v)]\n",
    "                            val_values_s = [v for v in history_seq_agg.get(f'val_{key_metric_s}', []) if v is not None and not np.isnan(v)]\n",
    "                            epochs_train_s = [j for j,v in enumerate(history_seq_agg.get(f'train_{key_metric_s}', [])) if v is not None and not np.isnan(v)]\n",
    "                            epochs_val_s = [j for j,v in enumerate(history_seq_agg.get(f'val_{key_metric_s}', [])) if v is not None and not np.isnan(v)]\n",
    "\n",
    "                            if epochs_train_s and train_values_s: ax_s_current.plot(epochs_train_s, train_values_s, label=f'Seq Train {title_s}')\n",
    "                            if epochs_val_s and val_values_s: ax_s_current.plot(epochs_val_s, val_values_s, label=f'Seq Validation {title_s}')\n",
    "                            ax_s_current.set_title(f'Sequence Agg. {title_s}'); ax_s_current.set_xlabel('Epoch'); ax_s_current.set_ylabel(title_s); ax_s_current.legend()\n",
    "                        plt.tight_layout(); plt.show()\n",
    "\n",
    "                        # Final evaluation of sequence model on test sequences\n",
    "                        if test_sequence_loader:\n",
    "                            print(\"\\n--- Final Evaluation of Sequence Aggregator Model on Test Sequences ---\")\n",
    "                            _, _, _, _, _, _, final_seq_true, final_seq_pred = evaluate_sequence_model(\n",
    "                                sequence_model, test_sequence_loader, criterion_seq, DEVICE, phase=\"Final Test Seq Agg\"\n",
    "                            )\n",
    "                            if final_seq_true and final_seq_pred:\n",
    "                                plot_confusion_matrix_custom(final_seq_true, final_seq_pred, class_names=['Normal Seq', 'Attack Seq'], title='Final Sequence Aggregator Confusion Matrix')\n",
    "            else:\n",
    "                print(f\"Best TGAT model file not found at: {best_tgat_model_path}. Skipping TGAT final evaluation and Stage 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974786e-9773-4ec4-9c25-5e2b7338c121",
   "metadata": {},
   "source": [
    "## 10. How to Run & Notes\n",
    "- **Ensure Preprocessing is Done**: Run `preprocess_kdd_large.ipynb` first.\n",
    "- **Adjust Configuration**: Check paths and hyperparameters in Cell 2.\n",
    "- **Run All Cells**: This will train, evaluate, save the best model, and plot metrics.\n",
    "- **Memory for `TemporalNeighborLoader`**:\n",
    "    - The current loader sends the *entire* graph's features (`self.temporal_data.x`) and timestamps (`self.temporal_data.ts`) to the specified `device` *for each batch*.\n",
    "    - **If `self.temporal_data.x` (all node features for the entire dataset) is too large to fit on the GPU, this will cause an Out-Of-Memory (OOM) error.**\n",
    "    - **For truly massive graphs**: The loader and model interaction need modification. For example, keep full data on CPU, loader passes indices, model fetches only necessary data slices to GPU. This is a more advanced optimization not implemented here but crucial for >GPU memory graphs. This script currently assumes the full feature/timestamp tensors fit on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11633d-ae85-419c-93bf-781961fca663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
