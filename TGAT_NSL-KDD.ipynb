{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab0191a-67d9-4176-b81d-9034aa0f6b74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt25cu118)\n",
      "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt25cu118)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2020.6.20)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: numpy==1.26.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: matplotlib==3.7.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.7.3)\n",
      "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: dask==2025.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2025.5.1)\n",
      "Requirement already satisfied: scipy==1.11.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.11.2)\n",
      "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl==3.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.2.0)\n",
      "Requirement already satisfied: pyarrow==15.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (15.0.2)\n",
      "Collecting setuptools==80.8.0 (from -r requirements.txt (line 18))\n",
      "  Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel==0.45.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.45.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2020.6.20)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (2023.6.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2025.5.1->-r requirements.txt (line 11)) (3.22.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask==2025.5.1->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Using cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: setuptools 80.9.0\n",
      "    Uninstalling setuptools-80.9.0:\n",
      "      Successfully uninstalled setuptools-80.9.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed setuptools-80.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 1. å®‰è£ PyTorch Geometric æ“´å±•å¥—ä»¶\n",
    "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
    "    -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
    "\n",
    "# 2. å®‰è£ PyTorch Geometric ä¸»å¥—ä»¶\n",
    "!pip install torch_geometric\n",
    "\n",
    "# 3. å®‰è£å…¶ä»–ä¾è³´ï¼ˆä½¿ç”¨ç°¡åŒ–ç‰ˆ requirements.txtï¼‰\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e56a1a0-a09e-47a2-ad16-4bab9350d410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ­£åœ¨é©—è­‰ PyTorch Geometric å®‰è£...\n",
      "==================================================\n",
      "âœ… PyTorch: 2.5.1+cu118\n",
      "âœ… CUDA å¯ç”¨: True\n",
      "âœ… CUDA ç‰ˆæœ¬: 11.8\n",
      "âœ… GPU è¨­å‚™æ•¸é‡: 1\n",
      "âœ… torch_scatter: å·²å®‰è£\n",
      "âœ… torch_sparse: å·²å®‰è£\n",
      "âœ… torch_cluster: å·²å®‰è£\n",
      "âœ… torch_spline_conv: å·²å®‰è£\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… torch_geometric: 2.6.1\n",
      "âœ… åŸºæœ¬åœ–ç¥ç¶“ç¶²è·¯æ¸¬è©¦: æˆåŠŸ\n",
      "   è¼¸å…¥ç¶­åº¦: torch.Size([3, 1])\n",
      "   è¼¸å‡ºç¶­åº¦: torch.Size([3, 2])\n",
      "âœ… pandas: 2.2.0\n",
      "âœ… numpy: 1.26.3\n",
      "âœ… matplotlib: å·²å®‰è£\n",
      "âœ… seaborn: 0.12.2\n",
      "âœ… scikit-learn: å·²å®‰è£\n",
      "==================================================\n",
      "ğŸ‰ æ‰€æœ‰å¥—ä»¶å®‰è£æˆåŠŸï¼æº–å‚™é–‹å§‹ä½ çš„åœ–ç¥ç¶“ç¶²è·¯å°ˆæ¡ˆï¼\n",
      "\n",
      "ğŸ“š æ¥ä¸‹ä¾†ä½ å¯ä»¥ï¼š\n",
      "1. é–‹å§‹å»ºç«‹ä½ çš„åœ–ç¥ç¶“ç¶²è·¯æ¨¡å‹\n",
      "2. è¼‰å…¥åœ–æ•¸æ“šé›†\n",
      "3. é€²è¡Œåœ–åˆ†æå’Œè¦–è¦ºåŒ–\n",
      "4. è¨“ç·´å’Œè©•ä¼°æ¨¡å‹\n"
     ]
    }
   ],
   "source": [
    "# â•â•â• PyTorch Geometric å®‰è£é©—è­‰ â•â•â•\n",
    "\n",
    "print(\"ğŸ” æ­£åœ¨é©—è­‰ PyTorch Geometric å®‰è£...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # 1. æª¢æŸ¥ PyTorch\n",
    "    import torch\n",
    "    print(f\"âœ… PyTorch: {torch.__version__}\")\n",
    "    print(f\"âœ… CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ… CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "        print(f\"âœ… GPU è¨­å‚™æ•¸é‡: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # 2. æª¢æŸ¥ PyTorch Geometric æ“´å±•\n",
    "    import torch_scatter\n",
    "    import torch_sparse  \n",
    "    import torch_cluster\n",
    "    import torch_spline_conv\n",
    "    print(f\"âœ… torch_scatter: å·²å®‰è£\")\n",
    "    print(f\"âœ… torch_sparse: å·²å®‰è£\") \n",
    "    print(f\"âœ… torch_cluster: å·²å®‰è£\")\n",
    "    print(f\"âœ… torch_spline_conv: å·²å®‰è£\")\n",
    "    \n",
    "    # 3. æª¢æŸ¥ PyTorch Geometric ä¸»å¥—ä»¶\n",
    "    import torch_geometric\n",
    "    print(f\"âœ… torch_geometric: {torch_geometric.__version__}\")\n",
    "    \n",
    "    # 4. æ¸¬è©¦åŸºæœ¬åŠŸèƒ½\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    \n",
    "    # å‰µå»ºç°¡å–®çš„åœ–æ•¸æ“š\n",
    "    edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                              [1, 0, 2, 1]], dtype=torch.long)\n",
    "    x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    \n",
    "    # å‰µå»ºç°¡å–®çš„ GCN å±¤\n",
    "    conv = GCNConv(1, 2)\n",
    "    out = conv(data.x, data.edge_index)\n",
    "    \n",
    "    print(f\"âœ… åŸºæœ¬åœ–ç¥ç¶“ç¶²è·¯æ¸¬è©¦: æˆåŠŸ\")\n",
    "    print(f\"   è¼¸å…¥ç¶­åº¦: {data.x.shape}\")\n",
    "    print(f\"   è¼¸å‡ºç¶­åº¦: {out.shape}\")\n",
    "    \n",
    "    # 5. æª¢æŸ¥æ•¸æ“šåˆ†æå¥—ä»¶\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    print(f\"âœ… pandas: {pd.__version__}\")\n",
    "    print(f\"âœ… numpy: {np.__version__}\")\n",
    "    print(f\"âœ… matplotlib: å·²å®‰è£\")\n",
    "    print(f\"âœ… seaborn: {sns.__version__}\")\n",
    "    print(f\"âœ… scikit-learn: å·²å®‰è£\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ‰ æ‰€æœ‰å¥—ä»¶å®‰è£æˆåŠŸï¼æº–å‚™é–‹å§‹ä½ çš„åœ–ç¥ç¶“ç¶²è·¯å°ˆæ¡ˆï¼\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å°å…¥éŒ¯èª¤: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¸¬è©¦éŒ¯èª¤: {e}\")\n",
    "\n",
    "print(\"\\nğŸ“š æ¥ä¸‹ä¾†ä½ å¯ä»¥ï¼š\")\n",
    "print(\"1. é–‹å§‹å»ºç«‹ä½ çš„åœ–ç¥ç¶“ç¶²è·¯æ¨¡å‹\")\n",
    "print(\"2. è¼‰å…¥åœ–æ•¸æ“šé›†\") \n",
    "print(\"3. é€²è¡Œåœ–åˆ†æå’Œè¦–è¦ºåŒ–\")\n",
    "print(\"4. è¨“ç·´å’Œè©•ä¼°æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d24db-34d0-4aa4-ac22-dc006beb9029",
   "metadata": {},
   "source": [
    "# preprocess_kdd_large.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083bb8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /usr/local/bin/python3\n",
      "Torch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "torch_geometric version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import sys\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"torch_geometric version:\", torch_geometric.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85382bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Preprocessing for Large Datasets\n",
    "This notebook handles the preprocessing of KDD-like datasets, optimized for larger files using Dask.\n",
    "It performs the following steps:\n",
    "1. Loads raw data in chunks.\n",
    "2. Defines column names and types.\n",
    "3. Preprocesses labels (binary and multi-class).\n",
    "4. Preprocesses features:\n",
    "   - One-hot encodes categorical features using Dask's `get_dummies`.\n",
    "   - Scales numerical features using Dask's mean/std.\n",
    "5. Constructs temporal graph components (node features `x`, edge indices `edge_index`, timestamps `ts`).\n",
    "6. Saves the processed data and metadata for the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018adbb",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ee8550",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.8.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 80.8.0\n",
      "    Uninstalling setuptools-80.8.0:\n",
      "      Successfully uninstalled setuptools-80.8.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed setuptools-80.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing PyG dependencies for Torch 2.5.1 and CUDA cu118...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt25cu118)\n",
      "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt25cu118)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing pyg-lib for Torch 2.5.1 and CUDA cu118...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
      "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt25cu118)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch_geometric==2.6.1 in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric==2.6.1) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric==2.6.1) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric==2.6.1) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric==2.6.1) (2020.6.20)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch-geometric-temporal==0.56.0 in /usr/local/lib/python3.11/dist-packages (0.56.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (4.4.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.5.1+cu118)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.0.2)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (1.26.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-geometric-temporal==0.56.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-geometric-temporal==0.56.0) (2.1.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (3.9.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2020.6.20)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse->torch-geometric-temporal==0.56.0) (1.11.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2025.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask) (3.22.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# --- Environment Setup ---\n",
    "# Make sure torch is installed first if not already\n",
    "# %pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install PyTorch Geometric core dependencies (adjust torch version and cuda suffix as needed)\n",
    "TORCH_VERSION = torch.__version__.split('+')[0] # Get base torch version\n",
    "CUDA_VERSION = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "CUDA_SUFFIX = f'cu{CUDA_VERSION}' if CUDA_VERSION != 'cpu' else 'cpu'\n",
    "print(f\"Installing PyG dependencies for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "\n",
    "# --- Install pyg-lib for potential speedup (addresses warning) ---\n",
    "print(f\"Installing pyg-lib for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install pyg_lib -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "%pip install \"torch_geometric==2.6.1\"\n",
    "%pip install \"torch-geometric-temporal==0.56.0\"\n",
    "\n",
    "# Other necessary libraries\n",
    "%pip install pandas numpy scikit-learn matplotlib seaborn tqdm requests dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afa06a-fc1d-4f50-9c81-ae6614625cac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 2: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebf4cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = './data/' # ç¢ºä¿æ‚¨çš„ NSL-KDD æ–‡ä»¶åœ¨æ­¤ç›®éŒ„ä¸­\n",
    "# æ›´æ–°ç‚ºæ‚¨ NSL-KDD æ–‡ä»¶çš„ç¢ºåˆ‡åç¨±\n",
    "TRAIN_FILE = 'KDDTrain+.txt' # NSL-KDD è¨“ç·´æ–‡ä»¶å (è«‹ç¢ºèªæ­¤æ–‡ä»¶åèˆ‡æ‚¨ä¸‹è¼‰çš„ä¸€è‡´)\n",
    "TEST_FILE = 'KDDTest+.txt'   # NSL-KDD æ¸¬è©¦æ–‡ä»¶å (æˆ– 'KDDTest-21.txt', è«‹ç¢ºèª)\n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_nslkdd/' # æ›´æ”¹ä»¥é¿å…è¦†è“‹ KDD99 è™•ç†çš„æ•¸æ“š\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data_nslkdd.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data_nslkdd.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata_nslkdd.json')\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "RECENCY_BIAS_FACTOR = 0.9\n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = 128\n",
    "SEQUENCE_LENGTH = 15\n",
    "STEP_SIZE = 5\n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64\n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 30\n",
    "SEQ_MODEL_EMBEDDING_DIM = HIDDEN_DIM\n",
    "SEQ_MODEL_HIDDEN_DIM = 128\n",
    "SEQ_MODEL_NUM_LAYERS = 2\n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'\n",
    "SEQ_MODEL_DROPOUT = 0.3\n",
    "\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score'\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = ['protocol_type', 'service', 'flag']\n",
    "NUMERICAL_COLS = [col for col in COL_NAMES if col not in CATEGORICAL_COLS + ['attack_type', 'difficulty_score']]\n",
    "LABEL_COL = 'attack_type'\n",
    "NORMAL_TAG = 'normal'\n",
    "\n",
    "ATTACK_MAP_MULTI_CLASS = {\n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos',\n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe',\n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l',\n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r'\n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5b30e",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171476e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Label Preprocessing Function\n",
    "def preprocess_labels_event_node_dask(df_chunk: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Preprocesses labels for a chunk of data (Pandas DataFrame). \"\"\"\n",
    "    df_chunk['label_binary'] = df_chunk[LABEL_COL].apply(lambda x: 0 if x == NORMAL_TAG else 1)\n",
    "    \n",
    "    def map_to_general_cat_id(attack_name):\n",
    "        if attack_name == NORMAL_TAG:\n",
    "            return ATTACK_MAP_MULTI_CLASS[NORMAL_TAG]\n",
    "        general_category = KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP.get(attack_name)\n",
    "        if general_category:\n",
    "            return ATTACK_MAP_MULTI_CLASS.get(general_category, UNKNOWN_ATTACK_CATEGORY_ID)\n",
    "        return UNKNOWN_ATTACK_CATEGORY_ID\n",
    "\n",
    "    df_chunk['label_multiclass_id'] = df_chunk[LABEL_COL].apply(map_to_general_cat_id)\n",
    "    return df_chunk[['label_binary', 'label_multiclass_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "custom_loader_cell",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Feature Scaler Fitting and Category Info (Minor refinement in comment/consistency)\n",
    "def fit_scalers_and_get_categories_info(ddf: dd.DataFrame, numerical_cols: list, categorical_cols: list):\n",
    "    \"\"\"\n",
    "    Computes means/stds for numerical columns and gets categorical feature names after one-hot encoding.\n",
    "    Assumes ddf[numerical_cols] contains numeric data and ddf[categorical_cols] has been categorized.\n",
    "    \"\"\"\n",
    "    print(\"Fitting scalers and determining categorical feature names...\")\n",
    "    # Numerical part remains the same\n",
    "    computed_means = ddf[numerical_cols].mean().compute()\n",
    "    computed_stds = ddf[numerical_cols].std().compute()\n",
    "    computed_stds = computed_stds.where(computed_stds != 0, 1.0) \n",
    "\n",
    "    # Categorical part: ddf[categorical_cols] should already have 'category' dtype with known categories\n",
    "    # from the .categorize() call in the main preprocessing function.\n",
    "    # So, ddf_cat_casted is essentially ddf[categorical_cols]\n",
    "    ddf_cat_subset = ddf[categorical_cols] \n",
    "    \n",
    "    # Get schema of dummy columns from a small sample for consistency.\n",
    "    # Since categories are known, head(1) or head(2) should be sufficient for schema.\n",
    "    # Compute=True is needed as head() is lazy.\n",
    "    sample_for_schema = ddf_cat_subset.head(max(2, ddf_cat_subset.npartitions if ddf_cat_subset.npartitions > 0 else 2), compute=True) \n",
    "    if sample_for_schema.empty and not ddf_cat_subset.known_divisions: # If dataframe is empty or structure is unknown after categorize\n",
    "        print(\"Warning: Categorical subset for dummy schema is empty or has unknown divisions. Using predefined columns for schema.\")\n",
    "        # Fallback to creating an empty DataFrame with expected columns if sample is problematic\n",
    "        # This might happen if the initial ddf was empty.\n",
    "        # This part might need more robust handling depending on how empty Dask DFs behave with categorize\n",
    "        categorical_feature_names_fitted = [] # Or load from a predefined schema if truly empty\n",
    "        if not ddf[categorical_cols].head(1).empty: # try again just in case.\n",
    "            dummy_ddf_schema = dd.get_dummies(ddf[categorical_cols].head(1), columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "            categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "\n",
    "    elif not sample_for_schema.empty:\n",
    "         dummy_ddf_schema = pd.get_dummies(sample_for_schema, columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "         categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "    else: # Fallback if sample_for_schema is empty but ddf_cat_subset was not entirely empty\n",
    "        print(\"Warning: Could not reliably determine dummy schema from sample. Categorical feature names might be incomplete.\")\n",
    "        categorical_feature_names_fitted = [f\"{col}_{cat}\" for col in categorical_cols for cat in ddf_cat_subset[col].cat.categories]\n",
    "\n",
    "\n",
    "    print(f\"Scalers determined. Categorical feature names derived: {len(categorical_feature_names_fitted)} features.\")\n",
    "    return computed_means, computed_stds, categorical_feature_names_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab3fa3-da28-43c8-88b8-3e7c552b743c",
   "metadata": {},
   "source": [
    "## 6. Main Preprocessing Orchestration (Function Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562b4365-33ba-4ffc-bb1f-b38cf41c5520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6 â€” Main Preprocessing Logic Function (FINAL)\n",
    "def preprocess_and_save_temporal_data(\n",
    "    raw_file_path: str,\n",
    "    output_file_path: str,\n",
    "    numerical_cols_original_config: list,\n",
    "    categorical_cols: list,\n",
    "    label_col: str,\n",
    "    is_training_set: bool = False,\n",
    "    fitted_scalers_and_cats_info: dict = None,\n",
    "    recent_window_size: int = 50\n",
    "):\n",
    "    \"\"\"Reads, preprocesses, engineers features, builds a temporal graph and saves tensors.\"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # 0. è®€å…¥èˆ‡åŸºæœ¬å‹åˆ¥è½‰æ›ï¼ˆèˆ‡åŸé‚è¼¯ç›¸åŒï¼‰ ----------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    print(f\"Starting preprocessing for: {raw_file_path}\")\n",
    "    current_numerical_cols = list(numerical_cols_original_config)\n",
    "    dtype_initial_read = {col: \"object\" for col in COL_NAMES}\n",
    "\n",
    "    try:\n",
    "        ddf = dd.read_csv(\n",
    "            raw_file_path,\n",
    "            header=None,\n",
    "            names=COL_NAMES,\n",
    "            dtype=dtype_initial_read,\n",
    "            blocksize=\"256MB\",\n",
    "            usecols=COL_NAMES,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Dask read_csv error: {e}.  Falling back to pandas chunks.\")\n",
    "        chunks = [\n",
    "            chunk_pd\n",
    "            for chunk_pd in pd.read_csv(\n",
    "                raw_file_path,\n",
    "                header=None,\n",
    "                names=COL_NAMES,\n",
    "                chunksize=100_000,\n",
    "                dtype=str,\n",
    "                low_memory=False,\n",
    "                usecols=COL_NAMES,\n",
    "            )\n",
    "        ]\n",
    "        if not chunks:\n",
    "            raise ValueError(f\"Pandas fallback failed: no data read from {raw_file_path}\")\n",
    "        ddf = dd.from_pandas(pd.concat(chunks, ignore_index=True),\n",
    "                             npartitions=max(1, int(np.ceil(len(chunks[0]) / 500_000))))\n",
    "        print(f\"Pandas fallback succeeded.  npartitions={ddf.npartitions}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. æ•¸å€¼æ¬„ä½è½‰ float / timestamp æ¬„å»ºç«‹ ---------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    for col in numerical_cols_original_config:\n",
    "        if col in ddf.columns:\n",
    "            ddf[col] = dd.to_numeric(ddf[col], errors=\"coerce\").fillna(0)\n",
    "        else:\n",
    "            print(f\"Warning: numerical column '{col}' not found.\")\n",
    "\n",
    "    if \"temp_event_timestamp\" not in ddf.columns:\n",
    "        ddf[\"temp_event_timestamp\"] = ddf.index.astype(np.int64)\n",
    "    else:\n",
    "        ddf[\"temp_event_timestamp\"] = (\n",
    "            dd.to_numeric(ddf[\"temp_event_timestamp\"], errors=\"coerce\")\n",
    "            .fillna(0)\n",
    "            .astype(np.int64)\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. é‡è¨­ç´¢å¼•ã€åˆ†é¡æ¬„å‹åˆ¥ã€ç‰¹å¾µå·¥ç¨‹ï¼ˆåŸç¨‹å¼ç¢¼ç„¡è®Šå‹•ï¼Œç…§è²¼ï¼‰ ----------\n",
    "    # ------------------------------------------------------------------\n",
    "    #   â€¦â€¦  <å‰åŠæ®µç¨‹å¼ç¢¼å®Œå…¨èˆ‡ä½ åŸç‰ˆæœ¬ä¸€è‡´ï¼Œæ­¤è™•ç‚ºçœç•¥æ¨™è¨˜>  â€¦â€¦\n",
    "\n",
    "    # â˜…â˜…â˜… ç›´åˆ°æœ€å¾Œä¸€è¡Œ x_np ç”Ÿæˆã€y_binary_np / y_multiclass_np æº–å‚™å®Œç•¢ç‚ºæ­¢ â˜…â˜…â˜…\n",
    "    # ------------------------------------------------------------------\n",
    "    # ä»¥ä¸‹ç‚º **æ–°å¢/ä¿®æ”¹** å€åŸŸ\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # ---------------- Labels numpy â†’ y_binary_np / y_multiclass_np å·²å°±ç·’ ----------------\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. å»ºç«‹ edge_index èˆ‡æ™‚é–“æˆ³ ts_tensor -----------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    num_original_rows = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "    \n",
    "    if \"service\" in ddf.columns:\n",
    "        src_ids_np = np.arange(num_original_rows, dtype=np.int64)\n",
    "        dst_ids_np = LabelEncoder().fit_transform(ddf[\"service\"].compute())\n",
    "    else:\n",
    "        print(\"Warning: 'service' column missing, fallback to star-graph.\")\n",
    "        src_ids_np = np.arange(num_original_rows, dtype=np.int64)\n",
    "        dst_ids_np = np.zeros(num_original_rows, dtype=np.int64)\n",
    "\n",
    "    edge_index_tensor = torch.tensor(\n",
    "        np.vstack([src_ids_np, dst_ids_np]), dtype=torch.long\n",
    "    )\n",
    "\n",
    "    if \"temp_event_timestamp\" in ddf.columns:\n",
    "        ts_np = ddf[\"temp_event_timestamp\"].compute().to_numpy(dtype=np.float32)\n",
    "    else:\n",
    "        ts_np = np.arange(num_original_rows, dtype=np.float32)\n",
    "    ts_tensor = torch.from_numpy(ts_np).float()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. è½‰ç‚º torch.Tensor ä¸¦å„²å­˜ --------------------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    x_tensor = torch.from_numpy(x_np).float()\n",
    "    y_binary_tensor = (\n",
    "        torch.from_numpy(y_binary_np).float().unsqueeze(1)\n",
    "        if len(y_binary_np)\n",
    "        else torch.empty((0, 1)).float()\n",
    "    )\n",
    "    y_multiclass_tensor = (\n",
    "        torch.from_numpy(y_multiclass_np).long()\n",
    "        if len(y_multiclass_np)\n",
    "        else torch.empty(0).long()\n",
    "    )\n",
    "\n",
    "    data_to_save = dict(\n",
    "        x=x_tensor,\n",
    "        edge_index=edge_index_tensor,\n",
    "        ts=ts_tensor,\n",
    "        y_binary=y_binary_tensor,\n",
    "        y_multiclass=y_multiclass_tensor,\n",
    "        num_nodes=num_original_rows,\n",
    "    )\n",
    "    torch.save(data_to_save, output_file_path)\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5. Metadataï¼ˆå« pos_weight_binaryï¼Œæ‰€æœ‰é›†åˆéƒ½å¯«ï¼‰ -------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    if len(y_binary_np):\n",
    "        pos_cnt = int(np.sum(y_binary_np))\n",
    "        neg_cnt = len(y_binary_np) - pos_cnt\n",
    "        pos_weight_binary = neg_cnt / (pos_cnt + 1e-7) if 0 < pos_cnt < len(y_binary_np) else 1.0\n",
    "    else:\n",
    "        pos_weight_binary = 1.0\n",
    "\n",
    "    current_set_metadata = dict(\n",
    "        node_feat_dim=node_feat_dim,\n",
    "        num_nodes=num_original_rows,\n",
    "        labels_binary_unique_count=len(np.unique(y_binary_np)) if len(y_binary_np) else 0,\n",
    "        labels_multiclass_unique_count=len(np.unique(y_multiclass_np)) if len(y_multiclass_np) else 0,\n",
    "        engineered_feature_cols=newly_engineered_feature_cols,\n",
    "        pos_weight_binary=pos_weight_binary,          # â˜… æ–°å¢ï¼šä¸€å¾‹å¯«å…¥\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6. å›å‚³ scaler / category è³‡è¨Šï¼ˆç¶­æŒåŸè¡Œç‚ºï¼‰ -----------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    return current_set_metadata, scaler_params_to_return_or_use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49628f-5666-47cd-bc29-0d3933214633",
   "metadata": {},
   "source": [
    "## 7. Execute Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25eb960d-6302-4bb5-afda-e09ce17923a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preprocessing Pipeline for NSL-KDD ---\n",
      "âœ… Found NSL-KDD training file: ./data/KDDTrain+.txt\n",
      "âœ… Found NSL-KDD test file: ./data/KDDTest+.txt\n",
      "All raw NSL-KDD files found.\n",
      "â†ª Detected missing processed files â€“ running preprocessingâ€¦\n",
      "Starting preprocessing for: ./data/KDDTrain+.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ†ª Detected missing processed files â€“ running preprocessingâ€¦\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ---------------- Training set ----------------\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m train_set_metadata, fitted_scalers_and_categories \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_save_temporal_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_raw_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROCESSED_TRAIN_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumerical_cols_original_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERICAL_COLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCATEGORICAL_COLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLABEL_COL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_training_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (train_set_metadata \u001b[38;5;129;01mand\u001b[39;00m fitted_scalers_and_categories):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data preprocessing failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 106\u001b[0m, in \u001b[0;36mpreprocess_and_save_temporal_data\u001b[0;34m(raw_file_path, output_file_path, numerical_cols_original_config, categorical_cols, label_col, is_training_set, fitted_scalers_and_cats_info, recent_window_size)\u001b[0m\n\u001b[1;32m    101\u001b[0m ts_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(ts_np)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# 4. è½‰ç‚º torch.Tensor ä¸¦å„²å­˜ --------------------------------------\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m x_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mx_np\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    107\u001b[0m y_binary_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_binary_np)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_binary_np)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m y_multiclass_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_multiclass_np)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_multiclass_np)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    116\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_np' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell: Main execution block  (FULL VERSION â€“ no lines omitted)\n",
    "\n",
    "import os, sys, json, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting Data Preprocessing Pipeline for NSL-KDD ---\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 0. æª¢æŸ¥ raw data ç›®éŒ„ï¼Œå¦‚ä¸å­˜åœ¨å‰‡å»ºç«‹\n",
    "    # ----------------------------------------------------------------------\n",
    "    if not os.path.exists(RAW_DATA_DIR):\n",
    "        os.makedirs(RAW_DATA_DIR)\n",
    "        print(f\"Created directory: {RAW_DATA_DIR}\")\n",
    "        print(\"This directory is for your raw NSL-KDD dataset files.\")\n",
    "\n",
    "    # é æœŸåŸå§‹æª”æ¡ˆè·¯å¾‘\n",
    "    train_raw_path = os.path.join(RAW_DATA_DIR, TRAIN_FILE)\n",
    "    test_raw_path  = os.path.join(RAW_DATA_DIR, TEST_FILE)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "    # ----------------------------------------------------------------------\n",
    "    files_missing = False\n",
    "    if not os.path.exists(train_raw_path):\n",
    "        print(f\"âŒ ERROR: Training file '{TRAIN_FILE}' not found in '{os.path.abspath(RAW_DATA_DIR)}'.\")\n",
    "        files_missing = True\n",
    "    else:\n",
    "        print(f\"âœ… Found NSL-KDD training file: {train_raw_path}\")\n",
    "\n",
    "    if not os.path.exists(test_raw_path):\n",
    "        print(f\"âŒ ERROR: Test file '{TEST_FILE}' not found in '{os.path.abspath(RAW_DATA_DIR)}'.\")\n",
    "        files_missing = True\n",
    "    else:\n",
    "        print(f\"âœ… Found NSL-KDD test file: {test_raw_path}\")\n",
    "\n",
    "    if files_missing:\n",
    "        # ------------------------------------------------------------------\n",
    "        # 1-a. è‹¥ç¼ºæª”ç›´æ¥åœï¼Œæç¤ºä¸‹è¼‰é€£çµ\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"\\nâ€¼ï¸ ACTION REQUIRED: Please download the NSL-KDD dataset files.\")\n",
    "        print(\"   1. GitHub: https://github.com/HoaNP/NSL-KDD-DataSet\")\n",
    "        print(\"   2. UNB CIC: https://www.unb.ca/cic/datasets/nsl.html\")\n",
    "        raise FileNotFoundError(f\"NSL-KDD files ('{TRAIN_FILE}', '{TEST_FILE}') not found in '{RAW_DATA_DIR}'.\")\n",
    "    else:\n",
    "        print(\"All raw NSL-KDD files found.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2. è‹¥å·²å­˜åœ¨ .pt/.json å‰‡è·³éï¼›å¦å‰‡è‡ªå‹•è·‘ preprocess\n",
    "    # ----------------------------------------------------------------------\n",
    "    if not (os.path.exists(PROCESSED_TRAIN_FILE) and\n",
    "            os.path.exists(PROCESSED_TEST_FILE)  and\n",
    "            os.path.exists(METADATA_FILE)):\n",
    "        print(\"â†ª Detected missing processed files â€“ running preprocessingâ€¦\")\n",
    "\n",
    "        # ---------------- Training set ----------------\n",
    "        train_set_metadata, fitted_scalers_and_categories = preprocess_and_save_temporal_data(\n",
    "            raw_file_path=train_raw_path,\n",
    "            output_file_path=PROCESSED_TRAIN_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col=LABEL_COL,\n",
    "            is_training_set=True\n",
    "        )\n",
    "\n",
    "        if not (train_set_metadata and fitted_scalers_and_categories):\n",
    "            raise RuntimeError(\"Training data preprocessing failed.\")\n",
    "\n",
    "        # ---------------- Test set ----------------\n",
    "        test_set_metadata, _ = preprocess_and_save_temporal_data(\n",
    "            raw_file_path=test_raw_path,\n",
    "            output_file_path=PROCESSED_TEST_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col=LABEL_COL,\n",
    "            is_training_set=False,\n",
    "            fitted_scalers_and_cats_info=fitted_scalers_and_categories\n",
    "        )\n",
    "\n",
    "        if not test_set_metadata:\n",
    "            raise RuntimeError(\"Test data preprocessing failed.\")\n",
    "\n",
    "        # ---------------- Save global metadata ----------------\n",
    "        global_metadata_to_save = {\n",
    "            'NODE_FEAT_DIM': train_set_metadata['node_feat_dim'],\n",
    "            'NUM_CLASSES_BINARY': 2,\n",
    "            'NUM_CLASSES_MULTI': (\n",
    "                len(ATTACK_MAP_MULTI_CLASS) +\n",
    "                (1 if UNKNOWN_ATTACK_CATEGORY_ID > max(ATTACK_MAP_MULTI_CLASS.values()) else 0)\n",
    "            ),\n",
    "            'POS_WEIGHT_BINARY': train_set_metadata.get('pos_weight_binary', 1.0),\n",
    "            'train_num_nodes': train_set_metadata['num_nodes'],\n",
    "            'test_num_nodes':  test_set_metadata['num_nodes'],\n",
    "            'categorical_feature_names': fitted_scalers_and_categories.get('categorical_feature_names', []),\n",
    "            'numerical_cols_list': fitted_scalers_and_categories.get('all_numerical_cols_scaled', NUMERICAL_COLS),\n",
    "            'engineered_feature_cols_list': train_set_metadata.get('engineered_feature_cols', [])\n",
    "        }\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(global_metadata_to_save, f, indent=4)\n",
    "        print(f\"Processed files & metadata saved to {PROCESSED_DATA_DIR}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Processed .pt/.json files already exist â€“ skip preprocessing.\")\n",
    "\n",
    "    print(\"--- Data Preprocessing Pipeline Finished ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21455837-2372-429b-9682-953c9e6cfc6b",
   "metadata": {},
   "source": [
    "## 8. Notes on Preprocessing\n",
    "- **Memory for `.compute()`**: The step `final_features_ddf.compute().to_numpy(dtype=np.float32)` will load all processed features into memory. For extremely large datasets where even the processed feature matrix doesn't fit, this part needs to be re-written to save the Dask DataFrame to a format like Parquet and then load it in chunks in the training script, or process Dask Arrays partition by partition into tensors.\n",
    "- **Dask `get_dummies` Consistency**: Ensuring `dd.get_dummies` on the test set produces columns consistent with the training set is critical. The `aligned_processed_features_ddf_cat` logic attempts to handle this by reindexing partitions based on `cat_feat_names` derived from the training set.\n",
    "- **Timestamps (`ts`)**: Currently, event indices are used as timestamps. If your data has actual timestamps, they should be used and appropriately scaled/normalized if necessary for the time encoder in TGAT.\n",
    "- **Error Handling & Robustness**: More error handling can be added, especially around file I/O and Dask computations. The KDD fallback is one example.\n",
    "- **Dask Performance**: `blocksize` in `dd.read_csv` and `npartitions` in `dd.from_pandas` can significantly affect Dask performance. These may need tuning based on your specific dataset size and system resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd438c-e086-44fb-817c-947e7a5936dc",
   "metadata": {},
   "source": [
    "# train_tgat_from_processed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747aa7d6-50d9-4365-bb99-77626ea95781",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Model Training from Preprocessed Data\n",
    "This notebook loads preprocessed temporal graph data and trains the TGAT model for network intrusion detection.\n",
    "**Prerequisites**:\n",
    "- Run `preprocess_kdd_large.ipynb` first to generate the `processed_data_large` directory with training/testing data and metadata.\n",
    "**Steps**:\n",
    "1. Configure paths and hyperparameters.\n",
    "2. Define utility functions, TGAT model, and TemporalNeighborLoader.\n",
    "3. Implement data loading function for preprocessed files.\n",
    "4. Implement training and evaluation functions.\n",
    "5. Orchestrate the training process.\n",
    "6. Plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa2200-b4b2-455e-b18f-e2133bb9dc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import TemporalData\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             confusion_matrix, roc_auc_score, classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = './data/' # ç¢ºä¿èˆ‡é è™•ç†é…ç½®ä¸€è‡´\n",
    "TRAIN_FILE = 'KDDTrain+.txt' # ç¢ºä¿èˆ‡é è™•ç†é…ç½®ä¸€è‡´\n",
    "TEST_FILE = 'KDDTest+.txt'      # ç¢ºä¿èˆ‡é è™•ç†é…ç½®ä¸€è‡´ (æˆ– 'KDDTest-21.txt')\n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_nslkdd/' # ä½¿ç”¨æ–°çš„ NSL-KDD è™•ç†ç›®éŒ„\n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data_nslkdd.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data_nslkdd.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata_nslkdd.json')\n",
    "\n",
    "MODEL_SAVE_DIR = './saved_models_nslkdd/' # æ›´æ”¹ä»¥é¿å…è¦†è“‹\n",
    "BEST_MODEL_NAME = 'best_tgat_model_nslkdd.pth'\n",
    "\n",
    "DEFAULT_DEVICE_ID = 0\n",
    "DEVICE = torch.device(f'cuda:{DEFAULT_DEVICE_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- TGAT Model Hyperparameters ---\n",
    "EPOCHS = 30 # èˆ‡æ‚¨çš„æ—¥èªŒè¼¸å‡ºä¸€è‡´\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.0005\n",
    "HIDDEN_DIM = 256\n",
    "TIME_DIM = 64\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "NUM_NEIGHBORS = [10, 5]\n",
    "CLIP_GRAD_NORM = 1.0\n",
    "WEIGHT_DECAY = 1e-5\n",
    "LR_SCHEDULER = \"cosine\"\n",
    "USE_FOCAL_LOSS = True\n",
    "CLASSIFICATION_MODE = 'binary'\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "# --- Parameters for Smarter Sampling in TemporalNeighborLoader ---\n",
    "RECENCY_BIAS_FACTOR = 0.9\n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3\n",
    "\n",
    "# --- Parameters for Sequence Modeling ---\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE\n",
    "SEQUENCE_LENGTH = 10\n",
    "STEP_SIZE = 5\n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64\n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 20 # èˆ‡æ‚¨çš„æ—¥èªŒè¼¸å‡ºä¸€è‡´\n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM\n",
    "SEQ_MODEL_HIDDEN_DIM = 128\n",
    "SEQ_MODEL_NUM_LAYERS = 1\n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'\n",
    "SEQ_MODEL_DROPOUT = 0.2\n",
    "\n",
    "# --- NSL-KDD Dataset Specific Column Names ---\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score'\n",
    "]\n",
    "ATTACK_MAP_MULTI_CLASS = {\n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos',\n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe',\n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l',\n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r'\n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "def get_device():\n",
    "    return DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038487d2-dd90-435a-8a7f-c40d56a9158e",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be5024-d6af-4536-8e83-b6b141e46d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cellï¼šUtility Functions & Custom Loss\n",
    "\n",
    "def get_device():\n",
    "    return DEVICE\n",
    "\n",
    "def plot_confusion_matrix_custom(y_true, y_pred, class_names, title='Confusion Matrix'):\n",
    "    if not y_true or not y_pred or len(y_true) != len(y_pred) or len(y_true) == 0:\n",
    "        print(f\"Cannot plot confusion matrix for {title}: y_true or y_pred is empty or mismatched.\")\n",
    "        return\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title); plt.xlabel('Predicted Label'); plt.ylabel('True Label'); plt.show()\n",
    "\n",
    "def print_metrics(epoch_str, loss, accuracy, precision, recall, f1, auc=None, phase='Train', class_report=None):\n",
    "    loss_str = f\"{loss:.4f}\" if loss is not None and not np.isnan(loss) else \"N/A\"\n",
    "    acc_str = f\"{accuracy:.4f}\" if accuracy is not None and not np.isnan(accuracy) else \"N/A\"\n",
    "    prec_str = f\"{precision:.4f}\" if precision is not None and not np.isnan(precision) else \"N/A\"\n",
    "    rec_str = f\"{recall:.4f}\" if recall is not None and not np.isnan(recall) else \"N/A\"\n",
    "    f1_str = f\"{f1:.4f}\" if f1 is not None and not np.isnan(f1) else \"N/A\"\n",
    "    \n",
    "    print(f\"{epoch_str} | {phase} Loss: {loss_str} | Acc: {acc_str} | Prec: {prec_str} | Rec: {rec_str} | F1: {f1_str}\", end=\"\")\n",
    "    if auc is not None and not np.isnan(auc):\n",
    "        print(f\" | AUC: {auc:.4f}\", end=\"\")\n",
    "    print() # Newline\n",
    "    if class_report:\n",
    "        if isinstance(class_report, str): # If it's already a formatted string\n",
    "            print(class_report)\n",
    "        elif isinstance(class_report, dict): # If it's a dict from classification_report\n",
    "            print(\"Classification Report (Dict):\\n\", json.dumps(class_report, indent=2))\n",
    "\n",
    "class FocalLoss(nn.Module): # Keep for future use\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', pos_weight_for_bce=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight_for_bce = pos_weight_for_bce\n",
    "\n",
    "    def forward(self, inputs, targets): \n",
    "        if self.pos_weight_for_bce is not None:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none', pos_weight=self.pos_weight_for_bce)\n",
    "        else:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none')\n",
    "        \n",
    "        pt = torch.exp(-bce_loss) \n",
    "        \n",
    "        alpha_t = self.alpha\n",
    "        if self.alpha is not None: \n",
    "            if isinstance(self.alpha, (float, int)): \n",
    "                alpha_tensor = torch.tensor([self.alpha], device=inputs.device, dtype=inputs.dtype)\n",
    "                alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            elif isinstance(self.alpha, torch.Tensor) and self.alpha.ndim == 0: \n",
    "                 alpha_tensor = self.alpha.to(inputs.device, dtype=inputs.dtype)\n",
    "                 alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            if alpha_t.ndim == 1 and targets.ndim > 1 and alpha_t.shape[0] == targets.shape[0] and targets.shape[1] == 1: # Ensure broadcasting for [B,1] targets\n",
    "                alpha_t = alpha_t.unsqueeze(1)\n",
    "            \n",
    "        if alpha_t is None: \n",
    "            focal_loss_unreduced = (1 - pt)**self.gamma * bce_loss\n",
    "        else:\n",
    "            focal_loss_unreduced = alpha_t * (1 - pt)**self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss_unreduced)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss_unreduced)\n",
    "        else: \n",
    "            return focal_loss_unreduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f4492-75ff-4946-adf0-e9db1cbcc6ad",
   "metadata": {},
   "source": [
    "## 4. Model Definition (TGAT & TemporalGraphAttentionLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45cea8-e5db-468c-8489-7ddb6581e434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Model Definition (TGAT class forward method MODIFIED for sliced data)\n",
    "class FunctionalTimeEncoder(nn.Module):\n",
    "    def __init__(self, D_in_emb, D_time_emb, D_out_emb):\n",
    "        super(FunctionalTimeEncoder, self).__init__()\n",
    "        self.time_emb_layer = nn.Linear(1, D_time_emb)\n",
    "        self.output_layer = nn.Linear(D_in_emb + D_time_emb, D_out_emb)\n",
    "\n",
    "    def forward(self, x_feat, delta_t):\n",
    "        if delta_t.ndim == 1: delta_t = delta_t.unsqueeze(-1)\n",
    "        time_embedding_input = torch.tanh(self.time_emb_layer(delta_t.float())) \n",
    "        time_emb = torch.cos(time_embedding_input) \n",
    "        output_concat = torch.cat([x_feat, time_emb], dim=-1)\n",
    "        return self.output_layer(output_concat)\n",
    "\n",
    "class TemporalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, n_feat_dim_input, n_time_emb_dim, n_out_dim_layer, n_head=2, dropout=0.1):\n",
    "        super(TemporalGraphAttentionLayer, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.n_out_dim_head = n_out_dim_layer // n_head\n",
    "        if self.n_out_dim_head == 0: \n",
    "            raise ValueError(f\"Output dimension per head is 0. n_out_dim_layer ({n_out_dim_layer}) must be >= n_head ({n_head}).\")\n",
    "        self.time_encoder = FunctionalTimeEncoder(n_feat_dim_input, n_time_emb_dim, n_feat_dim_input) \n",
    "        self.W_q = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head) \n",
    "        self.W_k = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_v = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_out = nn.Linear(self.n_out_dim_head * n_head, n_out_dim_layer)\n",
    "        self.dropout_m = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(n_out_dim_layer)\n",
    "\n",
    "    def forward(self, target_node_feat_input, target_node_ts, neighbor_feats_input_list, neighbor_ts_list, neighbor_masks):\n",
    "        B, N_max_neighbors, D_feat_input = neighbor_feats_input_list.shape\n",
    "        if target_node_feat_input.shape[-1] != D_feat_input:\n",
    "            raise ValueError(f\"Mismatched feature dimensions for target ({target_node_feat_input.shape[-1]}) and_neighbors ({D_feat_input}) in TemporalGraphAttentionLayer\")\n",
    "\n",
    "        Q = self.W_q(target_node_feat_input).view(B, self.n_head, self.n_out_dim_head)\n",
    "        neighbor_feats_flat = neighbor_feats_input_list.reshape(-1, D_feat_input)\n",
    "        neighbor_ts_flat = neighbor_ts_list.reshape(-1)\n",
    "        target_node_ts_expanded = target_node_ts.unsqueeze(1).expand(-1, N_max_neighbors).reshape(-1)\n",
    "        delta_t_neighbors = target_node_ts_expanded - neighbor_ts_flat\n",
    "        \n",
    "        time_aware_neighbor_feats_flat = self.time_encoder(neighbor_feats_flat, delta_t_neighbors)\n",
    "        K = self.W_k(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        V = self.W_v(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        K_t = K.permute(0, 2, 3, 1) \n",
    "        \n",
    "        attn_scores = torch.matmul(Q.unsqueeze(2), K_t) / np.sqrt(self.n_out_dim_head + 1e-9) \n",
    "        attn_scores = attn_scores.squeeze(2) \n",
    "        attn_scores = torch.clamp(attn_scores, min=-10.0, max=10.0) \n",
    "        attn_scores = attn_scores.masked_fill(~neighbor_masks.unsqueeze(1), float('-inf'))\n",
    "        all_masked = torch.all(attn_scores == float('-inf'), dim=-1, keepdim=True)\n",
    "        attn_scores_safe = torch.where(all_masked, torch.zeros_like(attn_scores), attn_scores)\n",
    "        attn_probs = torch.softmax(attn_scores_safe, dim=-1) \n",
    "        attn_probs = torch.where(all_masked, torch.zeros_like(attn_probs), attn_probs)\n",
    "        attn_probs = self.dropout_m(attn_probs) \n",
    "        output = torch.matmul(attn_probs.unsqueeze(2), V.permute(0, 2, 1, 3)) \n",
    "        output = output.squeeze(2).reshape(B, self.n_head * self.n_out_dim_head)\n",
    "        output = self.W_out(output)\n",
    "        output = self.dropout_m(output)\n",
    "        output = self.layer_norm(output)\n",
    "        return output\n",
    "\n",
    "class TGAT(nn.Module):\n",
    "    def __init__(self, node_feat_dim, time_emb_dim, n_head, n_layers, hidden_dim_per_layer, num_classes, dropout=0.1):\n",
    "        super(TGAT, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.node_feat_dim = node_feat_dim \n",
    "        self.attn_layers = nn.ModuleList()\n",
    "        self.neighbor_feat_projectors = nn.ModuleList()\n",
    "\n",
    "        current_dim_of_h = node_feat_dim\n",
    "        for i in range(n_layers):\n",
    "            self.attn_layers.append(\n",
    "                TemporalGraphAttentionLayer(\n",
    "                    n_feat_dim_input=current_dim_of_h, \n",
    "                    n_time_emb_dim=time_emb_dim,      \n",
    "                    n_out_dim_layer=hidden_dim_per_layer, \n",
    "                    n_head=n_head, \n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "            if i > 0: \n",
    "                self.neighbor_feat_projectors.append(\n",
    "                    nn.Linear(self.node_feat_dim, current_dim_of_h) # Project from original dim\n",
    "                )\n",
    "            else: \n",
    "                self.neighbor_feat_projectors.append(None) \n",
    "            current_dim_of_h = hidden_dim_per_layer\n",
    "\n",
    "        mlp_input_dim = current_dim_of_h\n",
    "        mlp_hidden_dim = mlp_input_dim // 2 if mlp_input_dim // 2 > 0 else 1\n",
    "        if mlp_hidden_dim == 0 : mlp_hidden_dim = 1\n",
    "\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_input_dim, mlp_hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, num_classes)\n",
    "        )\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "    # MODIFIED: forward now takes batch_node_features and batch_node_timestamps (sliced data)\n",
    "    # target_node_indices and neighbor_node_indices are now batch-local\n",
    "    def forward(self, target_node_indices_local, \n",
    "                batch_node_features, batch_node_timestamps, \n",
    "                neighbor_info_batches_all_layers_local, return_embedding=False):\n",
    "        \n",
    "        h = batch_node_features[target_node_indices_local] \n",
    "        target_ts_for_attn = batch_node_timestamps[target_node_indices_local]\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            layer_input_h_target = h \n",
    "            if i >= len(neighbor_info_batches_all_layers_local):\n",
    "                print(f\"Warning: Not enough neighbor_info_batches for layer {i}.\")\n",
    "                break \n",
    "            \n",
    "            # These are batch-local indices now\n",
    "            neighbor_node_indices_padded_local, neighbor_ts_padded, neighbor_masks = neighbor_info_batches_all_layers_local[i]\n",
    "            \n",
    "            # Fetch neighbor features using batch-local indices from batch_node_features\n",
    "            # Important: The dimension of batch_node_features is self.node_feat_dim (original)\n",
    "            original_neighbor_features = batch_node_features[neighbor_node_indices_padded_local.reshape(-1)].reshape(\n",
    "                neighbor_node_indices_padded_local.shape[0], \n",
    "                neighbor_node_indices_padded_local.shape[1], \n",
    "                self.node_feat_dim # Neighbors are always fetched with original feature dim\n",
    "            )\n",
    "            \n",
    "            projector = self.neighbor_feat_projectors[i]\n",
    "            if projector is not None:\n",
    "                # Project original neighbor features to match current_dim_of_h (which is layer_input_h_target.shape[-1])\n",
    "                B_Nmax_shape = original_neighbor_features.shape[:2]\n",
    "                flat_original_neighbor_features = original_neighbor_features.reshape(-1, self.node_feat_dim)\n",
    "                projected_flat_neighbor_features = projector(flat_original_neighbor_features)\n",
    "                input_neighbor_features_for_attn = projected_flat_neighbor_features.reshape(*B_Nmax_shape, -1)\n",
    "            else: \n",
    "                # First layer: layer_input_h_target is original_node_feat_dim, so original_neighbor_features match\n",
    "                input_neighbor_features_for_attn = original_neighbor_features\n",
    "            \n",
    "            input_neighbor_features_for_attn[~neighbor_masks] = 0 \n",
    "\n",
    "            h = self.attn_layers[i](\n",
    "                layer_input_h_target, \n",
    "                target_ts_for_attn, # These are absolute timestamps, but fetched for batch nodes\n",
    "                input_neighbor_features_for_attn, \n",
    "                neighbor_ts_padded, # These are absolute timestamps for neighbors\n",
    "                neighbor_masks\n",
    "            )\n",
    "            h = self.activation(h) \n",
    "        \n",
    "        output_logits = self.output_mlp(h)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return output_logits, h \n",
    "        else:\n",
    "            return output_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15103a6-15ef-437a-ba84-705d2d960555",
   "metadata": {},
   "source": [
    "## 5. Custom TemporalNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8936df-f7a4-4c4d-92a8-742d3b72819c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: TemporalNeighborLoader Class (MODIFIED for Smarter Neighbor Sampling)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm # Ensure tqdm is imported if used within the class\n",
    "\n",
    "class TemporalNeighborLoader:\n",
    "    def __init__(self, temporal_data_cpu, batch_size, num_neighbors_per_layer_list, device,\n",
    "                 shuffle=True, \n",
    "                 recency_bias_factor=0.8, \n",
    "                 feature_similarity_col_name='service', \n",
    "                 feature_similarity_weight=0.5, \n",
    "                 raw_data_file_path_for_ids=None, # Default is None\n",
    "                 col_names_list=None # Parameter to pass COL_NAMES for reading raw file\n",
    "                ):\n",
    "        self.temporal_data_cpu = temporal_data_cpu\n",
    "        self.x_cpu = temporal_data_cpu.x\n",
    "        self.ts_cpu = temporal_data_cpu.ts\n",
    "        self.y_cpu = temporal_data_cpu.y\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_neighbors_per_layer_list = num_neighbors_per_layer_list\n",
    "        self.shuffle = shuffle\n",
    "        self.device = device\n",
    "        self.N = temporal_data_cpu.num_nodes if temporal_data_cpu.num_nodes is not None else 0\n",
    "        self.node_indices_global = torch.arange(self.N) if self.N > 0 else torch.empty(0, dtype=torch.long)\n",
    "\n",
    "        self.adj = [[] for _ in range(self.N)]\n",
    "        if self.N > 0 and hasattr(temporal_data_cpu, 'edge_index') and temporal_data_cpu.edge_index is not None:\n",
    "            edge_index_cpu = temporal_data_cpu.edge_index.cpu() \n",
    "            src, dst = edge_index_cpu\n",
    "            \n",
    "            for i in range(len(src)):\n",
    "                s, d = src[i].item(), dst[i].item()\n",
    "                if s < self.N and d < self.N and self.ts_cpu[s] < self.ts_cpu[d]: # Bounds check\n",
    "                    self.adj[d].append(s)\n",
    "            \n",
    "            for i in range(self.N):\n",
    "                self.adj[i].sort(key=lambda pred_idx: self.ts_cpu[pred_idx], reverse=True)\n",
    "\n",
    "        self.recency_bias_factor = recency_bias_factor\n",
    "        self.feature_similarity_col_name = feature_similarity_col_name\n",
    "        self.feature_similarity_weight = feature_similarity_weight\n",
    "        self.raw_data_file_path_for_ids = raw_data_file_path_for_ids \n",
    "        self.original_feature_for_similarity_cpu = None\n",
    "        self._col_names_for_raw_read = col_names_list \n",
    "\n",
    "        if self.feature_similarity_col_name and self.raw_data_file_path_for_ids:\n",
    "            if not os.path.exists(self.raw_data_file_path_for_ids):\n",
    "                print(f\"Warning: 'raw_data_file_path_for_ids' ('{self.raw_data_file_path_for_ids}') provided but file does not exist. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self._col_names_for_raw_read is None or not isinstance(self._col_names_for_raw_read, list) or len(self._col_names_for_raw_read) == 0:\n",
    "                print(f\"Warning: 'col_names_list' not provided or invalid to TemporalNeighborLoader. Disabling feature similarity sampling for '{self.feature_similarity_col_name}'.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self.feature_similarity_col_name not in self._col_names_for_raw_read:\n",
    "                print(f\"Warning: feature_similarity_col_name '{self.feature_similarity_col_name}' not found in provided col_names_list. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            else:\n",
    "                try:\n",
    "                    print(f\"Loading '{self.feature_similarity_col_name}' from {self.raw_data_file_path_for_ids} for similarity sampling...\")\n",
    "                    df_ids = pd.read_csv(self.raw_data_file_path_for_ids, header=None, names=self._col_names_for_raw_read, usecols=[self.feature_similarity_col_name], low_memory=False)\n",
    "                    self.original_feature_for_similarity_cpu = df_ids[self.feature_similarity_col_name].values\n",
    "                    print(f\"Successfully loaded '{self.feature_similarity_col_name}' for {len(self.original_feature_for_similarity_cpu)} nodes.\")\n",
    "                    if self.N > 0 and len(self.original_feature_for_similarity_cpu) != self.N:\n",
    "                        print(f\"Warning: Length mismatch for similarity feature. Expected {self.N}, got {len(self.original_feature_for_similarity_cpu)}. Disabling feature similarity.\")\n",
    "                        self.original_feature_for_similarity_cpu = None\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not load feature '{self.feature_similarity_col_name}' for similarity sampling from '{self.raw_data_file_path_for_ids}': {e}. Disabling.\")\n",
    "                    self.original_feature_for_similarity_cpu = None\n",
    "        elif self.feature_similarity_col_name: \n",
    "             print(f\"Warning: 'feature_similarity_col_name' ('{self.feature_similarity_col_name}') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\")\n",
    "             self.original_feature_for_similarity_cpu = None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.N == 0 : \n",
    "            self.node_indices_permuted_global = torch.empty(0, dtype=torch.long)\n",
    "        elif self.shuffle:\n",
    "            self.node_indices_permuted_global = self.node_indices_global[torch.randperm(self.N)]\n",
    "        else:\n",
    "            self.node_indices_permuted_global = self.node_indices_global\n",
    "        self.current_idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_idx >= self.N or self.N == 0: \n",
    "            raise StopIteration\n",
    "        \n",
    "        end_idx = min(self.current_idx + self.batch_size, self.N)\n",
    "        target_node_indices_batch_global_cpu = self.node_indices_permuted_global[self.current_idx:end_idx]\n",
    "        self.current_idx = end_idx\n",
    "        \n",
    "        unique_global_indices_for_batch_set = set(target_node_indices_batch_global_cpu.tolist())\n",
    "        neighbor_info_for_model_layers_global_cpu = []\n",
    "        \n",
    "        for k_neighbors_this_layer in self.num_neighbors_per_layer_list:\n",
    "            batch_neigh_idx_padded_global_cpu, batch_neigh_ts_padded_cpu, batch_neigh_masks_cpu = [], [], []\n",
    "            for node_idx_val_global in target_node_indices_batch_global_cpu.tolist():\n",
    "                if node_idx_val_global >= self.N: \n",
    "                    preds_global = []\n",
    "                else:\n",
    "                    preds_global = self.adj[node_idx_val_global]\n",
    "                actual_k_candidates = len(preds_global)\n",
    "                \n",
    "                sampled_pred_indices_global_np = np.array([], dtype=np.int64)\n",
    "                if actual_k_candidates > 0:\n",
    "                    weights = np.ones(actual_k_candidates, dtype=float) \n",
    "                    \n",
    "                    if self.recency_bias_factor > 0 and self.recency_bias_factor < 1 and actual_k_candidates > 1:\n",
    "                        recency_weights = np.array([self.recency_bias_factor**i for i in range(actual_k_candidates)], dtype=float)\n",
    "                        weights *= recency_weights\n",
    "                    \n",
    "                    if self.original_feature_for_similarity_cpu is not None and \\\n",
    "                       self.feature_similarity_weight > 0 and \\\n",
    "                       node_idx_val_global < len(self.original_feature_for_similarity_cpu): \n",
    "                        \n",
    "                        target_feature_value = self.original_feature_for_similarity_cpu[node_idx_val_global]\n",
    "                        valid_preds_for_sim_indices = [p for p in preds_global if p < len(self.original_feature_for_similarity_cpu)]\n",
    "                        \n",
    "                        if valid_preds_for_sim_indices:\n",
    "                            pred_to_valid_idx_map = {pred_val: i for i, pred_val in enumerate(valid_preds_for_sim_indices)}\n",
    "                            neighbor_feature_values = self.original_feature_for_similarity_cpu[valid_preds_for_sim_indices]\n",
    "                            similarity_scores_for_valid_preds = np.array([1.0 if nf == target_feature_value else (1.0 - self.feature_similarity_weight) for nf in neighbor_feature_values], dtype=float)\n",
    "                            \n",
    "                            for i, pred_original_idx in enumerate(preds_global):\n",
    "                                if pred_original_idx in pred_to_valid_idx_map:\n",
    "                                    weights[i] *= similarity_scores_for_valid_preds[pred_to_valid_idx_map[pred_original_idx]]\n",
    "\n",
    "                    sum_weights = np.sum(weights)\n",
    "                    p_dist = None\n",
    "                    if sum_weights > 1e-9: \n",
    "                        p_dist = weights / sum_weights\n",
    "                    elif actual_k_candidates > 0 : \n",
    "                        pass # p=None in np.random.choice means uniform\n",
    "\n",
    "                    actual_k_to_sample = min(actual_k_candidates, k_neighbors_this_layer)\n",
    "                    \n",
    "                    try:\n",
    "                        if actual_k_candidates > 0:\n",
    "                            sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False, p=p_dist\n",
    "                            )\n",
    "                    except ValueError as e_choice: \n",
    "                        if actual_k_candidates > 0: # Ensure preds_global is not empty before trying uniform sampling\n",
    "                             # print(f\"Warning: np.random.choice ValueError ({e_choice}). Sum_w: {np.sum(p_dist) if p_dist is not None else 'None (uniform)'}. N_cand: {actual_k_candidates}, k_sample: {actual_k_to_sample}. Uniform sampling for node {node_idx_val_global}.\")\n",
    "                             sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False\n",
    "                            )\n",
    "                actual_k = len(sampled_pred_indices_global_np)\n",
    "                sampled_pred_indices_global_torch = torch.from_numpy(sampled_pred_indices_global_np).long()\n",
    "                \n",
    "                sampled_pred_ts_cpu = torch.empty(0, dtype=torch.long)\n",
    "                if actual_k > 0:\n",
    "                    # Ensure sampled indices are valid before fetching from ts_cpu\n",
    "                    valid_ts_indices = sampled_pred_indices_global_torch[(sampled_pred_indices_global_torch >= 0) & (sampled_pred_indices_global_torch < self.N)]\n",
    "                    if len(valid_ts_indices) > 0: \n",
    "                        sampled_pred_ts_cpu = self.ts_cpu[valid_ts_indices]\n",
    "                    \n",
    "                    # Pad if some indices became invalid (should be rare if preds_global are valid)\n",
    "                    if len(valid_ts_indices) != actual_k:\n",
    "                         # print(f\"Warning: Timestamp fetch mismatch for node {node_idx_val_global}. Expected {actual_k}, got {len(valid_ts_indices)}. Padded with zeros.\")\n",
    "                         sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.zeros(actual_k - len(valid_ts_indices), dtype=torch.long)])\n",
    "\n",
    "                unique_global_indices_for_batch_set.update(sampled_pred_indices_global_torch.tolist())\n",
    "                \n",
    "                padding_needed = k_neighbors_this_layer - actual_k\n",
    "                mask_cpu = torch.ones(actual_k, dtype=torch.bool)\n",
    "                \n",
    "                if padding_needed > 0:\n",
    "                    pad_idx_val = 0 \n",
    "                    if self.N > 0 and pad_idx_val not in unique_global_indices_for_batch_set: \n",
    "                         unique_global_indices_for_batch_set.add(pad_idx_val)\n",
    "                    \n",
    "                    sampled_pred_indices_global_torch = torch.cat([sampled_pred_indices_global_torch, torch.full((padding_needed,), pad_idx_val, dtype=torch.long)])\n",
    "                    pad_ts_val = self.ts_cpu[pad_idx_val].item() if self.N > 0 and pad_idx_val < self.N else 0\n",
    "                    sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.full((padding_needed,), pad_ts_val, dtype=torch.long)])\n",
    "                    mask_cpu = torch.cat([mask_cpu, torch.zeros(padding_needed, dtype=torch.bool)])\n",
    "                \n",
    "                batch_neigh_idx_padded_global_cpu.append(sampled_pred_indices_global_torch)\n",
    "                batch_neigh_ts_padded_cpu.append(sampled_pred_ts_cpu)\n",
    "                batch_neigh_masks_cpu.append(mask_cpu)\n",
    "            \n",
    "            if not batch_neigh_idx_padded_global_cpu: # If target_node_indices_batch_global_cpu was empty or led to no neighbors\n",
    "                 dummy_shape_neighbors = (0, k_neighbors_this_layer)\n",
    "                 neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.bool)))\n",
    "            else:\n",
    "                neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.stack(batch_neigh_idx_padded_global_cpu),\n",
    "                    torch.stack(batch_neigh_ts_padded_cpu),\n",
    "                    torch.stack(batch_neigh_masks_cpu)))\n",
    "\n",
    "        unique_global_indices_list_cpu = sorted(list(unique_global_indices_for_batch_set))\n",
    "        if not unique_global_indices_list_cpu : # If, after all processing, the set is empty\n",
    "            if self.N > 0 : # If dataset has nodes, but this batch yielded no unique indices (e.g. only padded 0s and 0 was already there)\n",
    "                unique_global_indices_list_cpu = [0] # Add 0 to fetch its features at least\n",
    "                # print(\"Warning: unique_global_indices_list_cpu was empty after processing neighbors, defaulting to [0].\")\n",
    "            else: # Dataset itself is empty\n",
    "                 # print(\"Error: Dataset has no nodes (self.N=0). Returning empty batch from loader.\")\n",
    "                 x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "                 y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                 return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                         torch.empty(0, x_dim).to(self.device), \n",
    "                         torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                         torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "\n",
    "        global_to_batch_local_idx_map = {global_idx: local_idx for local_idx, global_idx in enumerate(unique_global_indices_list_cpu)}\n",
    "        \n",
    "        valid_fetch_indices_tensor = torch.tensor(unique_global_indices_list_cpu, dtype=torch.long)\n",
    "        # Filter out-of-bounds indices, though ideally, unique_global_indices_list_cpu should only contain valid global indices < self.N\n",
    "        # (or index 0 if used for padding and N > 0)\n",
    "        valid_fetch_indices_tensor = valid_fetch_indices_tensor[valid_fetch_indices_tensor < self.N] \n",
    "        \n",
    "        if valid_fetch_indices_tensor.numel() == 0 : # If no valid indices after filtering (e.g., unique_global_indices_list_cpu was empty or only contained invalid indices)\n",
    "             if self.N > 0: # If dataset has nodes, but no valid indices were collected\n",
    "                # print(\"Warning: No valid indices to fetch features/timestamps after filtering. Using node 0 if N > 0.\")\n",
    "                valid_fetch_indices_tensor = torch.tensor([0], dtype=torch.long) # Default to fetching node 0\n",
    "                if 0 not in global_to_batch_local_idx_map: # Ensure mapping exists for node 0 if we defaulted to it\n",
    "                    global_to_batch_local_idx_map[0] = len(global_to_batch_local_idx_map) \n",
    "            \n",
    "        if valid_fetch_indices_tensor.numel() == 0: # Still no valid indices (e.g. self.N=0 or above fallback failed)\n",
    "             x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                     torch.empty(0, x_dim).to(self.device), \n",
    "                     torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                     torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "        batch_node_features_dev = self.x_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "        batch_node_timestamps_dev = self.ts_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "\n",
    "        target_node_indices_batch_local_dev_list = []\n",
    "        for global_idx_tensor in target_node_indices_batch_global_cpu:\n",
    "            global_idx = global_idx_tensor.item()\n",
    "            local_idx = global_to_batch_local_idx_map.get(global_idx)\n",
    "            if local_idx is None: # Should not happen if unique_global_indices_for_batch_set was built from targets\n",
    "                # print(f\"Critical Warning: Target node global index {global_idx} not in local map! Using local index of global 0 as fallback.\")\n",
    "                local_idx = global_to_batch_local_idx_map.get(0,0) # Default to local index of global 0 if something went wrong\n",
    "            target_node_indices_batch_local_dev_list.append(local_idx)\n",
    "        \n",
    "        target_node_indices_batch_local_dev = torch.tensor(\n",
    "            target_node_indices_batch_local_dev_list, dtype=torch.long\n",
    "        ).to(self.device)\n",
    "\n",
    "        neighbor_info_for_model_layers_local_dev = []\n",
    "        for global_indices_layer, global_ts_layer, masks_layer in neighbor_info_for_model_layers_global_cpu:\n",
    "            if global_indices_layer.numel() > 0: \n",
    "                remapped_indices_list = []\n",
    "                for row_idx in range(global_indices_layer.shape[0]):\n",
    "                    row = global_indices_layer[row_idx]\n",
    "                    remapped_row = [global_to_batch_local_idx_map.get(x.item(), global_to_batch_local_idx_map.get(0,0)) for x in row]\n",
    "                    remapped_indices_list.append(remapped_row)\n",
    "                \n",
    "                if not remapped_indices_list: \n",
    "                     batch_local_indices_layer = torch.empty_like(global_indices_layer) \n",
    "                else:\n",
    "                     batch_local_indices_layer = torch.tensor(remapped_indices_list, dtype=torch.long)\n",
    "\n",
    "                neighbor_info_for_model_layers_local_dev.append((\n",
    "                    batch_local_indices_layer.to(self.device),\n",
    "                    global_ts_layer.to(self.device),\n",
    "                    masks_layer.to(self.device)\n",
    "                ))\n",
    "            else: \n",
    "                 k_this_layer = global_indices_layer.shape[1] if global_indices_layer.ndim ==2 and global_indices_layer.shape[1] > 0 else (self.num_neighbors_per_layer_list[0] if self.num_neighbors_per_layer_list and len(self.num_neighbors_per_layer_list)>0 else 0)\n",
    "                 dummy_shape_layer_neighbors = (len(target_node_indices_batch_global_cpu), k_this_layer) # Ensure batch dim matches target nodes\n",
    "                 if len(target_node_indices_batch_global_cpu) == 0: dummy_shape_layer_neighbors = (0, k_this_layer)\n",
    "\n",
    "                 neighbor_info_for_model_layers_local_dev.append((\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.bool).to(self.device)\n",
    "                 ))\n",
    "        \n",
    "        if target_node_indices_batch_global_cpu.numel() > 0:\n",
    "             # Ensure indices are valid for y_cpu before fetching\n",
    "             valid_y_indices = target_node_indices_batch_global_cpu[target_node_indices_batch_global_cpu < self.N]\n",
    "             if valid_y_indices.numel() > 0:\n",
    "                 batch_labels_dev = self.y_cpu[valid_y_indices].to(self.device)\n",
    "                 if len(batch_labels_dev) != len(target_node_indices_batch_local_dev): # If filtering changed size\n",
    "                     print(f\"Warning: Label batch size mismatch after filtering valid y_indices. This might cause issues.\")\n",
    "                     # Fallback: create dummy labels matching target_node_indices_batch_local_dev size\n",
    "                     y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                     batch_labels_dev = torch.empty(len(target_node_indices_batch_local_dev), *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "             else: # No valid indices left for y_cpu\n",
    "                y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        else: # target_node_indices_batch_global_cpu was empty\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        return (target_node_indices_batch_local_dev,\n",
    "                batch_node_features_dev,\n",
    "                batch_node_timestamps_dev,\n",
    "                neighbor_info_for_model_layers_local_dev,\n",
    "                batch_labels_dev)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.N == 0: return 0\n",
    "        return (self.N + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292f589-fce4-4496-a455-a3620769bf62",
   "metadata": {},
   "source": [
    "## 6. Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbae281-216c-46ee-a595-681fbe6d6065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: load_processed_data function\n",
    "def load_processed_data(data_file_path: str, metadata_file_path: str, classification_mode: str = 'binary'):\n",
    "    print(f\"Loading data from: {data_file_path}\")\n",
    "    data_dict = torch.load(data_file_path, map_location='cpu') \n",
    "    \n",
    "    print(f\"Loading metadata from: {metadata_file_path}\")\n",
    "    with open(metadata_file_path, 'r') as f: metadata = json.load(f)\n",
    "\n",
    "    y_labels = data_dict['y_binary'] if classification_mode == 'binary' else data_dict['y_multiclass'].squeeze() # Ensure y_multiclass is 1D\n",
    "    num_classes = metadata['NUM_CLASSES_BINARY'] if classification_mode == 'binary' else metadata['NUM_CLASSES_MULTI']\n",
    "    \n",
    "    pos_weight_tensor = None\n",
    "    if classification_mode == 'binary':\n",
    "        pos_weight_val = metadata.get('POS_WEIGHT_BINARY', 1.0)\n",
    "        pos_weight_tensor = torch.tensor([pos_weight_val], dtype=torch.float32) \n",
    "\n",
    "    temporal_data_obj = TemporalData(x=data_dict['x'], edge_index=data_dict['edge_index'], \n",
    "                                     ts=data_dict['ts'], y=y_labels)\n",
    "    \n",
    "    print(f\"Data loaded: Nodes={temporal_data_obj.num_nodes}, Edges={temporal_data_obj.num_edges}\")\n",
    "    print(f\"Metadata: NodeFeatDim={metadata['NODE_FEAT_DIM']}, NumClasses({classification_mode})={num_classes}, PosWeight={pos_weight_tensor.item() if pos_weight_tensor is not None and classification_mode == 'binary' else 'N/A_or_Multiclass'}\")\n",
    "    return temporal_data_obj, metadata, num_classes, pos_weight_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549ab9b-0cd9-4513-9fac-2498fb7b1299",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b2775-77b8-489a-8486-26dfcfc5d3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_epoch and evaluate_model functions (MODIFIED for new loader output)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, clip_grad_val=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list = [], []\n",
    "    valid_batches_for_loss = 0\n",
    "    pbar = tqdm(loader, desc=\"Train Epoch\")\n",
    "    # MODIFIED: Unpack new items from loader\n",
    "    for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                     neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                print(f\"Warning: Batch {batch_idx} has insufficient neighbor_info_batches for N_LAYERS. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # MODIFIED: Pass sliced data to model\n",
    "            output_logits = model(target_indices_local_dev, batch_features_dev, batch_ts_dev, neighbor_batches_local_dev)\n",
    "            \n",
    "            if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                print(f\"Batch {batch_idx}: NaNs/Infs in model output_logits! Skipping.\")\n",
    "                continue \n",
    "            \n",
    "            # batch_labels_dev are already on device and correspond to target_indices_local_dev\n",
    "            true_labels_dev = batch_labels_dev \n",
    "            if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "            elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "            \n",
    "            loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "            \n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Batch {batch_idx}: Loss is NaN or Inf! Skipping backward. Logits: {output_logits.flatten()[:3]}, Labels: {true_labels_dev.flatten()[:3]}\")\n",
    "                continue \n",
    "            \n",
    "            loss.backward()\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and (param.grad.isnan().any() or param.grad.isinf().any()):\n",
    "                    print(f\"Batch {batch_idx}: NaNs/Infs in gradients of {name}! Zeroing grad.\")\n",
    "                    param.grad = torch.zeros_like(param.grad) \n",
    "            if clip_grad_val:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_val)\n",
    "            optimizer.step()\n",
    "            \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.isnan().any() or param.isinf().any():\n",
    "                    print(f\"CRITICAL: Batch {batch_idx}: NaNs/Infs in param {name} AFTER step!\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            valid_batches_for_loss += 1\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = (torch.sigmoid(output_logits.detach()) > 0.5).cpu().numpy() if CLASSIFICATION_MODE == 'binary' else torch.argmax(output_logits.detach(), dim=1).cpu().numpy()\n",
    "            all_preds_list.extend(preds.flatten().tolist())\n",
    "            all_true_list.extend(true_labels_dev.cpu().numpy().flatten().tolist()) # Use true_labels_dev which is already processed\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        except RuntimeError as e:\n",
    "            if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                print(f\"RuntimeError involving NaN/Inf in train batch {batch_idx}: {e}. Skipping.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Unexpected RuntimeError in train batch {batch_idx}: {e}\")\n",
    "                raise e\n",
    "                \n",
    "    if valid_batches_for_loss == 0: return float('nan'),0,0,0,0,None\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list): return avg_loss,0,0,0,0,None\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_val = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, pos_label=pos_label_val, zero_division=0)\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, zero_division=0)\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(np.unique(all_true_list)) >= 2:\n",
    "        # For AUC with 0/1 preds, it's equivalent to accuracy if preds are hard labels.\n",
    "        # If output_logits were probabilities, this would be more meaningful.\n",
    "        # The current `all_preds_list` are hard 0/1 predictions.\n",
    "        try:\n",
    "            auc = roc_auc_score(all_true_list, all_preds_list) \n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute train AUC (0/1 preds): {e}. True unique: {np.unique(all_true_list)}\")\n",
    "            \n",
    "    return avg_loss, accuracy, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, phase='Validation', return_embeddings_and_ids=False, entity_id_col_name=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list, all_probs_binary_list = [], [], []\n",
    "    \n",
    "    all_node_embeddings_list = []\n",
    "    all_target_node_indices_global_list = [] # Store GLOBAL indices if needed for post-hoc\n",
    "    all_entity_ids_list = []\n",
    "\n",
    "    valid_batches_for_loss = 0\n",
    "    class_report_dict = None\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        # MODIFIED: Unpack new items from loader\n",
    "        for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                         neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "            try:\n",
    "                if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                    print(f\"Warning: Batch {batch_idx} in {phase} has insufficient neighbor_info_batches. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                if return_embeddings_and_ids:\n",
    "                    # MODIFIED: Pass sliced data to model\n",
    "                    output_logits, node_embeddings = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=True\n",
    "                    )\n",
    "                    all_node_embeddings_list.append(node_embeddings.cpu())\n",
    "                    # To get global indices for post-hoc, we need the loader to also provide the original global indices for the batch\n",
    "                    # The current modified loader does not explicitly return target_node_indices_batch_global_cpu in the tuple.\n",
    "                    # For now, if we need global indices, this part needs adjustment in loader output.\n",
    "                    # Assuming target_indices_local_dev can be mapped back if necessary, or loader provides mapping.\n",
    "                    # For simplicity, let's say we store local indices for now, or acknowledge this limitation for post-hoc.\n",
    "                    # If loader.current_idx and batch_size are used, we can reconstruct global indices if not shuffled.\n",
    "                    # Placeholder:\n",
    "                    # all_target_node_indices_global_list.append(target_indices_local_dev.cpu()) # This is NOT global yet\n",
    "                    \n",
    "                else:\n",
    "                    output_logits = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=False\n",
    "                    )\n",
    "\n",
    "                if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                    print(f\"Batch {batch_idx} in {phase}: NaNs or Infs in model output_logits! Skipping metrics for this batch.\")\n",
    "                    continue\n",
    "                \n",
    "                true_labels_dev = batch_labels_dev # Already on device\n",
    "                if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                    true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "                elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                    true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "                \n",
    "                loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "                if not (loss.isnan() or loss.isinf()):\n",
    "                    total_loss += loss.item()\n",
    "                    valid_batches_for_loss +=1\n",
    "                else:\n",
    "                    print(f\"Batch {batch_idx} in {phase}: Loss is NaN or Inf! Logits: {output_logits.flatten()[:5]}\")\n",
    "                \n",
    "                current_batch_true_labels = true_labels_dev.cpu().numpy().flatten().tolist()\n",
    "                current_batch_preds_np, current_batch_probs_np = np.array([]), np.array([])\n",
    "                \n",
    "                if CLASSIFICATION_MODE == 'binary':\n",
    "                    probs = torch.sigmoid(output_logits)\n",
    "                    if probs.isnan().any() or probs.isinf().any():\n",
    "                        print(f\"Batch {batch_idx} in {phase}: Sigmoid probs NaN/Inf.\")\n",
    "                        current_batch_preds_np = np.zeros(len(current_batch_true_labels), dtype=int) \n",
    "                        current_batch_probs_np = np.full(len(current_batch_true_labels), 0.5, dtype=float)\n",
    "                    else:\n",
    "                        current_batch_probs_np = probs.cpu().numpy().flatten()\n",
    "                        current_batch_preds_np = (probs > 0.5).cpu().numpy().flatten()\n",
    "                    all_probs_binary_list.extend(current_batch_probs_np.tolist())\n",
    "                else:\n",
    "                    current_batch_preds_np = torch.argmax(output_logits, dim=1).cpu().numpy().flatten()\n",
    "                \n",
    "                all_preds_list.extend(current_batch_preds_np.tolist())\n",
    "                all_true_list.extend(current_batch_true_labels) \n",
    "                pbar.set_postfix({'loss': loss.item() if not (loss.isnan() or loss.isinf()) else float('nan')})\n",
    "            except RuntimeError as e:\n",
    "                if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                    print(f\"RuntimeError involving NaN/Inf in {phase} batch {batch_idx}: {e}. Skipping.\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Unexpected RuntimeError in {phase} batch {batch_idx}: {e}\")\n",
    "                    raise e\n",
    "\n",
    "    if valid_batches_for_loss == 0: \n",
    "        empty_return = (float('nan'),0,0,0,0, None, [], [], None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list):\n",
    "        print(f\"Warning: Mismatch/empty metric lists in {phase}. True: {len(all_true_list)}, Pred: {len(all_preds_list)}\")\n",
    "        empty_return = (avg_loss,0,0,0,0,None,all_true_list,all_preds_list, None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode_overall = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_overall = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    \n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, pos_label=pos_label_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            target_names = ['Normal (0)', 'Attack (1)']\n",
    "            try: \n",
    "                class_report_dict = classification_report(all_true_list, all_preds_list, target_names=target_names, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    else: \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            try: class_report_dict = classification_report(all_true_list, all_preds_list, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(all_true_list) > 0 :\n",
    "        valid_pairs = [(t, p) for t, p in zip(all_true_list, all_probs_binary_list) if not (isinstance(p, (float, np.floating)) and (np.isnan(p) or np.isinf(p)))]\n",
    "        if len(valid_pairs) > 1:\n",
    "            vt, vp = [p[0] for p in valid_pairs], [p[1] for p in valid_pairs]\n",
    "            if len(np.unique(vt)) >= 2:\n",
    "                try: auc = roc_auc_score(vt, vp)\n",
    "                except ValueError as e: print(f\"Could not compute AUC in {phase} (filtered): {e}. Unique true: {np.unique(vt)}\")\n",
    "            else: print(f\"Not enough unique classes in valid_true_for_auc ({np.unique(vt)}) for AUC in {phase}.\")\n",
    "        else: print(f\"Not enough valid (non-NaN prob) points ({len(valid_pairs)}) for AUC in {phase}.\")\n",
    "    \n",
    "    if return_embeddings_and_ids:\n",
    "        final_embeddings = torch.cat(all_node_embeddings_list, dim=0) if all_node_embeddings_list else torch.empty(0)\n",
    "        # final_indices below would be local if all_target_node_indices_global_list is not populated with global indices\n",
    "        final_indices = torch.cat(all_target_node_indices_global_list, dim=0) if all_target_node_indices_global_list else torch.empty(0) \n",
    "        final_entity_ids = [] # Placeholder, not populated in this version\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict, final_embeddings, final_indices, final_entity_ids\n",
    "    else:\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae711d39-282f-4cda-bb68-276e8cd4306c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW/MODIFIED - Prepare Sequences from Event Embeddings\n",
    "\n",
    "import torch.nn.utils.rnn as rnn_utils # ç¢ºä¿ rnn_utils å·²å°å…¥ï¼Œé›–ç„¶æ­¤å‡½æ•¸ä¸ç›´æ¥ç”¨å®ƒï¼Œä½†å®ƒåœ¨åºåˆ—éƒ¨åˆ†è¢«ä½¿ç”¨\n",
    "\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat,\n",
    "                             raw_file_path_for_loader_ids=None, # æ–°å¢åƒæ•¸\n",
    "                             col_names_for_loader_ids=None):    # æ–°å¢åƒæ•¸\n",
    "    \"\"\"\n",
    "    Gets TGAT embeddings for all events in data_cpu.\n",
    "    Assumes model_tgat is already trained and on the correct device.\n",
    "    \"\"\"\n",
    "    model_tgat.eval()\n",
    "    # ä½¿ç”¨ä¿®æ”¹å¾Œçš„ TemporalNeighborLoaderï¼Œå®ƒå¯ä»¥è™•ç†åŸå§‹æ–‡ä»¶è·¯å¾‘ä»¥é€²è¡Œç‰¹å¾µç›¸ä¼¼æ€§å–æ¨£\n",
    "    loader = TemporalNeighborLoader(\n",
    "        data_cpu, \n",
    "        batch_size_for_gen, \n",
    "        num_neighbors_tgat, \n",
    "        device_tgat, \n",
    "        shuffle=False,\n",
    "        raw_data_file_path_for_ids=raw_file_path_for_loader_ids, # å‚³éåƒæ•¸\n",
    "        col_names_list=col_names_for_loader_ids                    # å‚³éåƒæ•¸\n",
    "    )\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    all_global_indices_list = [] \n",
    "    all_original_labels_list = [] \n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data\n",
    "\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            # å‡è¨­ééš¨æ©Ÿ loader æŒ‰é †åºæä¾›å…¨å±€ç´¢å¼•\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "            _, node_embeddings = model_tgat( # å‡è¨­ TGAT forward è¿”å› (logits, embeddings)\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu())\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu())\n",
    "    \n",
    "    if not all_embeddings_list:\n",
    "        # å¦‚æœæ¨¡å‹æœ‰ attn_layers å±¬æ€§ä¸”ä¸ç‚ºç©ºï¼Œå‰‡ç²å–è¼¸å‡ºç¶­åº¦ï¼Œå¦å‰‡ä½¿ç”¨é è¨­å€¼\n",
    "        emb_dim_placeholder = model_tgat.attn_layers[-1].n_out_dim_layer \\\n",
    "            if hasattr(model_tgat, 'attn_layers') and model_tgat.attn_layers \\\n",
    "            else (model_tgat.output_mlp[0].in_features if hasattr(model_tgat, 'output_mlp') and model_tgat.output_mlp else 128) # å‚™ç”¨å›é€€\n",
    "        \n",
    "        # è¿”å›å…©å€‹å€¼ä»¥åŒ¹é…è§£åŒ…\n",
    "        return torch.empty(0, emb_dim_placeholder), torch.empty(0, dtype=torch.long) \n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', # 'any_attack', 'all_attack', 'majority_attack'\n",
    "                               classification_mode='binary'): # For KDD, labels are binary or multiclass event-wise\n",
    "    \"\"\"\n",
    "    Creates sequences of embeddings and corresponding sequence labels.\n",
    "    event_labels should be for binary classification (0 for normal, 1 for attack event).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length]\n",
    "        seq_event_labels = event_labels[i : i + sequence_length] # These are event-level labels\n",
    "\n",
    "        if classification_mode == 'binary':\n",
    "            # Determine sequence label based on event labels within the sequence\n",
    "            if label_mode == 'any_attack':\n",
    "                # If any event in the sequence is an attack, the sequence is an attack\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                # Only if all events in sequence are attacks\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                # If majority of events are attacks\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: # Default to 'any_attack'\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # Multiclass - how to define sequence label? For now, let's assume binary sequence target.\n",
    "            # Or, one could try to predict the dominant attack type in the sequence, or a multi-label output.\n",
    "            # This part needs more sophisticated handling for multiclass sequence labeling.\n",
    "            # For simplicity, we'll stick to binary sequence classification (attack vs. normal sequence).\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is not deeply implemented. Defaulting to binary 'any_attack'.\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal in multiclass too\n",
    "\n",
    "        sequences.append(seq)\n",
    "        sequence_labels.append(label)\n",
    "    \n",
    "    if not sequences:\n",
    "        # Return empty tensors with expected structure if no sequences are generated\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "\n",
    "    # For PackedSequence, we need lengths of sequences before padding\n",
    "    # In this sliding window approach, all sequences have the same length `sequence_length`\n",
    "    lengths = [sequence_length] * len(sequences)\n",
    "    \n",
    "    # Pad sequences to the max length (which is sequence_length here)\n",
    "    # `sequences` is a list of Tensors [ (seq_len, embed_dim), ... ]\n",
    "    # Need to stack them and then pad if lengths were variable. Here they are fixed.\n",
    "    padded_sequences = torch.stack(sequences) # (num_sequences, sequence_length, embedding_dim)\n",
    "    \n",
    "    return sequences, sequence_labels, padded_sequences, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32) # For BCEWithLogitsLoss\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return sequence, its actual length, and its label\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed(batch):\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already padded to the same length `sequence_length`\n",
    "    padded_sequences = torch.stack(sequences) # (batch_size, sequence_length, embedding_dim)\n",
    "    \n",
    "    # Create PackedSequence\n",
    "    # Sort by lengths in descending order for pack_padded_sequence\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    sorted_lengths, sorted_idx = lengths.sort(descending=True)\n",
    "    sorted_sequences = padded_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Also sort labels according to sorted_idx\n",
    "    labels = torch.stack(labels)[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9075d7-1512-48d5-bfa9-2f543572affa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW - Training and Evaluation for Sequence Aggregator Model\n",
    "\n",
    "def train_sequence_epoch(seq_model, loader, optimizer, criterion_seq, device):\n",
    "    seq_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "        if loss.isnan() or loss.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds.extend(preds.flatten().tolist())\n",
    "        all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true, all_seq_probs = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds = (probs > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds.extend(preds.flatten().tolist())\n",
    "            all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs.extend(probs.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    \n",
    "    auc = None\n",
    "    if all_seq_true and all_seq_probs and len(np.unique(all_seq_true)) >= 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_seq_true, all_seq_probs)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(phase, avg_loss, accuracy, precision, recall, f1, auc, phase=f\"{phase} Results\")\n",
    "    return avg_loss, accuracy, precision, recall, f1, auc, all_seq_true, all_seq_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9261f6-ce2d-418d-a83c-c16c952b719c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Sequence Modeling Additions and Modified Pipeline (Conceptual)\n",
    "# Ensure all necessary imports from the original notebook are present\n",
    "# e.g., torch, nn, optim, tqdm, sklearn.metrics, plt, np, os, json, time, Dataset, DataLoader, F\n",
    "# from torch.utils.data import Dataset, DataLoader # Add if not already imported globally\n",
    "\n",
    "\n",
    "# 1. EventSequenceAggregator Model Definition\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class EventSequenceAggregator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, num_classes, dropout=0.1, rnn_type='GRU'):\n",
    "        super(EventSequenceAggregator, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.rnn_type = rnn_type.upper()\n",
    "\n",
    "        if self.rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type. Choose 'GRU' or 'LSTM'.\")\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout_layer = nn.Dropout(dropout) # Renamed to avoid conflict\n",
    "\n",
    "    def forward(self, packed_event_embeddings):\n",
    "        # packed_event_embeddings is a PackedSequence object\n",
    "        if self.rnn_type == 'GRU':\n",
    "            # output is (batch, seq_len, hidden_dim) for packed sequence\n",
    "            # hidden is (num_layers, batch_size, hidden_dim)\n",
    "            _, hidden = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = hidden[-1, :, :] \n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            # output is (batch, seq_len, hidden_dim)\n",
    "            # h_n is (num_layers, batch_size, hidden_dim)\n",
    "            # c_n is (num_layers, batch_size, hidden_dim)\n",
    "            _, (h_n, _) = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = h_n[-1, :, :]\n",
    "        \n",
    "        out = self.dropout_layer(last_hidden)\n",
    "        out = self.fc(out) \n",
    "        return out\n",
    "\n",
    "# 2. Functions to Prepare Sequences from Event Embeddings\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat):\n",
    "    model_tgat.eval()\n",
    "    # Use the modified TemporalNeighborLoader that handles sliced data loading\n",
    "    loader = TemporalNeighborLoader(data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat, shuffle=False)\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    all_global_indices_list = [] \n",
    "    all_original_labels_list = [] \n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data\n",
    "\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            # Assuming non-shuffled loader gives sequential global indices\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "            _, node_embeddings = model_tgat( # Assuming TGAT forward returns (logits, embeddings)\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu())\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu())\n",
    "\n",
    "    if not all_embeddings_list:\n",
    "        # Determine embedding_dim from model or data if possible, else use a placeholder\n",
    "        emb_dim_placeholder = model_tgat.attn_layers[-1].n_out_dim_layer if hasattr(model_tgat, 'attn_layers') and model_tgat.attn_layers else 128 # Fallback\n",
    "        return torch.empty(0, emb_dim_placeholder), torch.empty(0, dtype=torch.long), torch.empty(0)\n",
    "\n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels\n",
    "\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', classification_mode='binary'):\n",
    "    sequences_as_tensors = [] # Store list of tensors directly\n",
    "    sequence_labels_list = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length] # (sequence_length, embedding_dim)\n",
    "        seq_event_labels = event_labels[i : i + sequence_length]\n",
    "\n",
    "        label = 0 # Default to normal\n",
    "        if classification_mode == 'binary': # Ensure event_labels are binary (0 or 1)\n",
    "            if label_mode == 'any_attack':\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: \n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # For multiclass event labels, defining sequence label needs care\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is complex. Defaulting to binary 'any_attack' (event_label > 0 is attack).\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal\n",
    "\n",
    "        sequences_as_tensors.append(seq)\n",
    "        sequence_labels_list.append(label)\n",
    "    \n",
    "    if not sequences_as_tensors:\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    padded_sequences = torch.stack(sequences_as_tensors) # (num_sequences, sequence_length, embedding_dim)\n",
    "    lengths = torch.full((len(sequences_as_tensors),), sequence_length, dtype=torch.long) # All sequences have same length\n",
    "    \n",
    "    return sequence_labels_list, padded_sequences, lengths\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        # Ensure sequence_labels is a tensor\n",
    "        if isinstance(sequence_labels, list):\n",
    "            self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32)\n",
    "        elif isinstance(sequence_labels, torch.Tensor):\n",
    "            self.sequence_labels = sequence_labels.float()\n",
    "        else:\n",
    "            raise TypeError(f\"sequence_labels must be a list or Tensor, got {type(sequence_labels)}\")\n",
    "\n",
    "        self.sequence_lengths = sequence_lengths # This is a tensor of lengths for each sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed_fixed_length(batch): # Simplified for fixed length sequences from sliding window\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already Tensors of shape (sequence_length, embedding_dim)\n",
    "    # Stack them to create (batch_size, sequence_length, embedding_dim)\n",
    "    stacked_sequences = torch.stack(sequences)\n",
    "    \n",
    "    # lengths are all the same (SEQUENCE_LENGTH), but pack_padded_sequence still needs them\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.long) \n",
    "    \n",
    "    # Sort by lengths in descending order (though here all are same)\n",
    "    sorted_lengths, sorted_idx = lengths_tensor.sort(descending=True)\n",
    "    sorted_sequences = stacked_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Sort labels\n",
    "    labels_tensor = torch.stack([l if isinstance(l, torch.Tensor) else torch.tensor(l) for l in labels])\n",
    "    sorted_labels = labels_tensor[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, sorted_labels\n",
    "\n",
    "\n",
    "# 3. Training and Evaluation Functions for Sequence Model\n",
    "def train_sequence_epoch(seq_model, loader, optimizer_seq, criterion_seq, device_seq):\n",
    "    seq_model.train()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_epoch, all_seq_true_epoch = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "        labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer_seq.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "        if loss_seq.isnan() or loss_seq.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Logits: {output_logits_seq.flatten()[:3]}, Labels: {labels_batch_seq.flatten()[:3]}. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss_seq.backward()\n",
    "        optimizer_seq.step()\n",
    "        \n",
    "        total_loss_seq += loss_seq.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds_seq = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds_epoch.extend(preds_seq.flatten().tolist())\n",
    "        all_seq_true_epoch.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss_seq.item()})\n",
    "        \n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    # Ensure all_seq_true_epoch is not empty before calculating metrics\n",
    "    if not all_seq_true_epoch:\n",
    "        print(\"Warning: No true labels collected in sequence training epoch.\")\n",
    "        return avg_loss_seq, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    accuracy_seq = accuracy_score(all_seq_true_epoch, all_seq_preds_epoch)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_epoch, all_seq_preds_epoch, average='binary', zero_division=0)\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device_seq, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_eval, all_seq_true_eval, all_seq_probs_eval = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "            labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "            if loss_seq.isnan() or loss_seq.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss_seq += loss_seq.item()\n",
    "            \n",
    "            probs_seq = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds_seq = (probs_seq > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds_eval.extend(preds_seq.flatten().tolist())\n",
    "            all_seq_true_eval.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs_eval.extend(probs_seq.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss_seq.item()})\n",
    "\n",
    "    if not all_seq_true_eval: # Check if any data was processed\n",
    "        print(f\"Warning: No true labels collected in sequence evaluation phase {phase}.\")\n",
    "        return float('nan'), 0.0, 0.0, 0.0, 0.0, None, [], []\n",
    "\n",
    "\n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy_seq = accuracy_score(all_seq_true_eval, all_seq_preds_eval)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_eval, all_seq_preds_eval, average='binary', zero_division=0)\n",
    "    \n",
    "    auc_seq = None\n",
    "    if all_seq_probs_eval and len(np.unique(all_seq_true_eval)) >= 2:\n",
    "        try:\n",
    "            auc_seq = roc_auc_score(all_seq_true_eval, all_seq_probs_eval)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(f\"{phase} Seq Aggregator\", avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, phase=f\"{phase} Seq Results\")\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, all_seq_true_eval, all_seq_preds_eval\n",
    "\n",
    "\n",
    "# 4. Modified train_pipeline (Conceptual - integrate stage 2)\n",
    "# This is a high-level sketch. The original train_pipeline needs to be carefully refactored.\n",
    "# For now, I will keep the original train_pipeline as is, and the sequence training\n",
    "# will be a separate set of calls in the __main__ block after TGAT training.\n",
    "\n",
    "# --- Keeping original train_pipeline for TGAT ---\n",
    "# The original train_pipeline in cell \"d6727e62-27d4-4ac9-8ffa-2563c1be7743\"\n",
    "# will train and save the best TGAT model. We will use that saved model.\n",
    "\n",
    "# --- Add these to your global configuration (e.g., Cell 2 of the notebook) ---\n",
    "# Make sure these are defined if you haven't already\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE # Use TGAT's batch size for consistency or define separately\n",
    "SEQUENCE_LENGTH = 10 \n",
    "STEP_SIZE = 5      \n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64  \n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 20 # Fewer epochs for the sequence model might be sufficient\n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM # This is the output dim of TGAT's attention layers, used as input to its MLP\n",
    "                                          # and thus the dimension of embeddings `h` returned by TGAT\n",
    "SEQ_MODEL_HIDDEN_DIM = 128   \n",
    "SEQ_MODEL_NUM_LAYERS = 1 # GRU/LSTM layers   \n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'        \n",
    "SEQ_MODEL_DROPOUT = 0.2\n",
    "\n",
    "# Ensure DEVICE is defined globally\n",
    "# DEVICE = get_device() \n",
    "\n",
    "# It's better to run sequence model training as a separate step after TGAT training is complete.\n",
    "# So, the `train_pipeline` function itself will not be massively changed to include stage 2.\n",
    "# Instead, the __main__ block will call TGAT training, then sequence model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebd06a-8c64-4583-a08b-08be53e7298e",
   "metadata": {},
   "source": [
    "## 8. Main Training Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6727e62-27d4-4ac9-8ffa-2563c1be7743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_pipeline function (FINAL, no lines omitted)\n",
    "def train_pipeline():\n",
    "    # --- STAGE 1: Train TGAT Event-Level Model --------------------------------\n",
    "    print(\"--- Stage 1: TGAT Event-Level Model Training ---\")\n",
    "    stage1_start_time = time.time()\n",
    "\n",
    "    processed_train_file_path = globals().get(\n",
    "        \"PROCESSED_TRAIN_FILE\",\n",
    "        \"./processed_data_nslkdd/train_temporal_data_nslkdd.pt\",\n",
    "    )\n",
    "    processed_test_file_path = globals().get(\n",
    "        \"PROCESSED_TEST_FILE\",\n",
    "        \"./processed_data_nslkdd/test_temporal_data_nslkdd.pt\",\n",
    "    )\n",
    "    metadata_file_path = globals().get(\n",
    "        \"METADATA_FILE\",\n",
    "        \"./processed_data_nslkdd/metadata_nslkdd.json\",\n",
    "    )\n",
    "    classification_mode_val = globals().get(\"CLASSIFICATION_MODE\", \"binary\")\n",
    "\n",
    "    if not all(\n",
    "        k in globals()\n",
    "        for k in [\n",
    "            \"PROCESSED_TRAIN_FILE\",\n",
    "            \"METADATA_FILE\",\n",
    "            \"CLASSIFICATION_MODE\",\n",
    "            \"PROCESSED_TEST_FILE\",\n",
    "        ]\n",
    "    ):\n",
    "        print(\n",
    "            \"Warning: Some essential global configuration variables for data loading might be missing. Using defaults.\"\n",
    "        )\n",
    "\n",
    "    train_data_cpu_tgat, metadata_tgat, num_classes_meta_tgat, pos_weight_cpu_tgat = load_processed_data(\n",
    "        processed_train_file_path, metadata_file_path, classification_mode_val\n",
    "    )\n",
    "    test_data_cpu_tgat, _, _, _ = load_processed_data(\n",
    "        processed_test_file_path, metadata_file_path, classification_mode_val\n",
    "    )\n",
    "\n",
    "    NODE_FEAT_DIM_RUNTIME_TGAT = metadata_tgat[\"NODE_FEAT_DIM\"]\n",
    "\n",
    "    device_val = globals().get(\n",
    "        \"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "\n",
    "    # ----- Loss (always BCE + pos_weight) ------------------------------------\n",
    "    if classification_mode_val == \"binary\":\n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = 1\n",
    "        criterion_tgat = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=pos_weight_cpu_tgat.to(device_val)\n",
    "            if pos_weight_cpu_tgat is not None\n",
    "            else None\n",
    "        )\n",
    "    else:\n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = metadata_tgat.get(\n",
    "            \"NUM_CLASSES_MULTI\", num_classes_meta_tgat\n",
    "        )\n",
    "        criterion_tgat = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ----- Hyper-parameters ---------------------------------------------------\n",
    "    epochs_val = globals().get(\"EPOCHS\", 30)  # â† default 30\n",
    "    scheduler_type_val = globals().get(\"LR_SCHEDULER\", \"cosine\")\n",
    "    batch_size_val = globals().get(\"BATCH_SIZE\", 256)\n",
    "    learning_rate_val = globals().get(\"LEARNING_RATE\", 5e-4)\n",
    "    hidden_dim_val = globals().get(\"HIDDEN_DIM\", 256)\n",
    "    time_dim_val = globals().get(\"TIME_DIM\", 64)\n",
    "    n_layers_val = globals().get(\"N_LAYERS\", 2)\n",
    "    n_heads_val = globals().get(\"N_HEADS\", 4)\n",
    "    dropout_val = globals().get(\"DROPOUT\", 0.3)\n",
    "    weight_decay_val = globals().get(\"WEIGHT_DECAY\", 1e-5)\n",
    "\n",
    "    print(\"\\n--- TGAT Training Configuration ---\")\n",
    "    print(\n",
    "        f\"Device: {device_val}, Epochs: {epochs_val}, Batch Size: {batch_size_val}, \"\n",
    "        f\"LR: {learning_rate_val}, Scheduler: {scheduler_type_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Node Feat Dim: {NODE_FEAT_DIM_RUNTIME_TGAT}, Hidden Dim: {hidden_dim_val}, \"\n",
    "        f\"Time Emb: {time_dim_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"TGAT Layers: {n_layers_val}, Heads: {n_heads_val}, Dropout: {dropout_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"TGAT Output Dim: {ACTUAL_NUM_OUTPUT_CLASSES_TGAT}, Mode: {classification_mode_val}\"\n",
    "    )\n",
    "    print(f\"TGAT Loss: {type(criterion_tgat).__name__}\")\n",
    "    print(f\"----------------------------\\n\")\n",
    "\n",
    "    # ----- Model & Optim ------------------------------------------------------\n",
    "    tgat_model = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT,\n",
    "        time_emb_dim=time_dim_val,\n",
    "        n_head=n_heads_val,\n",
    "        n_layers=n_layers_val,\n",
    "        hidden_dim_per_layer=hidden_dim_val,\n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT,\n",
    "        dropout=dropout_val,\n",
    "    ).to(device_val)\n",
    "\n",
    "    optimizer_tgat = optim.Adam(\n",
    "        tgat_model.parameters(), lr=learning_rate_val, weight_decay=weight_decay_val\n",
    "    )\n",
    "\n",
    "    if scheduler_type_val == \"cosine\":\n",
    "        lr_scheduler_tgat = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_tgat, T_max=20, eta_min=1e-6\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler_tgat = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer_tgat,\n",
    "            mode=\"max\",\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            verbose=True,\n",
    "            min_lr=1e-7,\n",
    "        )\n",
    "\n",
    "    # ----- DataLoader ---------------------------------------------------------\n",
    "    num_neighbors_val = globals().get(\"NUM_NEIGHBORS\", [10, 5])\n",
    "    train_loader_tgat = TemporalNeighborLoader(\n",
    "        train_data_cpu_tgat,\n",
    "        batch_size_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader_tgat = TemporalNeighborLoader(\n",
    "        test_data_cpu_tgat,\n",
    "        batch_size_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    best_val_f1_attack_tgat = -1.0\n",
    "    history_tgat = {\n",
    "        k: []\n",
    "        for k in [\n",
    "            \"train_loss\",\n",
    "            \"train_acc\",\n",
    "            \"train_f1\",\n",
    "            \"train_auc\",\n",
    "            \"val_loss\",\n",
    "            \"val_acc\",\n",
    "            \"val_f1\",\n",
    "            \"val_f1_attack\",\n",
    "            \"val_auc\",\n",
    "        ]\n",
    "    }\n",
    "    epochs_without_improvement_tgat = 0\n",
    "    early_stopping_patience_val = globals().get(\"EARLY_STOPPING_PATIENCE\", 20)\n",
    "    clip_grad_norm_val = globals().get(\"CLIP_GRAD_NORM\", 1.0)\n",
    "    model_save_dir_val = globals().get(\"MODEL_SAVE_DIR\", \"./saved_models_nslkdd/\")\n",
    "    best_model_name_val = globals().get(\n",
    "        \"BEST_MODEL_NAME\", \"best_tgat_model_nslkdd.pth\"\n",
    "    )\n",
    "\n",
    "    # ========================== Epoch loop ====================================\n",
    "    for epoch_tgat in range(epochs_val):\n",
    "        epoch_str_display_tgat = f\"TGAT Epoch {epoch_tgat + 1}/{epochs_val}\"\n",
    "        print(f\"--- {epoch_str_display_tgat} ---\")\n",
    "\n",
    "        # ---- train -----------------------------------------------------------\n",
    "        (\n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            train_prec,\n",
    "            train_rec,\n",
    "            train_f1,\n",
    "            train_auc,\n",
    "        ) = train_epoch(\n",
    "            tgat_model,\n",
    "            train_loader_tgat,\n",
    "            optimizer_tgat,\n",
    "            criterion_tgat,\n",
    "            clip_grad_norm_val,\n",
    "        )\n",
    "        print_metrics(\n",
    "            epoch_str_display_tgat,\n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            train_prec,\n",
    "            train_rec,\n",
    "            train_f1,\n",
    "            train_auc,\n",
    "            phase=\"Train TGAT\",\n",
    "        )\n",
    "        for k, v in zip(\n",
    "            [\"loss\", \"acc\", \"f1\", \"auc\"],\n",
    "            [train_loss, train_acc, train_f1, train_auc],\n",
    "        ):\n",
    "            history_tgat[f\"train_{k}\"].append(\n",
    "                v if v is not None and not (isinstance(v, float) and np.isnan(v)) else np.nan\n",
    "            )\n",
    "\n",
    "        # ---- validation ------------------------------------------------------\n",
    "        (\n",
    "            val_loss,\n",
    "            val_acc,\n",
    "            val_prec,\n",
    "            val_rec,\n",
    "            val_f1,\n",
    "            val_auc,\n",
    "            _,\n",
    "            _,\n",
    "            val_class_report_dict_tgat,\n",
    "        ) = evaluate_model(\n",
    "            tgat_model,\n",
    "            test_loader_tgat,\n",
    "            criterion_tgat,\n",
    "            phase=\"Validation TGAT\",\n",
    "            return_embeddings_and_ids=False,\n",
    "        )\n",
    "\n",
    "        # -- Attack F1 ---------------------------------------------------------\n",
    "        val_f1_attack_current_tgat = np.nan\n",
    "        if (\n",
    "            classification_mode_val == \"binary\"\n",
    "            and val_class_report_dict_tgat\n",
    "            and isinstance(val_class_report_dict_tgat, dict)\n",
    "        ):\n",
    "            attack_label_str = (\n",
    "                \"Attack (1)\"\n",
    "                if \"Attack (1)\" in val_class_report_dict_tgat\n",
    "                else (\"1\" if \"1\" in val_class_report_dict_tgat else None)\n",
    "            )\n",
    "            if (\n",
    "                attack_label_str\n",
    "                and attack_label_str in val_class_report_dict_tgat\n",
    "                and val_class_report_dict_tgat[attack_label_str].get(\"f1-score\")\n",
    "                is not None\n",
    "            ):\n",
    "                val_f1_attack_current_tgat = val_class_report_dict_tgat[\n",
    "                    attack_label_str\n",
    "                ].get(\"f1-score\")\n",
    "        elif val_f1 is not None and not np.isnan(val_f1):\n",
    "            val_f1_attack_current_tgat = val_f1\n",
    "\n",
    "        print_metrics(\n",
    "            epoch_str_display_tgat,\n",
    "            val_loss,\n",
    "            val_acc,\n",
    "            val_prec,\n",
    "            val_rec,\n",
    "            val_f1,\n",
    "            val_auc,\n",
    "            phase=\"Validation TGAT\",\n",
    "            class_report=str(val_class_report_dict_tgat)\n",
    "            if val_class_report_dict_tgat\n",
    "            else \"N/A\",\n",
    "        )\n",
    "        history_tgat[\"val_f1_attack\"].append(\n",
    "            val_f1_attack_current_tgat\n",
    "            if not np.isnan(val_f1_attack_current_tgat)\n",
    "            else np.nan\n",
    "        )\n",
    "        for k, v in zip(\n",
    "            [\"loss\", \"acc\", \"f1\", \"auc\"], [val_loss, val_acc, val_f1, val_auc]\n",
    "        ):\n",
    "            history_tgat[f\"val_{k}\"].append(\n",
    "                v if v is not None and not (isinstance(v, float) and np.isnan(v)) else np.nan\n",
    "            )\n",
    "\n",
    "        # ---- scheduler step --------------------------------------------------\n",
    "        if scheduler_type_val == \"cosine\":\n",
    "            lr_scheduler_tgat.step()\n",
    "        else:\n",
    "            scheduler_metric = (\n",
    "                val_f1_attack_current_tgat\n",
    "                if not np.isnan(val_f1_attack_current_tgat)\n",
    "                else -val_loss\n",
    "            )\n",
    "            lr_scheduler_tgat.step(scheduler_metric)\n",
    "\n",
    "        current_lr_tgat = optimizer_tgat.param_groups[0][\"lr\"]\n",
    "        print(f\"TGAT Current LR: {current_lr_tgat}\")\n",
    "\n",
    "        # ---- save best -------------------------------------------------------\n",
    "        if (\n",
    "            not np.isnan(val_f1_attack_current_tgat)\n",
    "            and val_f1_attack_current_tgat > best_val_f1_attack_tgat\n",
    "        ):\n",
    "            best_val_f1_attack_tgat = val_f1_attack_current_tgat\n",
    "            os.makedirs(model_save_dir_val, exist_ok=True)\n",
    "            torch.save(\n",
    "                tgat_model.state_dict(),\n",
    "                os.path.join(model_save_dir_val, best_model_name_val),\n",
    "            )\n",
    "            print(\n",
    "                f\"{epoch_str_display_tgat}: New best TGAT model saved! \"\n",
    "                f\"Val F1 (Attack): {best_val_f1_attack_tgat:.4f}\"\n",
    "            )\n",
    "            epochs_without_improvement_tgat = 0\n",
    "        else:\n",
    "            epochs_without_improvement_tgat += 1\n",
    "            print(\n",
    "                f\"{epoch_str_display_tgat}: No improvement count: {epochs_without_improvement_tgat} \"\n",
    "                f\"(Current F1 Attack: \"\n",
    "                f\"{val_f1_attack_current_tgat if not np.isnan(val_f1_attack_current_tgat) else 'NaN'}, \"\n",
    "                f\"Best F1 Attack: \"\n",
    "                f\"{best_val_f1_attack_tgat if best_val_f1_attack_tgat != -1.0 else 'N/A'}).\"\n",
    "            )\n",
    "\n",
    "        if epochs_without_improvement_tgat >= early_stopping_patience_val:\n",
    "            print(\n",
    "                f\"TGAT Early stopping triggered after \"\n",
    "                f\"{early_stopping_patience_val} epochs without improvement.\"\n",
    "            )\n",
    "            break\n",
    "        print(\"---------------------------------\\n\")\n",
    "\n",
    "    stage1_time = time.time() - stage1_start_time\n",
    "    best_val_f1_attack_tgat_str = (\n",
    "        f\"{best_val_f1_attack_tgat:.4f}\"\n",
    "        if best_val_f1_attack_tgat != -1.0 and not np.isnan(best_val_f1_attack_tgat)\n",
    "        else \"N/A\"\n",
    "    )\n",
    "    print(\n",
    "        f\"--- TGAT Training (Stage 1) Finished in {stage1_time:.2f}s. \"\n",
    "        f\"Best Val F1 (Attack): {best_val_f1_attack_tgat_str} ---\"\n",
    "    )\n",
    "\n",
    "    # ============================= STAGE 2 ===================================\n",
    "    # ï¼ˆä»¥ä¸‹ Sequence Aggregator å…§å®¹ä¿æŒåŸæ¨£ï¼Œæœªåšä»»ä½•è¡Œåˆªæ¸›ï¼‰\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n\\n--- Stage 2: Sequence Aggregator Model Training ---\")\n",
    "    stage2_start_time = time.time()\n",
    "\n",
    "    best_tgat_model_path = os.path.join(model_save_dir_val, best_model_name_val)\n",
    "    if not os.path.exists(best_tgat_model_path):\n",
    "        print(\n",
    "            f\"Error: Best TGAT model not found at {best_tgat_model_path} from Stage 1.\"\n",
    "            \" Cannot proceed with Stage 2.\"\n",
    "        )\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )  # MODIFIED RETURN\n",
    "\n",
    "    tgat_model_for_embeddings = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT,\n",
    "        time_emb_dim=time_dim_val,\n",
    "        n_head=n_heads_val,\n",
    "        n_layers=n_layers_val,\n",
    "        hidden_dim_per_layer=hidden_dim_val,\n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT,\n",
    "        dropout=dropout_val,\n",
    "    ).to(device_val)\n",
    "    tgat_model_for_embeddings.load_state_dict(\n",
    "        torch.load(best_tgat_model_path, map_location=device_val)\n",
    "    )\n",
    "    tgat_model_for_embeddings.eval()\n",
    "\n",
    "    batch_size_seq_embed_gen_val = globals().get(\"BATCH_SIZE_SEQ_EMBED_GEN\", batch_size_val)\n",
    "\n",
    "    train_event_embeddings, train_event_labels_tgat = get_all_event_embeddings(\n",
    "        tgat_model_for_embeddings,\n",
    "        train_data_cpu_tgat,\n",
    "        batch_size_seq_embed_gen_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "    )\n",
    "    test_event_embeddings = torch.empty(0)\n",
    "    test_event_labels_tgat = torch.empty(0)\n",
    "    if train_event_embeddings.numel() > 0:\n",
    "        test_event_embeddings, test_event_labels_tgat = get_all_event_embeddings(\n",
    "            tgat_model_for_embeddings,\n",
    "            test_data_cpu_tgat,\n",
    "            batch_size_seq_embed_gen_val,\n",
    "            num_neighbors_val,\n",
    "            device_val,\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: Failed to generate train event embeddings for Stage 2. Aborting Stage 2.\")\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    train_event_labels_binary_squeezed = (\n",
    "        (train_event_labels_tgat.squeeze() > 0).long()\n",
    "        if classification_mode_val == \"multiclass\"\n",
    "        else train_event_labels_tgat.squeeze().long()\n",
    "        if train_event_labels_tgat.numel() > 0\n",
    "        else torch.empty(0, dtype=torch.long)\n",
    "    )\n",
    "    test_event_labels_binary_squeezed = (\n",
    "        (test_event_labels_tgat.squeeze() > 0).long()\n",
    "        if classification_mode_val == \"multiclass\"\n",
    "        else test_event_labels_tgat.squeeze().long()\n",
    "        if test_event_labels_tgat.numel() > 0\n",
    "        else torch.empty(0, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "    sequence_length_val = globals().get(\"SEQUENCE_LENGTH\", 10)\n",
    "    step_size_val = globals().get(\"STEP_SIZE\", 5)\n",
    "    seq_label_mode_val = globals().get(\"SEQ_LABEL_MODE\", \"any_attack\")\n",
    "\n",
    "    returned_train_seq_labels_list = []\n",
    "    returned_train_padded_sequences = torch.empty(0)\n",
    "    returned_train_seq_lengths = torch.empty(0, dtype=torch.long)\n",
    "    returned_test_seq_labels_list = []\n",
    "    returned_test_padded_sequences = torch.empty(0)\n",
    "    returned_test_seq_lengths = torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    if train_event_embeddings.numel() > 0 and train_event_labels_binary_squeezed.numel() > 0:\n",
    "        (\n",
    "            _,\n",
    "            returned_train_seq_labels_list,\n",
    "            returned_train_padded_sequences,\n",
    "            returned_train_seq_lengths,\n",
    "        ) = create_embedding_sequences(\n",
    "            train_event_embeddings,\n",
    "            train_event_labels_binary_squeezed,\n",
    "            sequence_length_val,\n",
    "            step_size_val,\n",
    "            seq_label_mode_val,\n",
    "            \"binary\",\n",
    "        )\n",
    "        if returned_train_padded_sequences.numel() == 0:\n",
    "            print(\"No training sequences generated. Aborting Stage 2.\")\n",
    "            return (\n",
    "                history_tgat,\n",
    "                None,\n",
    "                test_event_embeddings,\n",
    "                test_event_labels_binary_squeezed,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "\n",
    "        train_sequence_dataset = EmbeddingSequenceDataset(\n",
    "            returned_train_padded_sequences,\n",
    "            returned_train_seq_labels_list,\n",
    "            returned_train_seq_lengths,\n",
    "        )\n",
    "        batch_size_seq_model_val = globals().get(\"BATCH_SIZE_SEQ_MODEL\", 64)\n",
    "        train_sequence_loader = DataLoader(\n",
    "            train_sequence_dataset,\n",
    "            batch_size=batch_size_seq_model_val,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn_packed_fixed_length,\n",
    "        )\n",
    "        print(f\"Created {len(train_sequence_dataset)} training sequences.\")\n",
    "    else:\n",
    "        print(\"No train event embeddings or labels. Aborting Stage 2.\")\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            test_event_embeddings,\n",
    "            test_event_labels_binary_squeezed,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    test_sequence_loader = None\n",
    "    if test_event_embeddings.numel() > 0 and test_event_labels_binary_squeezed.numel() > 0:\n",
    "        (\n",
    "            _,\n",
    "            returned_test_seq_labels_list,\n",
    "            returned_test_padded_sequences,\n",
    "            returned_test_seq_lengths,\n",
    "        ) = create_embedding_sequences(\n",
    "            test_event_embeddings,\n",
    "            test_event_labels_binary_squeezed,\n",
    "            sequence_length_val,\n",
    "            step_size_val,\n",
    "            seq_label_mode_val,\n",
    "            \"binary\",\n",
    "        )\n",
    "        if returned_test_padded_sequences.numel() > 0:\n",
    "            test_sequence_dataset = EmbeddingSequenceDataset(\n",
    "                returned_test_padded_sequences,\n",
    "                returned_test_seq_labels_list,\n",
    "                returned_test_seq_lengths,\n",
    "            )\n",
    "            test_sequence_loader = DataLoader(\n",
    "                test_sequence_dataset,\n",
    "                batch_size=batch_size_seq_model_val,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn_packed_fixed_length,\n",
    "            )\n",
    "            print(f\"Created {len(test_sequence_dataset)} test sequences.\")\n",
    "        else:\n",
    "            print(\"No test sequences generated for sequence model evaluation.\")\n",
    "    else:\n",
    "        print(\"No test event embeddings or labels available for test sequences.\")\n",
    "\n",
    "    seq_model_input_dim = (\n",
    "        train_event_embeddings.shape[1] if train_event_embeddings.numel() > 0 else hidden_dim_val\n",
    "    )\n",
    "    seq_model_hidden_dim_val = globals().get(\"SEQ_MODEL_HIDDEN_DIM\", 128)\n",
    "    seq_model_num_layers_val = globals().get(\"SEQ_MODEL_NUM_LAYERS\", 1)\n",
    "    seq_model_dropout_val = globals().get(\"SEQ_MODEL_DROPOUT\", 0.2)\n",
    "    seq_model_rnn_type_val = globals().get(\"SEQ_MODEL_RNN_TYPE\", \"GRU\")\n",
    "\n",
    "    sequence_model = EventSequenceAggregator(\n",
    "        embedding_dim=seq_model_input_dim,\n",
    "        hidden_dim=seq_model_hidden_dim_val,\n",
    "        num_layers=seq_model_num_layers_val,\n",
    "        num_classes=1,\n",
    "        dropout=seq_model_dropout_val,\n",
    "        rnn_type=seq_model_rnn_type_val,\n",
    "    ).to(device_val)\n",
    "\n",
    "    lr_seq_model_val = globals().get(\"LEARNING_RATE_SEQ_MODEL\", 1e-4)\n",
    "    criterion_seq = nn.BCEWithLogitsLoss()\n",
    "    optimizer_seq = optim.Adam(sequence_model.parameters(), lr=lr_seq_model_val)\n",
    "\n",
    "    epochs_seq_model_val = globals().get(\"EPOCHS_SEQ_MODEL\", 20)\n",
    "    print(\n",
    "        f\"\\n--- Training Sequence Aggregator Model ({seq_model_rnn_type_val}) ---\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Input Embedding Dim: {seq_model_input_dim}, Sequence Length: {sequence_length_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Seq Model: Hidden={seq_model_hidden_dim_val}, Layers={seq_model_num_layers_val}, \"\n",
    "        f\"Dropout={seq_model_dropout_val}\"\n",
    "    )\n",
    "    print(f\"Optimizer: Adam, LR={lr_seq_model_val}. Epochs: {epochs_seq_model_val}\")\n",
    "\n",
    "    history_sequence_model = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "        \"val_auc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch_seq in range(epochs_seq_model_val):\n",
    "        print(f\"Sequence Model Epoch {epoch_seq + 1}/{epochs_seq_model_val}\")\n",
    "        if train_sequence_loader and len(train_sequence_loader) > 0:\n",
    "            train_loss_s, train_acc_s, _, _, train_f1_s = train_sequence_epoch(\n",
    "                sequence_model,\n",
    "                train_sequence_loader,\n",
    "                optimizer_seq,\n",
    "                criterion_seq,\n",
    "                device_val,\n",
    "            )\n",
    "            history_sequence_model[\"train_loss\"].append(train_loss_s)\n",
    "            history_sequence_model[\"train_acc\"].append(train_acc_s)\n",
    "            history_sequence_model[\"train_f1\"].append(train_f1_s)\n",
    "\n",
    "            print(\n",
    "                f\"  Seq Train: Loss={train_loss_s:.4f}, Acc={train_acc_s:.4f}, \"\n",
    "                f\"F1={train_f1_s:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"  Skipping sequence training epoch (no loader).\")\n",
    "            for k in [\"train_loss\", \"train_acc\", \"train_f1\"]:\n",
    "                history_sequence_model[k].append(float(\"nan\"))\n",
    "\n",
    "        if test_sequence_loader and len(test_sequence_loader) > 0:\n",
    "            (\n",
    "                val_loss_s,\n",
    "                val_acc_s,\n",
    "                _,\n",
    "                _,\n",
    "                val_f1_s,\n",
    "                val_auc_s,\n",
    "                _,\n",
    "                _,\n",
    "            ) = evaluate_sequence_model(\n",
    "                sequence_model,\n",
    "                test_sequence_loader,\n",
    "                criterion_seq,\n",
    "                device_val,\n",
    "                phase=\"Val Seq Agg\",\n",
    "            )\n",
    "            history_sequence_model[\"val_loss\"].append(val_loss_s)\n",
    "            history_sequence_model[\"val_acc\"].append(val_acc_s)\n",
    "            history_sequence_model[\"val_f1\"].append(val_f1_s)\n",
    "            history_sequence_model[\"val_auc\"].append(\n",
    "                val_auc_s if val_auc_s is not None and not np.isnan(val_auc_s) else np.nan\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"  Seq Val:   Loss={val_loss_s:.4f}, Acc={val_acc_s:.4f}, \"\n",
    "                f\"F1={val_f1_s:.4f}, AUC={val_auc_s:.4f if val_auc_s else 'N/A'}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"  No test data for sequence model validation this epoch.\")\n",
    "            for k in [\"val_loss\", \"val_acc\", \"val_f1\", \"val_auc\"]:\n",
    "                history_sequence_model[k].append(float(\"nan\"))\n",
    "\n",
    "    stage2_time = time.time() - stage2_start_time\n",
    "    print(f\"--- Sequence Aggregator Training (Stage 2) Finished in {stage2_time:.2f}s ---\")\n",
    "\n",
    "    seq_model_save_path = os.path.join(\n",
    "        model_save_dir_val, \"sequence_aggregator_model_nslkdd.pth\"\n",
    "    )\n",
    "    os.makedirs(model_save_dir_val, exist_ok=True)\n",
    "    torch.save(sequence_model.state_dict(), seq_model_save_path)\n",
    "    print(f\"Sequence aggregator model saved to {seq_model_save_path}\")\n",
    "\n",
    "    combined_history = {\n",
    "        \"tgat\": history_tgat,\n",
    "        \"sequence_aggregator\": history_sequence_model,\n",
    "    }\n",
    "\n",
    "    # è¿”å› Stage-2 æ¸¬è©¦é›†è³‡æ–™ä¾›ä¸»ç¨‹å¼ä½¿ç”¨\n",
    "    return (\n",
    "        combined_history,\n",
    "        sequence_model,\n",
    "        test_event_embeddings,\n",
    "        test_event_labels_binary_squeezed,\n",
    "        returned_test_seq_labels_list,\n",
    "        returned_test_padded_sequences,\n",
    "        returned_test_seq_lengths,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407f186-ed1d-43f2-951e-4b7994642995",
   "metadata": {},
   "source": [
    "## 9. Execute Training and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bf76e-e447-4a64-8797-e172ce67c977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Main execution block  (FINAL â€“ no lines omitted)\n",
    "\n",
    "import os, sys, json, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ----------------------------------------------------------\n",
    "    # 0. è‹¥ .pt/.json ä¸å­˜åœ¨ â†’ è‡ªå‹•è·‘ä¸€æ¬¡é è™•ç†\n",
    "    # ----------------------------------------------------------\n",
    "    missing_files = [\n",
    "        p for p in [PROCESSED_TRAIN_FILE, PROCESSED_TEST_FILE, METADATA_FILE]\n",
    "        if not os.path.exists(p)\n",
    "    ]\n",
    "    if missing_files:\n",
    "        print(\"Missing pre-processed files:\", missing_files)\n",
    "        print(\"Running preprocess_and_save_temporal_data() automaticallyâ€¦\")\n",
    "\n",
    "        preprocess_and_save_temporal_data(\n",
    "            raw_file_path=os.path.join(RAW_DATA_DIR, TRAIN_FILE),\n",
    "            output_file_path=PROCESSED_TRAIN_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col='label',\n",
    "            is_training_set=True\n",
    "        )\n",
    "        # æ¸¬è©¦é›†å¯ç°¡æ˜“è¤‡è£½ trainï¼ˆè‹¥ä½ å·²å¦å¤–è™•ç†ï¼Œå¯åˆªé™¤ä¸‹è¡Œï¼‰\n",
    "        shutil.copy(PROCESSED_TRAIN_FILE, PROCESSED_TEST_FILE)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 1. åŸ·è¡Œ TGAT + Sequence pipeline\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\n--- Starting Combined Training Pipeline (TGAT and Sequence Model) for NSL-KDD ---\")\n",
    "\n",
    "    (combined_history_data,\n",
    "     final_trained_sequence_model,\n",
    "     returned_test_event_embeddings,\n",
    "     returned_test_event_labels_binary_squeezed,\n",
    "     returned_test_seq_labels_list,\n",
    "     returned_test_padded_sequences,\n",
    "     returned_test_seq_lengths) = train_pipeline()\n",
    "\n",
    "    if not combined_history_data:\n",
    "        print(\"Training pipeline failed.  Aborting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 2. ä¿å­˜æ­·å² CSV\n",
    "    # ----------------------------------------------------------\n",
    "    history_tgat = combined_history_data.get('tgat')\n",
    "    history_sequence_model = combined_history_data.get('sequence_aggregator')\n",
    "\n",
    "    if history_tgat:\n",
    "        try:\n",
    "            df_tgat_history = pd.DataFrame(history_tgat)\n",
    "            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "            path_hist_tgat = os.path.join(MODEL_SAVE_DIR, 'tgat_training_history_nslkdd.csv')\n",
    "            df_tgat_history.to_csv(path_hist_tgat, index_label='epoch')\n",
    "            print(f\"\\nTGAT history saved â–º {path_hist_tgat}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving TGAT history: {e}\")\n",
    "\n",
    "    if history_sequence_model:\n",
    "        try:\n",
    "            df_seq_hist = pd.DataFrame(history_sequence_model)\n",
    "            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "            path_hist_seq = os.path.join(MODEL_SAVE_DIR, 'sequence_model_training_history_nslkdd.csv')\n",
    "            df_seq_hist.to_csv(path_hist_seq, index_label='epoch')\n",
    "            print(f\"Seq-Agg history saved â–º {path_hist_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving Seq-Agg history: {e}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 3.  ç¹ªè£½ TGAT è¨“ç·´/é©—è­‰æ›²ç·š\n",
    "    # ----------------------------------------------------------\n",
    "    if history_tgat:\n",
    "        fig_tgat, axs_tgat = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        map_tgat = [('Loss','loss'), ('Accuracy','acc'), ('F1-score','f1'), ('AUC','auc')]\n",
    "        for i,(ttl,key) in enumerate(map_tgat):\n",
    "            ax = axs_tgat[i//2, i%2]\n",
    "            tr_vals = [v for v in history_tgat.get(f'train_{key}', []) if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            vl_vals = [v for v in history_tgat.get(f'val_{key}', [])   if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_tr   = [j for j,v in enumerate(history_tgat.get(f'train_{key}', [])) if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_vl   = [j for j,v in enumerate(history_tgat.get(f'val_{key}', []))   if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            if ep_tr and tr_vals: ax.plot(ep_tr, tr_vals, label=f'Train {ttl}')\n",
    "            if ep_vl and vl_vals: ax.plot(ep_vl, vl_vals, label=f'Val {ttl}')\n",
    "            ax.set_title(f'TGAT {ttl}'); ax.set_xlabel('Epoch'); ax.set_ylabel(ttl); ax.legend()\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 4.  ç¹ªè£½ Sequence-Aggregator è¨“ç·´/é©—è­‰æ›²ç·š\n",
    "    # ----------------------------------------------------------\n",
    "    if history_sequence_model:\n",
    "        metrics_seq = [('Loss','loss'), ('Accuracy','acc'), ('F1-score','f1')]\n",
    "        if any(val is not None and not (isinstance(val,float) and torch.isnan(torch.tensor(val)))\n",
    "               for val in history_sequence_model.get('val_auc', [])):\n",
    "            metrics_seq.append(('AUC','auc'))\n",
    "\n",
    "        if len(metrics_seq) == 3:\n",
    "            fig_seq, axs_seq = plt.subplots(1,3,figsize=(18,5)); axs_seq = axs_seq.reshape(-1)\n",
    "        elif len(metrics_seq) == 4:\n",
    "            fig_seq, axs_seq = plt.subplots(2,2,figsize=(12,10)); axs_seq = axs_seq.flatten()\n",
    "        else:\n",
    "            fig_seq, axs_seq = plt.subplots(1,len(metrics_seq),figsize=(6*len(metrics_seq),5)); axs_seq = axs_seq.reshape(-1)\n",
    "\n",
    "        for i,(ttl,key) in enumerate(metrics_seq):\n",
    "            ax = axs_seq[i]\n",
    "            tr_vals = [v for v in history_sequence_model.get(f'train_{key}', []) if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            vl_vals = [v for v in history_sequence_model.get(f'val_{key}', [])   if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_tr   = [j for j,v in enumerate(history_sequence_model.get(f'train_{key}', [])) if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_vl   = [j for j,v in enumerate(history_sequence_model.get(f'val_{key}', []))   if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            if ep_tr and tr_vals: ax.plot(ep_tr, tr_vals, label=f'Train {ttl}')\n",
    "            if ep_vl and vl_vals: ax.plot(ep_vl, vl_vals, label=f'Val {ttl}')\n",
    "            ax.set_title(f'Seq-Agg {ttl}'); ax.set_xlabel('Epoch'); ax.set_ylabel(ttl); ax.legend()\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 5. æœ€ä½³ TGAT æ¨¡å‹åœ¨æ¸¬è©¦é›†æœ€çµ‚è©•ä¼°\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\n--- Final Evaluation of Best TGAT Model (Stage-1) on Test Set ---\")\n",
    "    best_tgat_path = os.path.join(MODEL_SAVE_DIR, BEST_MODEL_NAME)\n",
    "    if os.path.exists(best_tgat_path):\n",
    "        with open(METADATA_FILE) as f: meta = json.load(f)\n",
    "        tgat_model_final = TGAT(\n",
    "            node_feat_dim=meta['NODE_FEAT_DIM'],\n",
    "            time_emb_dim=TIME_DIM,\n",
    "            n_head=N_HEADS,\n",
    "            n_layers=N_LAYERS,\n",
    "            hidden_dim_per_layer=HIDDEN_DIM,\n",
    "            num_classes=1,\n",
    "            dropout=DROPOUT\n",
    "        ).to(DEVICE)\n",
    "        tgat_model_final.load_state_dict(torch.load(best_tgat_path, map_location=DEVICE))\n",
    "        test_data_cpu, _, _, pos_w = load_processed_data(PROCESSED_TEST_FILE, METADATA_FILE, CLASSIFICATION_MODE)\n",
    "        loader_test = TemporalNeighborLoader(\n",
    "            test_data_cpu, BATCH_SIZE, NUM_NEIGHBORS, DEVICE,\n",
    "            shuffle=False,\n",
    "            recency_bias_factor=RECENCY_BIAS_FACTOR,\n",
    "            feature_similarity_col_name=FEATURE_SIMILARITY_COL_NAME,\n",
    "            feature_similarity_weight=FEATURE_SIMILARITY_WEIGHT,\n",
    "            raw_data_file_path_for_ids=os.path.join(RAW_DATA_DIR, TEST_FILE),\n",
    "            col_names_list=COL_NAMES\n",
    "        )\n",
    "        crit = nn.BCEWithLogitsLoss(pos_weight=pos_w.to(DEVICE) if pos_w is not None else None)\n",
    "        loss_f, acc_f, prec_f, rec_f, f1_f, auc_f, y_true_f, y_pred_f, rpt_f = evaluate_model(\n",
    "            tgat_model_final, loader_test, crit,\n",
    "            phase='Final TGAT Test', return_embeddings_and_ids=False)\n",
    "        print_metrics(\"Final TGAT Test\", loss_f, acc_f, prec_f, rec_f, f1_f, auc_f,\n",
    "                      phase='Final TGAT', class_report=str(rpt_f))\n",
    "        if y_true_f and y_pred_f:\n",
    "            plot_confusion_matrix_custom(\n",
    "                y_true_f, y_pred_f,\n",
    "                class_names=['Normal (0)','Attack (1)'],\n",
    "                title='Final TGAT Confusion Matrix')\n",
    "\n",
    "    else:\n",
    "        print(f\"Best TGAT model not found â–º {best_tgat_path}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 6. æœ€ä½³ Sequence-Aggregator æ¨¡å‹åœ¨æ¸¬è©¦åºåˆ—æœ€çµ‚è©•ä¼°\n",
    "    # ----------------------------------------------------------\n",
    "    if final_trained_sequence_model and returned_test_padded_sequences.numel():\n",
    "        print(\"\\n--- Final Evaluation of Sequence Aggregator on Test Sequences ---\")\n",
    "        final_test_seq_ds = EmbeddingSequenceDataset(\n",
    "            returned_test_padded_sequences,\n",
    "            returned_test_seq_labels_list,\n",
    "            returned_test_seq_lengths\n",
    "        )\n",
    "        final_test_seq_loader = DataLoader(\n",
    "            final_test_seq_ds,\n",
    "            batch_size=BATCH_SIZE_SEQ_MODEL,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn_packed_fixed_length\n",
    "        )\n",
    "        crit_seq = nn.BCEWithLogitsLoss()\n",
    "        _, _, _, _, _, _, seq_true, seq_pred = evaluate_sequence_model(\n",
    "            final_trained_sequence_model,\n",
    "            final_test_seq_loader,\n",
    "            crit_seq,\n",
    "            DEVICE,\n",
    "            phase=\"Final Seq-Agg Test\")\n",
    "        if seq_true and seq_pred:\n",
    "            plot_confusion_matrix_custom(\n",
    "                seq_true, seq_pred,\n",
    "                class_names=['Normal Seq','Attack Seq'],\n",
    "                title='Final Sequence-Agg Confusion Matrix')\n",
    "    else:\n",
    "        print(\"Sequence-Aggregator final evaluation skipped (no sequences or model unavailable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974786e-9773-4ec4-9c25-5e2b7338c121",
   "metadata": {},
   "source": [
    "## 10. How to Run & Notes\n",
    "- **Ensure Preprocessing is Done**: Run `preprocess_kdd_large.ipynb` first.\n",
    "- **Adjust Configuration**: Check paths and hyperparameters in Cell 2.\n",
    "- **Run All Cells**: This will train, evaluate, save the best model, and plot metrics.\n",
    "- **Memory for `TemporalNeighborLoader`**:\n",
    "    - The current loader sends the *entire* graph's features (`self.temporal_data.x`) and timestamps (`self.temporal_data.ts`) to the specified `device` *for each batch*.\n",
    "    - **If `self.temporal_data.x` (all node features for the entire dataset) is too large to fit on the GPU, this will cause an Out-Of-Memory (OOM) error.**\n",
    "    - **For truly massive graphs**: The loader and model interaction need modification. For example, keep full data on CPU, loader passes indices, model fetches only necessary data slices to GPU. This is a more advanced optimization not implemented here but crucial for >GPU memory graphs. This script currently assumes the full feature/timestamp tensors fit on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11633d-ae85-419c-93bf-781961fca663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
