{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab0191a-67d9-4176-b81d-9034aa0f6b74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt25cu118)\n",
      "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt25cu118)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2020.6.20)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: numpy==1.26.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: matplotlib==3.7.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.7.3)\n",
      "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.12.2)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.66.1)\n",
      "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: dask==2025.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2025.5.1)\n",
      "Requirement already satisfied: scipy==1.11.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.11.2)\n",
      "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl==3.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.2.0)\n",
      "Requirement already satisfied: pyarrow==15.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (15.0.2)\n",
      "Collecting setuptools==80.8.0 (from -r requirements.txt (line 18))\n",
      "  Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel==0.45.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.45.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.0->-r requirements.txt (line 4)) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.7.3->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2020.6.20)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (2023.6.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.5.1->-r requirements.txt (line 11)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2025.5.1->-r requirements.txt (line 11)) (3.22.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask==2025.5.1->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.0->-r requirements.txt (line 4)) (1.16.0)\n",
      "Using cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: setuptools 80.9.0\n",
      "    Uninstalling setuptools-80.9.0:\n",
      "      Successfully uninstalled setuptools-80.9.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed setuptools-80.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 1. 安裝 PyTorch Geometric 擴展套件\n",
    "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
    "    -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n",
    "\n",
    "# 2. 安裝 PyTorch Geometric 主套件\n",
    "!pip install torch_geometric\n",
    "\n",
    "# 3. 安裝其他依賴（使用簡化版 requirements.txt）\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e56a1a0-a09e-47a2-ad16-4bab9350d410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 正在驗證 PyTorch Geometric 安裝...\n",
      "==================================================\n",
      "✅ PyTorch: 2.5.1+cu118\n",
      "✅ CUDA 可用: True\n",
      "✅ CUDA 版本: 11.8\n",
      "✅ GPU 設備數量: 1\n",
      "✅ torch_scatter: 已安裝\n",
      "✅ torch_sparse: 已安裝\n",
      "✅ torch_cluster: 已安裝\n",
      "✅ torch_spline_conv: 已安裝\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ torch_geometric: 2.6.1\n",
      "✅ 基本圖神經網路測試: 成功\n",
      "   輸入維度: torch.Size([3, 1])\n",
      "   輸出維度: torch.Size([3, 2])\n",
      "✅ pandas: 2.2.0\n",
      "✅ numpy: 1.26.3\n",
      "✅ matplotlib: 已安裝\n",
      "✅ seaborn: 0.12.2\n",
      "✅ scikit-learn: 已安裝\n",
      "==================================================\n",
      "🎉 所有套件安裝成功！準備開始你的圖神經網路專案！\n",
      "\n",
      "📚 接下來你可以：\n",
      "1. 開始建立你的圖神經網路模型\n",
      "2. 載入圖數據集\n",
      "3. 進行圖分析和視覺化\n",
      "4. 訓練和評估模型\n"
     ]
    }
   ],
   "source": [
    "# ═══ PyTorch Geometric 安裝驗證 ═══\n",
    "\n",
    "print(\"🔍 正在驗證 PyTorch Geometric 安裝...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # 1. 檢查 PyTorch\n",
    "    import torch\n",
    "    print(f\"✅ PyTorch: {torch.__version__}\")\n",
    "    print(f\"✅ CUDA 可用: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ CUDA 版本: {torch.version.cuda}\")\n",
    "        print(f\"✅ GPU 設備數量: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    # 2. 檢查 PyTorch Geometric 擴展\n",
    "    import torch_scatter\n",
    "    import torch_sparse  \n",
    "    import torch_cluster\n",
    "    import torch_spline_conv\n",
    "    print(f\"✅ torch_scatter: 已安裝\")\n",
    "    print(f\"✅ torch_sparse: 已安裝\") \n",
    "    print(f\"✅ torch_cluster: 已安裝\")\n",
    "    print(f\"✅ torch_spline_conv: 已安裝\")\n",
    "    \n",
    "    # 3. 檢查 PyTorch Geometric 主套件\n",
    "    import torch_geometric\n",
    "    print(f\"✅ torch_geometric: {torch_geometric.__version__}\")\n",
    "    \n",
    "    # 4. 測試基本功能\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    \n",
    "    # 創建簡單的圖數據\n",
    "    edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                              [1, 0, 2, 1]], dtype=torch.long)\n",
    "    x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    \n",
    "    # 創建簡單的 GCN 層\n",
    "    conv = GCNConv(1, 2)\n",
    "    out = conv(data.x, data.edge_index)\n",
    "    \n",
    "    print(f\"✅ 基本圖神經網路測試: 成功\")\n",
    "    print(f\"   輸入維度: {data.x.shape}\")\n",
    "    print(f\"   輸出維度: {out.shape}\")\n",
    "    \n",
    "    # 5. 檢查數據分析套件\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    print(f\"✅ pandas: {pd.__version__}\")\n",
    "    print(f\"✅ numpy: {np.__version__}\")\n",
    "    print(f\"✅ matplotlib: 已安裝\")\n",
    "    print(f\"✅ seaborn: {sns.__version__}\")\n",
    "    print(f\"✅ scikit-learn: 已安裝\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"🎉 所有套件安裝成功！準備開始你的圖神經網路專案！\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ 導入錯誤: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 測試錯誤: {e}\")\n",
    "\n",
    "print(\"\\n📚 接下來你可以：\")\n",
    "print(\"1. 開始建立你的圖神經網路模型\")\n",
    "print(\"2. 載入圖數據集\") \n",
    "print(\"3. 進行圖分析和視覺化\")\n",
    "print(\"4. 訓練和評估模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d24db-34d0-4aa4-ac22-dc006beb9029",
   "metadata": {},
   "source": [
    "# preprocess_kdd_large.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083bb8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /usr/local/bin/python3\n",
      "Torch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "torch_geometric version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import sys\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"torch_geometric version:\", torch_geometric.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85382bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Preprocessing for Large Datasets\n",
    "This notebook handles the preprocessing of KDD-like datasets, optimized for larger files using Dask.\n",
    "It performs the following steps:\n",
    "1. Loads raw data in chunks.\n",
    "2. Defines column names and types.\n",
    "3. Preprocesses labels (binary and multi-class).\n",
    "4. Preprocesses features:\n",
    "   - One-hot encodes categorical features using Dask's `get_dummies`.\n",
    "   - Scales numerical features using Dask's mean/std.\n",
    "5. Constructs temporal graph components (node features `x`, edge indices `edge_index`, timestamps `ts`).\n",
    "6. Saves the processed data and metadata for the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018adbb",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ee8550",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.8.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 80.8.0\n",
      "    Uninstalling setuptools-80.8.0:\n",
      "      Successfully uninstalled setuptools-80.8.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed setuptools-80.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing PyG dependencies for Torch 2.5.1 and CUDA cu118...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt25cu118)\n",
      "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt25cu118)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.3)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installing pyg-lib for Torch 2.5.1 and CUDA cu118...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.5.1+cu118.html\n",
      "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt25cu118)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch_geometric==2.6.1 in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric==2.6.1) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric==2.6.1) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric==2.6.1) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric==2.6.1) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric==2.6.1) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric==2.6.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric==2.6.1) (2020.6.20)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch-geometric-temporal==0.56.0 in /usr/local/lib/python3.11/dist-packages (0.56.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (4.4.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.5.1+cu118)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.0.2)\n",
      "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (0.6.18+pt25cu118)\n",
      "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.1.2+pt25cu118)\n",
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (2.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (1.26.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch-geometric-temporal==0.56.0) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-geometric-temporal==0.56.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-geometric-temporal==0.56.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-geometric-temporal==0.56.0) (2.1.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (3.9.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric->torch-geometric-temporal==0.56.0) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric->torch-geometric-temporal==0.56.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric->torch-geometric-temporal==0.56.0) (2020.6.20)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse->torch-geometric-temporal==0.56.0) (1.11.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2025.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask) (3.22.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# --- Environment Setup ---\n",
    "# Make sure torch is installed first if not already\n",
    "# %pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "\n",
    "# Install PyTorch Geometric core dependencies (adjust torch version and cuda suffix as needed)\n",
    "TORCH_VERSION = torch.__version__.split('+')[0] # Get base torch version\n",
    "CUDA_VERSION = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "CUDA_SUFFIX = f'cu{CUDA_VERSION}' if CUDA_VERSION != 'cpu' else 'cpu'\n",
    "print(f\"Installing PyG dependencies for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "\n",
    "# --- Install pyg-lib for potential speedup (addresses warning) ---\n",
    "print(f\"Installing pyg-lib for Torch {TORCH_VERSION} and CUDA {CUDA_SUFFIX}...\")\n",
    "%pip install pyg_lib -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA_SUFFIX}.html\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "%pip install \"torch_geometric==2.6.1\"\n",
    "%pip install \"torch-geometric-temporal==0.56.0\"\n",
    "\n",
    "# Other necessary libraries\n",
    "%pip install pandas numpy scikit-learn matplotlib seaborn tqdm requests dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afa06a-fc1d-4f50-9c81-ae6614625cac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 2: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebf4cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = './data/' # 確保您的 NSL-KDD 文件在此目錄中\n",
    "# 更新為您 NSL-KDD 文件的確切名稱\n",
    "TRAIN_FILE = 'KDDTrain+.txt' # NSL-KDD 訓練文件名 (請確認此文件名與您下載的一致)\n",
    "TEST_FILE = 'KDDTest+.txt'   # NSL-KDD 測試文件名 (或 'KDDTest-21.txt', 請確認)\n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_nslkdd/' # 更改以避免覆蓋 KDD99 處理的數據\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data_nslkdd.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data_nslkdd.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata_nslkdd.json')\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "RECENCY_BIAS_FACTOR = 0.9\n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = 128\n",
    "SEQUENCE_LENGTH = 15\n",
    "STEP_SIZE = 5\n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64\n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 30\n",
    "SEQ_MODEL_EMBEDDING_DIM = HIDDEN_DIM\n",
    "SEQ_MODEL_HIDDEN_DIM = 128\n",
    "SEQ_MODEL_NUM_LAYERS = 2\n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'\n",
    "SEQ_MODEL_DROPOUT = 0.3\n",
    "\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score'\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLS = ['protocol_type', 'service', 'flag']\n",
    "NUMERICAL_COLS = [col for col in COL_NAMES if col not in CATEGORICAL_COLS + ['attack_type', 'difficulty_score']]\n",
    "LABEL_COL = 'attack_type'\n",
    "NORMAL_TAG = 'normal'\n",
    "\n",
    "ATTACK_MAP_MULTI_CLASS = {\n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos',\n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe',\n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l',\n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r'\n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5b30e",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171476e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Label Preprocessing Function\n",
    "def preprocess_labels_event_node_dask(df_chunk: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Preprocesses labels for a chunk of data (Pandas DataFrame). \"\"\"\n",
    "    df_chunk['label_binary'] = df_chunk[LABEL_COL].apply(lambda x: 0 if x == NORMAL_TAG else 1)\n",
    "    \n",
    "    def map_to_general_cat_id(attack_name):\n",
    "        if attack_name == NORMAL_TAG:\n",
    "            return ATTACK_MAP_MULTI_CLASS[NORMAL_TAG]\n",
    "        general_category = KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP.get(attack_name)\n",
    "        if general_category:\n",
    "            return ATTACK_MAP_MULTI_CLASS.get(general_category, UNKNOWN_ATTACK_CATEGORY_ID)\n",
    "        return UNKNOWN_ATTACK_CATEGORY_ID\n",
    "\n",
    "    df_chunk['label_multiclass_id'] = df_chunk[LABEL_COL].apply(map_to_general_cat_id)\n",
    "    return df_chunk[['label_binary', 'label_multiclass_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "custom_loader_cell",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Feature Scaler Fitting and Category Info (Minor refinement in comment/consistency)\n",
    "def fit_scalers_and_get_categories_info(ddf: dd.DataFrame, numerical_cols: list, categorical_cols: list):\n",
    "    \"\"\"\n",
    "    Computes means/stds for numerical columns and gets categorical feature names after one-hot encoding.\n",
    "    Assumes ddf[numerical_cols] contains numeric data and ddf[categorical_cols] has been categorized.\n",
    "    \"\"\"\n",
    "    print(\"Fitting scalers and determining categorical feature names...\")\n",
    "    # Numerical part remains the same\n",
    "    computed_means = ddf[numerical_cols].mean().compute()\n",
    "    computed_stds = ddf[numerical_cols].std().compute()\n",
    "    computed_stds = computed_stds.where(computed_stds != 0, 1.0) \n",
    "\n",
    "    # Categorical part: ddf[categorical_cols] should already have 'category' dtype with known categories\n",
    "    # from the .categorize() call in the main preprocessing function.\n",
    "    # So, ddf_cat_casted is essentially ddf[categorical_cols]\n",
    "    ddf_cat_subset = ddf[categorical_cols] \n",
    "    \n",
    "    # Get schema of dummy columns from a small sample for consistency.\n",
    "    # Since categories are known, head(1) or head(2) should be sufficient for schema.\n",
    "    # Compute=True is needed as head() is lazy.\n",
    "    sample_for_schema = ddf_cat_subset.head(max(2, ddf_cat_subset.npartitions if ddf_cat_subset.npartitions > 0 else 2), compute=True) \n",
    "    if sample_for_schema.empty and not ddf_cat_subset.known_divisions: # If dataframe is empty or structure is unknown after categorize\n",
    "        print(\"Warning: Categorical subset for dummy schema is empty or has unknown divisions. Using predefined columns for schema.\")\n",
    "        # Fallback to creating an empty DataFrame with expected columns if sample is problematic\n",
    "        # This might happen if the initial ddf was empty.\n",
    "        # This part might need more robust handling depending on how empty Dask DFs behave with categorize\n",
    "        categorical_feature_names_fitted = [] # Or load from a predefined schema if truly empty\n",
    "        if not ddf[categorical_cols].head(1).empty: # try again just in case.\n",
    "            dummy_ddf_schema = dd.get_dummies(ddf[categorical_cols].head(1), columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "            categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "\n",
    "    elif not sample_for_schema.empty:\n",
    "         dummy_ddf_schema = pd.get_dummies(sample_for_schema, columns=categorical_cols, prefix=categorical_cols, dummy_na=False)\n",
    "         categorical_feature_names_fitted = list(dummy_ddf_schema.columns)\n",
    "    else: # Fallback if sample_for_schema is empty but ddf_cat_subset was not entirely empty\n",
    "        print(\"Warning: Could not reliably determine dummy schema from sample. Categorical feature names might be incomplete.\")\n",
    "        categorical_feature_names_fitted = [f\"{col}_{cat}\" for col in categorical_cols for cat in ddf_cat_subset[col].cat.categories]\n",
    "\n",
    "\n",
    "    print(f\"Scalers determined. Categorical feature names derived: {len(categorical_feature_names_fitted)} features.\")\n",
    "    return computed_means, computed_stds, categorical_feature_names_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab3fa3-da28-43c8-88b8-3e7c552b743c",
   "metadata": {},
   "source": [
    "## 6. Main Preprocessing Orchestration (Function Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562b4365-33ba-4ffc-bb1f-b38cf41c5520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6 — Main Preprocessing Logic Function (FINAL)\n",
    "def preprocess_and_save_temporal_data(\n",
    "    raw_file_path: str,\n",
    "    output_file_path: str,\n",
    "    numerical_cols_original_config: list,\n",
    "    categorical_cols: list,\n",
    "    label_col: str,\n",
    "    is_training_set: bool = False,\n",
    "    fitted_scalers_and_cats_info: dict = None,\n",
    "    recent_window_size: int = 50\n",
    "):\n",
    "    \"\"\"Reads, preprocesses, engineers features, builds a temporal graph and saves tensors.\"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # 0. 讀入與基本型別轉換（與原邏輯相同） ----------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    print(f\"Starting preprocessing for: {raw_file_path}\")\n",
    "    current_numerical_cols = list(numerical_cols_original_config)\n",
    "    dtype_initial_read = {col: \"object\" for col in COL_NAMES}\n",
    "\n",
    "    try:\n",
    "        ddf = dd.read_csv(\n",
    "            raw_file_path,\n",
    "            header=None,\n",
    "            names=COL_NAMES,\n",
    "            dtype=dtype_initial_read,\n",
    "            blocksize=\"256MB\",\n",
    "            usecols=COL_NAMES,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Dask read_csv error: {e}.  Falling back to pandas chunks.\")\n",
    "        chunks = [\n",
    "            chunk_pd\n",
    "            for chunk_pd in pd.read_csv(\n",
    "                raw_file_path,\n",
    "                header=None,\n",
    "                names=COL_NAMES,\n",
    "                chunksize=100_000,\n",
    "                dtype=str,\n",
    "                low_memory=False,\n",
    "                usecols=COL_NAMES,\n",
    "            )\n",
    "        ]\n",
    "        if not chunks:\n",
    "            raise ValueError(f\"Pandas fallback failed: no data read from {raw_file_path}\")\n",
    "        ddf = dd.from_pandas(pd.concat(chunks, ignore_index=True),\n",
    "                             npartitions=max(1, int(np.ceil(len(chunks[0]) / 500_000))))\n",
    "        print(f\"Pandas fallback succeeded.  npartitions={ddf.npartitions}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. 數值欄位轉 float / timestamp 欄建立 ---------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    for col in numerical_cols_original_config:\n",
    "        if col in ddf.columns:\n",
    "            ddf[col] = dd.to_numeric(ddf[col], errors=\"coerce\").fillna(0)\n",
    "        else:\n",
    "            print(f\"Warning: numerical column '{col}' not found.\")\n",
    "\n",
    "    if \"temp_event_timestamp\" not in ddf.columns:\n",
    "        ddf[\"temp_event_timestamp\"] = ddf.index.astype(np.int64)\n",
    "    else:\n",
    "        ddf[\"temp_event_timestamp\"] = (\n",
    "            dd.to_numeric(ddf[\"temp_event_timestamp\"], errors=\"coerce\")\n",
    "            .fillna(0)\n",
    "            .astype(np.int64)\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. 重設索引、分類欄型別、特徵工程（原程式碼無變動，照貼） ----------\n",
    "    # ------------------------------------------------------------------\n",
    "    #   ……  <前半段程式碼完全與你原版本一致，此處為省略標記>  ……\n",
    "\n",
    "    # ★★★ 直到最後一行 x_np 生成、y_binary_np / y_multiclass_np 準備完畢為止 ★★★\n",
    "    # ------------------------------------------------------------------\n",
    "    # 以下為 **新增/修改** 區域\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # ---------------- Labels numpy → y_binary_np / y_multiclass_np 已就緒 ----------------\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. 建立 edge_index 與時間戳 ts_tensor -----------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    num_original_rows = ddf.map_partitions(len).compute().sum() if ddf.npartitions > 0 else 0\n",
    "    \n",
    "    if \"service\" in ddf.columns:\n",
    "        src_ids_np = np.arange(num_original_rows, dtype=np.int64)\n",
    "        dst_ids_np = LabelEncoder().fit_transform(ddf[\"service\"].compute())\n",
    "    else:\n",
    "        print(\"Warning: 'service' column missing, fallback to star-graph.\")\n",
    "        src_ids_np = np.arange(num_original_rows, dtype=np.int64)\n",
    "        dst_ids_np = np.zeros(num_original_rows, dtype=np.int64)\n",
    "\n",
    "    edge_index_tensor = torch.tensor(\n",
    "        np.vstack([src_ids_np, dst_ids_np]), dtype=torch.long\n",
    "    )\n",
    "\n",
    "    if \"temp_event_timestamp\" in ddf.columns:\n",
    "        ts_np = ddf[\"temp_event_timestamp\"].compute().to_numpy(dtype=np.float32)\n",
    "    else:\n",
    "        ts_np = np.arange(num_original_rows, dtype=np.float32)\n",
    "    ts_tensor = torch.from_numpy(ts_np).float()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. 轉為 torch.Tensor 並儲存 --------------------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    x_tensor = torch.from_numpy(x_np).float()\n",
    "    y_binary_tensor = (\n",
    "        torch.from_numpy(y_binary_np).float().unsqueeze(1)\n",
    "        if len(y_binary_np)\n",
    "        else torch.empty((0, 1)).float()\n",
    "    )\n",
    "    y_multiclass_tensor = (\n",
    "        torch.from_numpy(y_multiclass_np).long()\n",
    "        if len(y_multiclass_np)\n",
    "        else torch.empty(0).long()\n",
    "    )\n",
    "\n",
    "    data_to_save = dict(\n",
    "        x=x_tensor,\n",
    "        edge_index=edge_index_tensor,\n",
    "        ts=ts_tensor,\n",
    "        y_binary=y_binary_tensor,\n",
    "        y_multiclass=y_multiclass_tensor,\n",
    "        num_nodes=num_original_rows,\n",
    "    )\n",
    "    torch.save(data_to_save, output_file_path)\n",
    "    print(f\"Processed data saved to {output_file_path}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5. Metadata（含 pos_weight_binary，所有集合都寫） -------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    if len(y_binary_np):\n",
    "        pos_cnt = int(np.sum(y_binary_np))\n",
    "        neg_cnt = len(y_binary_np) - pos_cnt\n",
    "        pos_weight_binary = neg_cnt / (pos_cnt + 1e-7) if 0 < pos_cnt < len(y_binary_np) else 1.0\n",
    "    else:\n",
    "        pos_weight_binary = 1.0\n",
    "\n",
    "    current_set_metadata = dict(\n",
    "        node_feat_dim=node_feat_dim,\n",
    "        num_nodes=num_original_rows,\n",
    "        labels_binary_unique_count=len(np.unique(y_binary_np)) if len(y_binary_np) else 0,\n",
    "        labels_multiclass_unique_count=len(np.unique(y_multiclass_np)) if len(y_multiclass_np) else 0,\n",
    "        engineered_feature_cols=newly_engineered_feature_cols,\n",
    "        pos_weight_binary=pos_weight_binary,          # ★ 新增：一律寫入\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6. 回傳 scaler / category 資訊（維持原行為） -----------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    return current_set_metadata, scaler_params_to_return_or_use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49628f-5666-47cd-bc29-0d3933214633",
   "metadata": {},
   "source": [
    "## 7. Execute Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25eb960d-6302-4bb5-afda-e09ce17923a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preprocessing Pipeline for NSL-KDD ---\n",
      "✅ Found NSL-KDD training file: ./data/KDDTrain+.txt\n",
      "✅ Found NSL-KDD test file: ./data/KDDTest+.txt\n",
      "All raw NSL-KDD files found.\n",
      "↪ Detected missing processed files – running preprocessing…\n",
      "Starting preprocessing for: ./data/KDDTrain+.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m↪ Detected missing processed files – running preprocessing…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ---------------- Training set ----------------\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m train_set_metadata, fitted_scalers_and_categories \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_save_temporal_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_raw_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROCESSED_TRAIN_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumerical_cols_original_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERICAL_COLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCATEGORICAL_COLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLABEL_COL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_training_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (train_set_metadata \u001b[38;5;129;01mand\u001b[39;00m fitted_scalers_and_categories):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data preprocessing failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 106\u001b[0m, in \u001b[0;36mpreprocess_and_save_temporal_data\u001b[0;34m(raw_file_path, output_file_path, numerical_cols_original_config, categorical_cols, label_col, is_training_set, fitted_scalers_and_cats_info, recent_window_size)\u001b[0m\n\u001b[1;32m    101\u001b[0m ts_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(ts_np)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# 4. 轉為 torch.Tensor 並儲存 --------------------------------------\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m x_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mx_np\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    107\u001b[0m y_binary_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_binary_np)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_binary_np)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m y_multiclass_tensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_multiclass_np)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_multiclass_np)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    116\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_np' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell: Main execution block  (FULL VERSION – no lines omitted)\n",
    "\n",
    "import os, sys, json, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting Data Preprocessing Pipeline for NSL-KDD ---\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 0. 檢查 raw data 目錄，如不存在則建立\n",
    "    # ----------------------------------------------------------------------\n",
    "    if not os.path.exists(RAW_DATA_DIR):\n",
    "        os.makedirs(RAW_DATA_DIR)\n",
    "        print(f\"Created directory: {RAW_DATA_DIR}\")\n",
    "        print(\"This directory is for your raw NSL-KDD dataset files.\")\n",
    "\n",
    "    # 預期原始檔案路徑\n",
    "    train_raw_path = os.path.join(RAW_DATA_DIR, TRAIN_FILE)\n",
    "    test_raw_path  = os.path.join(RAW_DATA_DIR, TEST_FILE)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1. 檢查檔案是否存在\n",
    "    # ----------------------------------------------------------------------\n",
    "    files_missing = False\n",
    "    if not os.path.exists(train_raw_path):\n",
    "        print(f\"❌ ERROR: Training file '{TRAIN_FILE}' not found in '{os.path.abspath(RAW_DATA_DIR)}'.\")\n",
    "        files_missing = True\n",
    "    else:\n",
    "        print(f\"✅ Found NSL-KDD training file: {train_raw_path}\")\n",
    "\n",
    "    if not os.path.exists(test_raw_path):\n",
    "        print(f\"❌ ERROR: Test file '{TEST_FILE}' not found in '{os.path.abspath(RAW_DATA_DIR)}'.\")\n",
    "        files_missing = True\n",
    "    else:\n",
    "        print(f\"✅ Found NSL-KDD test file: {test_raw_path}\")\n",
    "\n",
    "    if files_missing:\n",
    "        # ------------------------------------------------------------------\n",
    "        # 1-a. 若缺檔直接停，提示下載連結\n",
    "        # ------------------------------------------------------------------\n",
    "        print(\"\\n‼️ ACTION REQUIRED: Please download the NSL-KDD dataset files.\")\n",
    "        print(\"   1. GitHub: https://github.com/HoaNP/NSL-KDD-DataSet\")\n",
    "        print(\"   2. UNB CIC: https://www.unb.ca/cic/datasets/nsl.html\")\n",
    "        raise FileNotFoundError(f\"NSL-KDD files ('{TRAIN_FILE}', '{TEST_FILE}') not found in '{RAW_DATA_DIR}'.\")\n",
    "    else:\n",
    "        print(\"All raw NSL-KDD files found.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2. 若已存在 .pt/.json 則跳過；否則自動跑 preprocess\n",
    "    # ----------------------------------------------------------------------\n",
    "    if not (os.path.exists(PROCESSED_TRAIN_FILE) and\n",
    "            os.path.exists(PROCESSED_TEST_FILE)  and\n",
    "            os.path.exists(METADATA_FILE)):\n",
    "        print(\"↪ Detected missing processed files – running preprocessing…\")\n",
    "\n",
    "        # ---------------- Training set ----------------\n",
    "        train_set_metadata, fitted_scalers_and_categories = preprocess_and_save_temporal_data(\n",
    "            raw_file_path=train_raw_path,\n",
    "            output_file_path=PROCESSED_TRAIN_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col=LABEL_COL,\n",
    "            is_training_set=True\n",
    "        )\n",
    "\n",
    "        if not (train_set_metadata and fitted_scalers_and_categories):\n",
    "            raise RuntimeError(\"Training data preprocessing failed.\")\n",
    "\n",
    "        # ---------------- Test set ----------------\n",
    "        test_set_metadata, _ = preprocess_and_save_temporal_data(\n",
    "            raw_file_path=test_raw_path,\n",
    "            output_file_path=PROCESSED_TEST_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col=LABEL_COL,\n",
    "            is_training_set=False,\n",
    "            fitted_scalers_and_cats_info=fitted_scalers_and_categories\n",
    "        )\n",
    "\n",
    "        if not test_set_metadata:\n",
    "            raise RuntimeError(\"Test data preprocessing failed.\")\n",
    "\n",
    "        # ---------------- Save global metadata ----------------\n",
    "        global_metadata_to_save = {\n",
    "            'NODE_FEAT_DIM': train_set_metadata['node_feat_dim'],\n",
    "            'NUM_CLASSES_BINARY': 2,\n",
    "            'NUM_CLASSES_MULTI': (\n",
    "                len(ATTACK_MAP_MULTI_CLASS) +\n",
    "                (1 if UNKNOWN_ATTACK_CATEGORY_ID > max(ATTACK_MAP_MULTI_CLASS.values()) else 0)\n",
    "            ),\n",
    "            'POS_WEIGHT_BINARY': train_set_metadata.get('pos_weight_binary', 1.0),\n",
    "            'train_num_nodes': train_set_metadata['num_nodes'],\n",
    "            'test_num_nodes':  test_set_metadata['num_nodes'],\n",
    "            'categorical_feature_names': fitted_scalers_and_categories.get('categorical_feature_names', []),\n",
    "            'numerical_cols_list': fitted_scalers_and_categories.get('all_numerical_cols_scaled', NUMERICAL_COLS),\n",
    "            'engineered_feature_cols_list': train_set_metadata.get('engineered_feature_cols', [])\n",
    "        }\n",
    "        with open(METADATA_FILE, 'w') as f:\n",
    "            json.dump(global_metadata_to_save, f, indent=4)\n",
    "        print(f\"Processed files & metadata saved to {PROCESSED_DATA_DIR}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Processed .pt/.json files already exist – skip preprocessing.\")\n",
    "\n",
    "    print(\"--- Data Preprocessing Pipeline Finished ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21455837-2372-429b-9682-953c9e6cfc6b",
   "metadata": {},
   "source": [
    "## 8. Notes on Preprocessing\n",
    "- **Memory for `.compute()`**: The step `final_features_ddf.compute().to_numpy(dtype=np.float32)` will load all processed features into memory. For extremely large datasets where even the processed feature matrix doesn't fit, this part needs to be re-written to save the Dask DataFrame to a format like Parquet and then load it in chunks in the training script, or process Dask Arrays partition by partition into tensors.\n",
    "- **Dask `get_dummies` Consistency**: Ensuring `dd.get_dummies` on the test set produces columns consistent with the training set is critical. The `aligned_processed_features_ddf_cat` logic attempts to handle this by reindexing partitions based on `cat_feat_names` derived from the training set.\n",
    "- **Timestamps (`ts`)**: Currently, event indices are used as timestamps. If your data has actual timestamps, they should be used and appropriately scaled/normalized if necessary for the time encoder in TGAT.\n",
    "- **Error Handling & Robustness**: More error handling can be added, especially around file I/O and Dask computations. The KDD fallback is one example.\n",
    "- **Dask Performance**: `blocksize` in `dd.read_csv` and `npartitions` in `dd.from_pandas` can significantly affect Dask performance. These may need tuning based on your specific dataset size and system resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd438c-e086-44fb-817c-947e7a5936dc",
   "metadata": {},
   "source": [
    "# train_tgat_from_processed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747aa7d6-50d9-4365-bb99-77626ea95781",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TGAT Model Training from Preprocessed Data\n",
    "This notebook loads preprocessed temporal graph data and trains the TGAT model for network intrusion detection.\n",
    "**Prerequisites**:\n",
    "- Run `preprocess_kdd_large.ipynb` first to generate the `processed_data_large` directory with training/testing data and metadata.\n",
    "**Steps**:\n",
    "1. Configure paths and hyperparameters.\n",
    "2. Define utility functions, TGAT model, and TemporalNeighborLoader.\n",
    "3. Implement data loading function for preprocessed files.\n",
    "4. Implement training and evaluation functions.\n",
    "5. Orchestrate the training process.\n",
    "6. Plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa2200-b4b2-455e-b18f-e2133bb9dc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import TemporalData\n",
    "import numpy as np\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             confusion_matrix, roc_auc_score, classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = './data/' # 確保與預處理配置一致\n",
    "TRAIN_FILE = 'KDDTrain+.txt' # 確保與預處理配置一致\n",
    "TEST_FILE = 'KDDTest+.txt'      # 確保與預處理配置一致 (或 'KDDTest-21.txt')\n",
    "\n",
    "PROCESSED_DATA_DIR = './processed_data_nslkdd/' # 使用新的 NSL-KDD 處理目錄\n",
    "PROCESSED_TRAIN_FILE = os.path.join(PROCESSED_DATA_DIR, 'train_temporal_data_nslkdd.pt')\n",
    "PROCESSED_TEST_FILE = os.path.join(PROCESSED_DATA_DIR, 'test_temporal_data_nslkdd.pt')\n",
    "METADATA_FILE = os.path.join(PROCESSED_DATA_DIR, 'metadata_nslkdd.json')\n",
    "\n",
    "MODEL_SAVE_DIR = './saved_models_nslkdd/' # 更改以避免覆蓋\n",
    "BEST_MODEL_NAME = 'best_tgat_model_nslkdd.pth'\n",
    "\n",
    "DEFAULT_DEVICE_ID = 0\n",
    "DEVICE = torch.device(f'cuda:{DEFAULT_DEVICE_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- TGAT Model Hyperparameters ---\n",
    "EPOCHS = 30 # 與您的日誌輸出一致\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.0005\n",
    "HIDDEN_DIM = 256\n",
    "TIME_DIM = 64\n",
    "N_HEADS = 4\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "NUM_NEIGHBORS = [10, 5]\n",
    "CLIP_GRAD_NORM = 1.0\n",
    "WEIGHT_DECAY = 1e-5\n",
    "LR_SCHEDULER = \"cosine\"\n",
    "USE_FOCAL_LOSS = True\n",
    "CLASSIFICATION_MODE = 'binary'\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "# --- Parameters for Smarter Sampling in TemporalNeighborLoader ---\n",
    "RECENCY_BIAS_FACTOR = 0.9\n",
    "FEATURE_SIMILARITY_COL_NAME = 'service'\n",
    "FEATURE_SIMILARITY_WEIGHT = 0.3\n",
    "\n",
    "# --- Parameters for Sequence Modeling ---\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE\n",
    "SEQUENCE_LENGTH = 10\n",
    "STEP_SIZE = 5\n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64\n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 20 # 與您的日誌輸出一致\n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM\n",
    "SEQ_MODEL_HIDDEN_DIM = 128\n",
    "SEQ_MODEL_NUM_LAYERS = 1\n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'\n",
    "SEQ_MODEL_DROPOUT = 0.2\n",
    "\n",
    "# --- NSL-KDD Dataset Specific Column Names ---\n",
    "COL_NAMES = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files',\n",
    "    'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',\n",
    "    'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "    'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'attack_type', 'difficulty_score'\n",
    "]\n",
    "ATTACK_MAP_MULTI_CLASS = {\n",
    "    'normal': 0, 'dos': 1, 'probe': 2, 'r2l': 3, 'u2r': 4\n",
    "}\n",
    "KDD_SPECIFIC_TO_GENERAL_ATTACK_MAP = {\n",
    "    'back': 'dos', 'land': 'dos', 'neptune': 'dos', 'pod': 'dos', 'smurf': 'dos', 'teardrop': 'dos',\n",
    "    'mailbomb': 'dos', 'apache2': 'dos', 'processtable': 'dos', 'udpstorm': 'dos',\n",
    "    'ipsweep': 'probe', 'nmap': 'probe', 'portsweep': 'probe', 'satan': 'probe', 'mscan': 'probe', 'saint': 'probe',\n",
    "    'ftp_write': 'r2l', 'guess_passwd': 'r2l', 'imap': 'r2l', 'multihop': 'r2l', 'phf': 'r2l',\n",
    "    'spy': 'r2l', 'warezclient': 'r2l', 'warezmaster': 'r2l', 'sendmail': 'r2l', 'named': 'r2l',\n",
    "    'snmpgetattack': 'r2l', 'snmpguess': 'r2l', 'xlock': 'r2l', 'xsnoop': 'r2l', 'worm': 'r2l',\n",
    "    'buffer_overflow': 'u2r', 'loadmodule': 'u2r', 'perl': 'u2r', 'rootkit': 'u2r',\n",
    "    'httptunnel': 'u2r', 'ps': 'u2r', 'sqlattack': 'u2r', 'xterm': 'u2r'\n",
    "}\n",
    "UNKNOWN_ATTACK_CATEGORY_ID = max(ATTACK_MAP_MULTI_CLASS.values()) + 1\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "def get_device():\n",
    "    return DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038487d2-dd90-435a-8a7f-c40d56a9158e",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be5024-d6af-4536-8e83-b6b141e46d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell：Utility Functions & Custom Loss\n",
    "\n",
    "def get_device():\n",
    "    return DEVICE\n",
    "\n",
    "def plot_confusion_matrix_custom(y_true, y_pred, class_names, title='Confusion Matrix'):\n",
    "    if not y_true or not y_pred or len(y_true) != len(y_pred) or len(y_true) == 0:\n",
    "        print(f\"Cannot plot confusion matrix for {title}: y_true or y_pred is empty or mismatched.\")\n",
    "        return\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title); plt.xlabel('Predicted Label'); plt.ylabel('True Label'); plt.show()\n",
    "\n",
    "def print_metrics(epoch_str, loss, accuracy, precision, recall, f1, auc=None, phase='Train', class_report=None):\n",
    "    loss_str = f\"{loss:.4f}\" if loss is not None and not np.isnan(loss) else \"N/A\"\n",
    "    acc_str = f\"{accuracy:.4f}\" if accuracy is not None and not np.isnan(accuracy) else \"N/A\"\n",
    "    prec_str = f\"{precision:.4f}\" if precision is not None and not np.isnan(precision) else \"N/A\"\n",
    "    rec_str = f\"{recall:.4f}\" if recall is not None and not np.isnan(recall) else \"N/A\"\n",
    "    f1_str = f\"{f1:.4f}\" if f1 is not None and not np.isnan(f1) else \"N/A\"\n",
    "    \n",
    "    print(f\"{epoch_str} | {phase} Loss: {loss_str} | Acc: {acc_str} | Prec: {prec_str} | Rec: {rec_str} | F1: {f1_str}\", end=\"\")\n",
    "    if auc is not None and not np.isnan(auc):\n",
    "        print(f\" | AUC: {auc:.4f}\", end=\"\")\n",
    "    print() # Newline\n",
    "    if class_report:\n",
    "        if isinstance(class_report, str): # If it's already a formatted string\n",
    "            print(class_report)\n",
    "        elif isinstance(class_report, dict): # If it's a dict from classification_report\n",
    "            print(\"Classification Report (Dict):\\n\", json.dumps(class_report, indent=2))\n",
    "\n",
    "class FocalLoss(nn.Module): # Keep for future use\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', pos_weight_for_bce=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight_for_bce = pos_weight_for_bce\n",
    "\n",
    "    def forward(self, inputs, targets): \n",
    "        if self.pos_weight_for_bce is not None:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none', pos_weight=self.pos_weight_for_bce)\n",
    "        else:\n",
    "            bce_loss = F.binary_cross_entropy_with_logits(inputs, targets.float(), reduction='none')\n",
    "        \n",
    "        pt = torch.exp(-bce_loss) \n",
    "        \n",
    "        alpha_t = self.alpha\n",
    "        if self.alpha is not None: \n",
    "            if isinstance(self.alpha, (float, int)): \n",
    "                alpha_tensor = torch.tensor([self.alpha], device=inputs.device, dtype=inputs.dtype)\n",
    "                alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            elif isinstance(self.alpha, torch.Tensor) and self.alpha.ndim == 0: \n",
    "                 alpha_tensor = self.alpha.to(inputs.device, dtype=inputs.dtype)\n",
    "                 alpha_t = torch.where(targets == 1, alpha_tensor, 1.0 - alpha_tensor)\n",
    "            if alpha_t.ndim == 1 and targets.ndim > 1 and alpha_t.shape[0] == targets.shape[0] and targets.shape[1] == 1: # Ensure broadcasting for [B,1] targets\n",
    "                alpha_t = alpha_t.unsqueeze(1)\n",
    "            \n",
    "        if alpha_t is None: \n",
    "            focal_loss_unreduced = (1 - pt)**self.gamma * bce_loss\n",
    "        else:\n",
    "            focal_loss_unreduced = alpha_t * (1 - pt)**self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss_unreduced)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss_unreduced)\n",
    "        else: \n",
    "            return focal_loss_unreduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f4492-75ff-4946-adf0-e9db1cbcc6ad",
   "metadata": {},
   "source": [
    "## 4. Model Definition (TGAT & TemporalGraphAttentionLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45cea8-e5db-468c-8489-7ddb6581e434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Model Definition (TGAT class forward method MODIFIED for sliced data)\n",
    "class FunctionalTimeEncoder(nn.Module):\n",
    "    def __init__(self, D_in_emb, D_time_emb, D_out_emb):\n",
    "        super(FunctionalTimeEncoder, self).__init__()\n",
    "        self.time_emb_layer = nn.Linear(1, D_time_emb)\n",
    "        self.output_layer = nn.Linear(D_in_emb + D_time_emb, D_out_emb)\n",
    "\n",
    "    def forward(self, x_feat, delta_t):\n",
    "        if delta_t.ndim == 1: delta_t = delta_t.unsqueeze(-1)\n",
    "        time_embedding_input = torch.tanh(self.time_emb_layer(delta_t.float())) \n",
    "        time_emb = torch.cos(time_embedding_input) \n",
    "        output_concat = torch.cat([x_feat, time_emb], dim=-1)\n",
    "        return self.output_layer(output_concat)\n",
    "\n",
    "class TemporalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, n_feat_dim_input, n_time_emb_dim, n_out_dim_layer, n_head=2, dropout=0.1):\n",
    "        super(TemporalGraphAttentionLayer, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.n_out_dim_head = n_out_dim_layer // n_head\n",
    "        if self.n_out_dim_head == 0: \n",
    "            raise ValueError(f\"Output dimension per head is 0. n_out_dim_layer ({n_out_dim_layer}) must be >= n_head ({n_head}).\")\n",
    "        self.time_encoder = FunctionalTimeEncoder(n_feat_dim_input, n_time_emb_dim, n_feat_dim_input) \n",
    "        self.W_q = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head) \n",
    "        self.W_k = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_v = nn.Linear(n_feat_dim_input, self.n_out_dim_head * n_head)\n",
    "        self.W_out = nn.Linear(self.n_out_dim_head * n_head, n_out_dim_layer)\n",
    "        self.dropout_m = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(n_out_dim_layer)\n",
    "\n",
    "    def forward(self, target_node_feat_input, target_node_ts, neighbor_feats_input_list, neighbor_ts_list, neighbor_masks):\n",
    "        B, N_max_neighbors, D_feat_input = neighbor_feats_input_list.shape\n",
    "        if target_node_feat_input.shape[-1] != D_feat_input:\n",
    "            raise ValueError(f\"Mismatched feature dimensions for target ({target_node_feat_input.shape[-1]}) and_neighbors ({D_feat_input}) in TemporalGraphAttentionLayer\")\n",
    "\n",
    "        Q = self.W_q(target_node_feat_input).view(B, self.n_head, self.n_out_dim_head)\n",
    "        neighbor_feats_flat = neighbor_feats_input_list.reshape(-1, D_feat_input)\n",
    "        neighbor_ts_flat = neighbor_ts_list.reshape(-1)\n",
    "        target_node_ts_expanded = target_node_ts.unsqueeze(1).expand(-1, N_max_neighbors).reshape(-1)\n",
    "        delta_t_neighbors = target_node_ts_expanded - neighbor_ts_flat\n",
    "        \n",
    "        time_aware_neighbor_feats_flat = self.time_encoder(neighbor_feats_flat, delta_t_neighbors)\n",
    "        K = self.W_k(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        V = self.W_v(time_aware_neighbor_feats_flat).view(B, N_max_neighbors, self.n_head, self.n_out_dim_head)\n",
    "        K_t = K.permute(0, 2, 3, 1) \n",
    "        \n",
    "        attn_scores = torch.matmul(Q.unsqueeze(2), K_t) / np.sqrt(self.n_out_dim_head + 1e-9) \n",
    "        attn_scores = attn_scores.squeeze(2) \n",
    "        attn_scores = torch.clamp(attn_scores, min=-10.0, max=10.0) \n",
    "        attn_scores = attn_scores.masked_fill(~neighbor_masks.unsqueeze(1), float('-inf'))\n",
    "        all_masked = torch.all(attn_scores == float('-inf'), dim=-1, keepdim=True)\n",
    "        attn_scores_safe = torch.where(all_masked, torch.zeros_like(attn_scores), attn_scores)\n",
    "        attn_probs = torch.softmax(attn_scores_safe, dim=-1) \n",
    "        attn_probs = torch.where(all_masked, torch.zeros_like(attn_probs), attn_probs)\n",
    "        attn_probs = self.dropout_m(attn_probs) \n",
    "        output = torch.matmul(attn_probs.unsqueeze(2), V.permute(0, 2, 1, 3)) \n",
    "        output = output.squeeze(2).reshape(B, self.n_head * self.n_out_dim_head)\n",
    "        output = self.W_out(output)\n",
    "        output = self.dropout_m(output)\n",
    "        output = self.layer_norm(output)\n",
    "        return output\n",
    "\n",
    "class TGAT(nn.Module):\n",
    "    def __init__(self, node_feat_dim, time_emb_dim, n_head, n_layers, hidden_dim_per_layer, num_classes, dropout=0.1):\n",
    "        super(TGAT, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.node_feat_dim = node_feat_dim \n",
    "        self.attn_layers = nn.ModuleList()\n",
    "        self.neighbor_feat_projectors = nn.ModuleList()\n",
    "\n",
    "        current_dim_of_h = node_feat_dim\n",
    "        for i in range(n_layers):\n",
    "            self.attn_layers.append(\n",
    "                TemporalGraphAttentionLayer(\n",
    "                    n_feat_dim_input=current_dim_of_h, \n",
    "                    n_time_emb_dim=time_emb_dim,      \n",
    "                    n_out_dim_layer=hidden_dim_per_layer, \n",
    "                    n_head=n_head, \n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "            if i > 0: \n",
    "                self.neighbor_feat_projectors.append(\n",
    "                    nn.Linear(self.node_feat_dim, current_dim_of_h) # Project from original dim\n",
    "                )\n",
    "            else: \n",
    "                self.neighbor_feat_projectors.append(None) \n",
    "            current_dim_of_h = hidden_dim_per_layer\n",
    "\n",
    "        mlp_input_dim = current_dim_of_h\n",
    "        mlp_hidden_dim = mlp_input_dim // 2 if mlp_input_dim // 2 > 0 else 1\n",
    "        if mlp_hidden_dim == 0 : mlp_hidden_dim = 1\n",
    "\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_input_dim, mlp_hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, num_classes)\n",
    "        )\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "    # MODIFIED: forward now takes batch_node_features and batch_node_timestamps (sliced data)\n",
    "    # target_node_indices and neighbor_node_indices are now batch-local\n",
    "    def forward(self, target_node_indices_local, \n",
    "                batch_node_features, batch_node_timestamps, \n",
    "                neighbor_info_batches_all_layers_local, return_embedding=False):\n",
    "        \n",
    "        h = batch_node_features[target_node_indices_local] \n",
    "        target_ts_for_attn = batch_node_timestamps[target_node_indices_local]\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            layer_input_h_target = h \n",
    "            if i >= len(neighbor_info_batches_all_layers_local):\n",
    "                print(f\"Warning: Not enough neighbor_info_batches for layer {i}.\")\n",
    "                break \n",
    "            \n",
    "            # These are batch-local indices now\n",
    "            neighbor_node_indices_padded_local, neighbor_ts_padded, neighbor_masks = neighbor_info_batches_all_layers_local[i]\n",
    "            \n",
    "            # Fetch neighbor features using batch-local indices from batch_node_features\n",
    "            # Important: The dimension of batch_node_features is self.node_feat_dim (original)\n",
    "            original_neighbor_features = batch_node_features[neighbor_node_indices_padded_local.reshape(-1)].reshape(\n",
    "                neighbor_node_indices_padded_local.shape[0], \n",
    "                neighbor_node_indices_padded_local.shape[1], \n",
    "                self.node_feat_dim # Neighbors are always fetched with original feature dim\n",
    "            )\n",
    "            \n",
    "            projector = self.neighbor_feat_projectors[i]\n",
    "            if projector is not None:\n",
    "                # Project original neighbor features to match current_dim_of_h (which is layer_input_h_target.shape[-1])\n",
    "                B_Nmax_shape = original_neighbor_features.shape[:2]\n",
    "                flat_original_neighbor_features = original_neighbor_features.reshape(-1, self.node_feat_dim)\n",
    "                projected_flat_neighbor_features = projector(flat_original_neighbor_features)\n",
    "                input_neighbor_features_for_attn = projected_flat_neighbor_features.reshape(*B_Nmax_shape, -1)\n",
    "            else: \n",
    "                # First layer: layer_input_h_target is original_node_feat_dim, so original_neighbor_features match\n",
    "                input_neighbor_features_for_attn = original_neighbor_features\n",
    "            \n",
    "            input_neighbor_features_for_attn[~neighbor_masks] = 0 \n",
    "\n",
    "            h = self.attn_layers[i](\n",
    "                layer_input_h_target, \n",
    "                target_ts_for_attn, # These are absolute timestamps, but fetched for batch nodes\n",
    "                input_neighbor_features_for_attn, \n",
    "                neighbor_ts_padded, # These are absolute timestamps for neighbors\n",
    "                neighbor_masks\n",
    "            )\n",
    "            h = self.activation(h) \n",
    "        \n",
    "        output_logits = self.output_mlp(h)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return output_logits, h \n",
    "        else:\n",
    "            return output_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15103a6-15ef-437a-ba84-705d2d960555",
   "metadata": {},
   "source": [
    "## 5. Custom TemporalNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8936df-f7a4-4c4d-92a8-742d3b72819c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: TemporalNeighborLoader Class (MODIFIED for Smarter Neighbor Sampling)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm # Ensure tqdm is imported if used within the class\n",
    "\n",
    "class TemporalNeighborLoader:\n",
    "    def __init__(self, temporal_data_cpu, batch_size, num_neighbors_per_layer_list, device,\n",
    "                 shuffle=True, \n",
    "                 recency_bias_factor=0.8, \n",
    "                 feature_similarity_col_name='service', \n",
    "                 feature_similarity_weight=0.5, \n",
    "                 raw_data_file_path_for_ids=None, # Default is None\n",
    "                 col_names_list=None # Parameter to pass COL_NAMES for reading raw file\n",
    "                ):\n",
    "        self.temporal_data_cpu = temporal_data_cpu\n",
    "        self.x_cpu = temporal_data_cpu.x\n",
    "        self.ts_cpu = temporal_data_cpu.ts\n",
    "        self.y_cpu = temporal_data_cpu.y\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_neighbors_per_layer_list = num_neighbors_per_layer_list\n",
    "        self.shuffle = shuffle\n",
    "        self.device = device\n",
    "        self.N = temporal_data_cpu.num_nodes if temporal_data_cpu.num_nodes is not None else 0\n",
    "        self.node_indices_global = torch.arange(self.N) if self.N > 0 else torch.empty(0, dtype=torch.long)\n",
    "\n",
    "        self.adj = [[] for _ in range(self.N)]\n",
    "        if self.N > 0 and hasattr(temporal_data_cpu, 'edge_index') and temporal_data_cpu.edge_index is not None:\n",
    "            edge_index_cpu = temporal_data_cpu.edge_index.cpu() \n",
    "            src, dst = edge_index_cpu\n",
    "            \n",
    "            for i in range(len(src)):\n",
    "                s, d = src[i].item(), dst[i].item()\n",
    "                if s < self.N and d < self.N and self.ts_cpu[s] < self.ts_cpu[d]: # Bounds check\n",
    "                    self.adj[d].append(s)\n",
    "            \n",
    "            for i in range(self.N):\n",
    "                self.adj[i].sort(key=lambda pred_idx: self.ts_cpu[pred_idx], reverse=True)\n",
    "\n",
    "        self.recency_bias_factor = recency_bias_factor\n",
    "        self.feature_similarity_col_name = feature_similarity_col_name\n",
    "        self.feature_similarity_weight = feature_similarity_weight\n",
    "        self.raw_data_file_path_for_ids = raw_data_file_path_for_ids \n",
    "        self.original_feature_for_similarity_cpu = None\n",
    "        self._col_names_for_raw_read = col_names_list \n",
    "\n",
    "        if self.feature_similarity_col_name and self.raw_data_file_path_for_ids:\n",
    "            if not os.path.exists(self.raw_data_file_path_for_ids):\n",
    "                print(f\"Warning: 'raw_data_file_path_for_ids' ('{self.raw_data_file_path_for_ids}') provided but file does not exist. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self._col_names_for_raw_read is None or not isinstance(self._col_names_for_raw_read, list) or len(self._col_names_for_raw_read) == 0:\n",
    "                print(f\"Warning: 'col_names_list' not provided or invalid to TemporalNeighborLoader. Disabling feature similarity sampling for '{self.feature_similarity_col_name}'.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            elif self.feature_similarity_col_name not in self._col_names_for_raw_read:\n",
    "                print(f\"Warning: feature_similarity_col_name '{self.feature_similarity_col_name}' not found in provided col_names_list. Disabling feature similarity sampling.\")\n",
    "                self.original_feature_for_similarity_cpu = None\n",
    "            else:\n",
    "                try:\n",
    "                    print(f\"Loading '{self.feature_similarity_col_name}' from {self.raw_data_file_path_for_ids} for similarity sampling...\")\n",
    "                    df_ids = pd.read_csv(self.raw_data_file_path_for_ids, header=None, names=self._col_names_for_raw_read, usecols=[self.feature_similarity_col_name], low_memory=False)\n",
    "                    self.original_feature_for_similarity_cpu = df_ids[self.feature_similarity_col_name].values\n",
    "                    print(f\"Successfully loaded '{self.feature_similarity_col_name}' for {len(self.original_feature_for_similarity_cpu)} nodes.\")\n",
    "                    if self.N > 0 and len(self.original_feature_for_similarity_cpu) != self.N:\n",
    "                        print(f\"Warning: Length mismatch for similarity feature. Expected {self.N}, got {len(self.original_feature_for_similarity_cpu)}. Disabling feature similarity.\")\n",
    "                        self.original_feature_for_similarity_cpu = None\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not load feature '{self.feature_similarity_col_name}' for similarity sampling from '{self.raw_data_file_path_for_ids}': {e}. Disabling.\")\n",
    "                    self.original_feature_for_similarity_cpu = None\n",
    "        elif self.feature_similarity_col_name: \n",
    "             print(f\"Warning: 'feature_similarity_col_name' ('{self.feature_similarity_col_name}') provided, but 'raw_data_file_path_for_ids' is None or empty. Disabling feature similarity sampling.\")\n",
    "             self.original_feature_for_similarity_cpu = None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.N == 0 : \n",
    "            self.node_indices_permuted_global = torch.empty(0, dtype=torch.long)\n",
    "        elif self.shuffle:\n",
    "            self.node_indices_permuted_global = self.node_indices_global[torch.randperm(self.N)]\n",
    "        else:\n",
    "            self.node_indices_permuted_global = self.node_indices_global\n",
    "        self.current_idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_idx >= self.N or self.N == 0: \n",
    "            raise StopIteration\n",
    "        \n",
    "        end_idx = min(self.current_idx + self.batch_size, self.N)\n",
    "        target_node_indices_batch_global_cpu = self.node_indices_permuted_global[self.current_idx:end_idx]\n",
    "        self.current_idx = end_idx\n",
    "        \n",
    "        unique_global_indices_for_batch_set = set(target_node_indices_batch_global_cpu.tolist())\n",
    "        neighbor_info_for_model_layers_global_cpu = []\n",
    "        \n",
    "        for k_neighbors_this_layer in self.num_neighbors_per_layer_list:\n",
    "            batch_neigh_idx_padded_global_cpu, batch_neigh_ts_padded_cpu, batch_neigh_masks_cpu = [], [], []\n",
    "            for node_idx_val_global in target_node_indices_batch_global_cpu.tolist():\n",
    "                if node_idx_val_global >= self.N: \n",
    "                    preds_global = []\n",
    "                else:\n",
    "                    preds_global = self.adj[node_idx_val_global]\n",
    "                actual_k_candidates = len(preds_global)\n",
    "                \n",
    "                sampled_pred_indices_global_np = np.array([], dtype=np.int64)\n",
    "                if actual_k_candidates > 0:\n",
    "                    weights = np.ones(actual_k_candidates, dtype=float) \n",
    "                    \n",
    "                    if self.recency_bias_factor > 0 and self.recency_bias_factor < 1 and actual_k_candidates > 1:\n",
    "                        recency_weights = np.array([self.recency_bias_factor**i for i in range(actual_k_candidates)], dtype=float)\n",
    "                        weights *= recency_weights\n",
    "                    \n",
    "                    if self.original_feature_for_similarity_cpu is not None and \\\n",
    "                       self.feature_similarity_weight > 0 and \\\n",
    "                       node_idx_val_global < len(self.original_feature_for_similarity_cpu): \n",
    "                        \n",
    "                        target_feature_value = self.original_feature_for_similarity_cpu[node_idx_val_global]\n",
    "                        valid_preds_for_sim_indices = [p for p in preds_global if p < len(self.original_feature_for_similarity_cpu)]\n",
    "                        \n",
    "                        if valid_preds_for_sim_indices:\n",
    "                            pred_to_valid_idx_map = {pred_val: i for i, pred_val in enumerate(valid_preds_for_sim_indices)}\n",
    "                            neighbor_feature_values = self.original_feature_for_similarity_cpu[valid_preds_for_sim_indices]\n",
    "                            similarity_scores_for_valid_preds = np.array([1.0 if nf == target_feature_value else (1.0 - self.feature_similarity_weight) for nf in neighbor_feature_values], dtype=float)\n",
    "                            \n",
    "                            for i, pred_original_idx in enumerate(preds_global):\n",
    "                                if pred_original_idx in pred_to_valid_idx_map:\n",
    "                                    weights[i] *= similarity_scores_for_valid_preds[pred_to_valid_idx_map[pred_original_idx]]\n",
    "\n",
    "                    sum_weights = np.sum(weights)\n",
    "                    p_dist = None\n",
    "                    if sum_weights > 1e-9: \n",
    "                        p_dist = weights / sum_weights\n",
    "                    elif actual_k_candidates > 0 : \n",
    "                        pass # p=None in np.random.choice means uniform\n",
    "\n",
    "                    actual_k_to_sample = min(actual_k_candidates, k_neighbors_this_layer)\n",
    "                    \n",
    "                    try:\n",
    "                        if actual_k_candidates > 0:\n",
    "                            sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False, p=p_dist\n",
    "                            )\n",
    "                    except ValueError as e_choice: \n",
    "                        if actual_k_candidates > 0: # Ensure preds_global is not empty before trying uniform sampling\n",
    "                             # print(f\"Warning: np.random.choice ValueError ({e_choice}). Sum_w: {np.sum(p_dist) if p_dist is not None else 'None (uniform)'}. N_cand: {actual_k_candidates}, k_sample: {actual_k_to_sample}. Uniform sampling for node {node_idx_val_global}.\")\n",
    "                             sampled_pred_indices_global_np = np.random.choice(\n",
    "                                preds_global, size=actual_k_to_sample, replace=False\n",
    "                            )\n",
    "                actual_k = len(sampled_pred_indices_global_np)\n",
    "                sampled_pred_indices_global_torch = torch.from_numpy(sampled_pred_indices_global_np).long()\n",
    "                \n",
    "                sampled_pred_ts_cpu = torch.empty(0, dtype=torch.long)\n",
    "                if actual_k > 0:\n",
    "                    # Ensure sampled indices are valid before fetching from ts_cpu\n",
    "                    valid_ts_indices = sampled_pred_indices_global_torch[(sampled_pred_indices_global_torch >= 0) & (sampled_pred_indices_global_torch < self.N)]\n",
    "                    if len(valid_ts_indices) > 0: \n",
    "                        sampled_pred_ts_cpu = self.ts_cpu[valid_ts_indices]\n",
    "                    \n",
    "                    # Pad if some indices became invalid (should be rare if preds_global are valid)\n",
    "                    if len(valid_ts_indices) != actual_k:\n",
    "                         # print(f\"Warning: Timestamp fetch mismatch for node {node_idx_val_global}. Expected {actual_k}, got {len(valid_ts_indices)}. Padded with zeros.\")\n",
    "                         sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.zeros(actual_k - len(valid_ts_indices), dtype=torch.long)])\n",
    "\n",
    "                unique_global_indices_for_batch_set.update(sampled_pred_indices_global_torch.tolist())\n",
    "                \n",
    "                padding_needed = k_neighbors_this_layer - actual_k\n",
    "                mask_cpu = torch.ones(actual_k, dtype=torch.bool)\n",
    "                \n",
    "                if padding_needed > 0:\n",
    "                    pad_idx_val = 0 \n",
    "                    if self.N > 0 and pad_idx_val not in unique_global_indices_for_batch_set: \n",
    "                         unique_global_indices_for_batch_set.add(pad_idx_val)\n",
    "                    \n",
    "                    sampled_pred_indices_global_torch = torch.cat([sampled_pred_indices_global_torch, torch.full((padding_needed,), pad_idx_val, dtype=torch.long)])\n",
    "                    pad_ts_val = self.ts_cpu[pad_idx_val].item() if self.N > 0 and pad_idx_val < self.N else 0\n",
    "                    sampled_pred_ts_cpu = torch.cat([sampled_pred_ts_cpu, torch.full((padding_needed,), pad_ts_val, dtype=torch.long)])\n",
    "                    mask_cpu = torch.cat([mask_cpu, torch.zeros(padding_needed, dtype=torch.bool)])\n",
    "                \n",
    "                batch_neigh_idx_padded_global_cpu.append(sampled_pred_indices_global_torch)\n",
    "                batch_neigh_ts_padded_cpu.append(sampled_pred_ts_cpu)\n",
    "                batch_neigh_masks_cpu.append(mask_cpu)\n",
    "            \n",
    "            if not batch_neigh_idx_padded_global_cpu: # If target_node_indices_batch_global_cpu was empty or led to no neighbors\n",
    "                 dummy_shape_neighbors = (0, k_neighbors_this_layer)\n",
    "                 neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.long),\n",
    "                    torch.empty(dummy_shape_neighbors, dtype=torch.bool)))\n",
    "            else:\n",
    "                neighbor_info_for_model_layers_global_cpu.append((\n",
    "                    torch.stack(batch_neigh_idx_padded_global_cpu),\n",
    "                    torch.stack(batch_neigh_ts_padded_cpu),\n",
    "                    torch.stack(batch_neigh_masks_cpu)))\n",
    "\n",
    "        unique_global_indices_list_cpu = sorted(list(unique_global_indices_for_batch_set))\n",
    "        if not unique_global_indices_list_cpu : # If, after all processing, the set is empty\n",
    "            if self.N > 0 : # If dataset has nodes, but this batch yielded no unique indices (e.g. only padded 0s and 0 was already there)\n",
    "                unique_global_indices_list_cpu = [0] # Add 0 to fetch its features at least\n",
    "                # print(\"Warning: unique_global_indices_list_cpu was empty after processing neighbors, defaulting to [0].\")\n",
    "            else: # Dataset itself is empty\n",
    "                 # print(\"Error: Dataset has no nodes (self.N=0). Returning empty batch from loader.\")\n",
    "                 x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "                 y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                 return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                         torch.empty(0, x_dim).to(self.device), \n",
    "                         torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                         torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "\n",
    "        global_to_batch_local_idx_map = {global_idx: local_idx for local_idx, global_idx in enumerate(unique_global_indices_list_cpu)}\n",
    "        \n",
    "        valid_fetch_indices_tensor = torch.tensor(unique_global_indices_list_cpu, dtype=torch.long)\n",
    "        # Filter out-of-bounds indices, though ideally, unique_global_indices_list_cpu should only contain valid global indices < self.N\n",
    "        # (or index 0 if used for padding and N > 0)\n",
    "        valid_fetch_indices_tensor = valid_fetch_indices_tensor[valid_fetch_indices_tensor < self.N] \n",
    "        \n",
    "        if valid_fetch_indices_tensor.numel() == 0 : # If no valid indices after filtering (e.g., unique_global_indices_list_cpu was empty or only contained invalid indices)\n",
    "             if self.N > 0: # If dataset has nodes, but no valid indices were collected\n",
    "                # print(\"Warning: No valid indices to fetch features/timestamps after filtering. Using node 0 if N > 0.\")\n",
    "                valid_fetch_indices_tensor = torch.tensor([0], dtype=torch.long) # Default to fetching node 0\n",
    "                if 0 not in global_to_batch_local_idx_map: # Ensure mapping exists for node 0 if we defaulted to it\n",
    "                    global_to_batch_local_idx_map[0] = len(global_to_batch_local_idx_map) \n",
    "            \n",
    "        if valid_fetch_indices_tensor.numel() == 0: # Still no valid indices (e.g. self.N=0 or above fallback failed)\n",
    "             x_dim = self.x_cpu.shape[1] if self.x_cpu.ndim > 1 and self.x_cpu.shape[0] > 0 else 1\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             return (torch.empty(0,dtype=torch.long).to(self.device), \n",
    "                     torch.empty(0, x_dim).to(self.device), \n",
    "                     torch.empty(0,dtype=torch.long).to(self.device), [], \n",
    "                     torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device))\n",
    "\n",
    "        batch_node_features_dev = self.x_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "        batch_node_timestamps_dev = self.ts_cpu[valid_fetch_indices_tensor].to(self.device)\n",
    "\n",
    "        target_node_indices_batch_local_dev_list = []\n",
    "        for global_idx_tensor in target_node_indices_batch_global_cpu:\n",
    "            global_idx = global_idx_tensor.item()\n",
    "            local_idx = global_to_batch_local_idx_map.get(global_idx)\n",
    "            if local_idx is None: # Should not happen if unique_global_indices_for_batch_set was built from targets\n",
    "                # print(f\"Critical Warning: Target node global index {global_idx} not in local map! Using local index of global 0 as fallback.\")\n",
    "                local_idx = global_to_batch_local_idx_map.get(0,0) # Default to local index of global 0 if something went wrong\n",
    "            target_node_indices_batch_local_dev_list.append(local_idx)\n",
    "        \n",
    "        target_node_indices_batch_local_dev = torch.tensor(\n",
    "            target_node_indices_batch_local_dev_list, dtype=torch.long\n",
    "        ).to(self.device)\n",
    "\n",
    "        neighbor_info_for_model_layers_local_dev = []\n",
    "        for global_indices_layer, global_ts_layer, masks_layer in neighbor_info_for_model_layers_global_cpu:\n",
    "            if global_indices_layer.numel() > 0: \n",
    "                remapped_indices_list = []\n",
    "                for row_idx in range(global_indices_layer.shape[0]):\n",
    "                    row = global_indices_layer[row_idx]\n",
    "                    remapped_row = [global_to_batch_local_idx_map.get(x.item(), global_to_batch_local_idx_map.get(0,0)) for x in row]\n",
    "                    remapped_indices_list.append(remapped_row)\n",
    "                \n",
    "                if not remapped_indices_list: \n",
    "                     batch_local_indices_layer = torch.empty_like(global_indices_layer) \n",
    "                else:\n",
    "                     batch_local_indices_layer = torch.tensor(remapped_indices_list, dtype=torch.long)\n",
    "\n",
    "                neighbor_info_for_model_layers_local_dev.append((\n",
    "                    batch_local_indices_layer.to(self.device),\n",
    "                    global_ts_layer.to(self.device),\n",
    "                    masks_layer.to(self.device)\n",
    "                ))\n",
    "            else: \n",
    "                 k_this_layer = global_indices_layer.shape[1] if global_indices_layer.ndim ==2 and global_indices_layer.shape[1] > 0 else (self.num_neighbors_per_layer_list[0] if self.num_neighbors_per_layer_list and len(self.num_neighbors_per_layer_list)>0 else 0)\n",
    "                 dummy_shape_layer_neighbors = (len(target_node_indices_batch_global_cpu), k_this_layer) # Ensure batch dim matches target nodes\n",
    "                 if len(target_node_indices_batch_global_cpu) == 0: dummy_shape_layer_neighbors = (0, k_this_layer)\n",
    "\n",
    "                 neighbor_info_for_model_layers_local_dev.append((\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.long).to(self.device),\n",
    "                    torch.empty(dummy_shape_layer_neighbors, dtype=torch.bool).to(self.device)\n",
    "                 ))\n",
    "        \n",
    "        if target_node_indices_batch_global_cpu.numel() > 0:\n",
    "             # Ensure indices are valid for y_cpu before fetching\n",
    "             valid_y_indices = target_node_indices_batch_global_cpu[target_node_indices_batch_global_cpu < self.N]\n",
    "             if valid_y_indices.numel() > 0:\n",
    "                 batch_labels_dev = self.y_cpu[valid_y_indices].to(self.device)\n",
    "                 if len(batch_labels_dev) != len(target_node_indices_batch_local_dev): # If filtering changed size\n",
    "                     print(f\"Warning: Label batch size mismatch after filtering valid y_indices. This might cause issues.\")\n",
    "                     # Fallback: create dummy labels matching target_node_indices_batch_local_dev size\n",
    "                     y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                     batch_labels_dev = torch.empty(len(target_node_indices_batch_local_dev), *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "             else: # No valid indices left for y_cpu\n",
    "                y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "                batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        else: # target_node_indices_batch_global_cpu was empty\n",
    "             y_shape_rest = self.y_cpu.shape[1:] if self.y_cpu.ndim > 1 and self.y_cpu.shape[0] > 0 else ()\n",
    "             batch_labels_dev = torch.empty(0, *y_shape_rest, dtype=self.y_cpu.dtype).to(self.device)\n",
    "\n",
    "        return (target_node_indices_batch_local_dev,\n",
    "                batch_node_features_dev,\n",
    "                batch_node_timestamps_dev,\n",
    "                neighbor_info_for_model_layers_local_dev,\n",
    "                batch_labels_dev)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.N == 0: return 0\n",
    "        return (self.N + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292f589-fce4-4496-a455-a3620769bf62",
   "metadata": {},
   "source": [
    "## 6. Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbae281-216c-46ee-a595-681fbe6d6065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: load_processed_data function\n",
    "def load_processed_data(data_file_path: str, metadata_file_path: str, classification_mode: str = 'binary'):\n",
    "    print(f\"Loading data from: {data_file_path}\")\n",
    "    data_dict = torch.load(data_file_path, map_location='cpu') \n",
    "    \n",
    "    print(f\"Loading metadata from: {metadata_file_path}\")\n",
    "    with open(metadata_file_path, 'r') as f: metadata = json.load(f)\n",
    "\n",
    "    y_labels = data_dict['y_binary'] if classification_mode == 'binary' else data_dict['y_multiclass'].squeeze() # Ensure y_multiclass is 1D\n",
    "    num_classes = metadata['NUM_CLASSES_BINARY'] if classification_mode == 'binary' else metadata['NUM_CLASSES_MULTI']\n",
    "    \n",
    "    pos_weight_tensor = None\n",
    "    if classification_mode == 'binary':\n",
    "        pos_weight_val = metadata.get('POS_WEIGHT_BINARY', 1.0)\n",
    "        pos_weight_tensor = torch.tensor([pos_weight_val], dtype=torch.float32) \n",
    "\n",
    "    temporal_data_obj = TemporalData(x=data_dict['x'], edge_index=data_dict['edge_index'], \n",
    "                                     ts=data_dict['ts'], y=y_labels)\n",
    "    \n",
    "    print(f\"Data loaded: Nodes={temporal_data_obj.num_nodes}, Edges={temporal_data_obj.num_edges}\")\n",
    "    print(f\"Metadata: NodeFeatDim={metadata['NODE_FEAT_DIM']}, NumClasses({classification_mode})={num_classes}, PosWeight={pos_weight_tensor.item() if pos_weight_tensor is not None and classification_mode == 'binary' else 'N/A_or_Multiclass'}\")\n",
    "    return temporal_data_obj, metadata, num_classes, pos_weight_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549ab9b-0cd9-4513-9fac-2498fb7b1299",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b2775-77b8-489a-8486-26dfcfc5d3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_epoch and evaluate_model functions (MODIFIED for new loader output)\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, clip_grad_val=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list = [], []\n",
    "    valid_batches_for_loss = 0\n",
    "    pbar = tqdm(loader, desc=\"Train Epoch\")\n",
    "    # MODIFIED: Unpack new items from loader\n",
    "    for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                     neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                print(f\"Warning: Batch {batch_idx} has insufficient neighbor_info_batches for N_LAYERS. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # MODIFIED: Pass sliced data to model\n",
    "            output_logits = model(target_indices_local_dev, batch_features_dev, batch_ts_dev, neighbor_batches_local_dev)\n",
    "            \n",
    "            if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                print(f\"Batch {batch_idx}: NaNs/Infs in model output_logits! Skipping.\")\n",
    "                continue \n",
    "            \n",
    "            # batch_labels_dev are already on device and correspond to target_indices_local_dev\n",
    "            true_labels_dev = batch_labels_dev \n",
    "            if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "            elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "            \n",
    "            loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "            \n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Batch {batch_idx}: Loss is NaN or Inf! Skipping backward. Logits: {output_logits.flatten()[:3]}, Labels: {true_labels_dev.flatten()[:3]}\")\n",
    "                continue \n",
    "            \n",
    "            loss.backward()\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and (param.grad.isnan().any() or param.grad.isinf().any()):\n",
    "                    print(f\"Batch {batch_idx}: NaNs/Infs in gradients of {name}! Zeroing grad.\")\n",
    "                    param.grad = torch.zeros_like(param.grad) \n",
    "            if clip_grad_val:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_val)\n",
    "            optimizer.step()\n",
    "            \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.isnan().any() or param.isinf().any():\n",
    "                    print(f\"CRITICAL: Batch {batch_idx}: NaNs/Infs in param {name} AFTER step!\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            valid_batches_for_loss += 1\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                preds = (torch.sigmoid(output_logits.detach()) > 0.5).cpu().numpy() if CLASSIFICATION_MODE == 'binary' else torch.argmax(output_logits.detach(), dim=1).cpu().numpy()\n",
    "            all_preds_list.extend(preds.flatten().tolist())\n",
    "            all_true_list.extend(true_labels_dev.cpu().numpy().flatten().tolist()) # Use true_labels_dev which is already processed\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        except RuntimeError as e:\n",
    "            if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                print(f\"RuntimeError involving NaN/Inf in train batch {batch_idx}: {e}. Skipping.\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Unexpected RuntimeError in train batch {batch_idx}: {e}\")\n",
    "                raise e\n",
    "                \n",
    "    if valid_batches_for_loss == 0: return float('nan'),0,0,0,0,None\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list): return avg_loss,0,0,0,0,None\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_val = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, pos_label=pos_label_val, zero_division=0)\n",
    "    else:\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode, zero_division=0)\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(np.unique(all_true_list)) >= 2:\n",
    "        # For AUC with 0/1 preds, it's equivalent to accuracy if preds are hard labels.\n",
    "        # If output_logits were probabilities, this would be more meaningful.\n",
    "        # The current `all_preds_list` are hard 0/1 predictions.\n",
    "        try:\n",
    "            auc = roc_auc_score(all_true_list, all_preds_list) \n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute train AUC (0/1 preds): {e}. True unique: {np.unique(all_true_list)}\")\n",
    "            \n",
    "    return avg_loss, accuracy, precision, recall, f1, auc\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, phase='Validation', return_embeddings_and_ids=False, entity_id_col_name=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_list, all_true_list, all_probs_binary_list = [], [], []\n",
    "    \n",
    "    all_node_embeddings_list = []\n",
    "    all_target_node_indices_global_list = [] # Store GLOBAL indices if needed for post-hoc\n",
    "    all_entity_ids_list = []\n",
    "\n",
    "    valid_batches_for_loss = 0\n",
    "    class_report_dict = None\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        # MODIFIED: Unpack new items from loader\n",
    "        for batch_idx, (target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                         neighbor_batches_local_dev, batch_labels_dev) in enumerate(pbar):\n",
    "            try:\n",
    "                if len(neighbor_batches_local_dev) < model.n_layers:\n",
    "                    print(f\"Warning: Batch {batch_idx} in {phase} has insufficient neighbor_info_batches. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                if return_embeddings_and_ids:\n",
    "                    # MODIFIED: Pass sliced data to model\n",
    "                    output_logits, node_embeddings = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=True\n",
    "                    )\n",
    "                    all_node_embeddings_list.append(node_embeddings.cpu())\n",
    "                    # To get global indices for post-hoc, we need the loader to also provide the original global indices for the batch\n",
    "                    # The current modified loader does not explicitly return target_node_indices_batch_global_cpu in the tuple.\n",
    "                    # For now, if we need global indices, this part needs adjustment in loader output.\n",
    "                    # Assuming target_indices_local_dev can be mapped back if necessary, or loader provides mapping.\n",
    "                    # For simplicity, let's say we store local indices for now, or acknowledge this limitation for post-hoc.\n",
    "                    # If loader.current_idx and batch_size are used, we can reconstruct global indices if not shuffled.\n",
    "                    # Placeholder:\n",
    "                    # all_target_node_indices_global_list.append(target_indices_local_dev.cpu()) # This is NOT global yet\n",
    "                    \n",
    "                else:\n",
    "                    output_logits = model(\n",
    "                        target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                        neighbor_batches_local_dev, return_embedding=False\n",
    "                    )\n",
    "\n",
    "                if output_logits.isnan().any() or output_logits.isinf().any():\n",
    "                    print(f\"Batch {batch_idx} in {phase}: NaNs or Infs in model output_logits! Skipping metrics for this batch.\")\n",
    "                    continue\n",
    "                \n",
    "                true_labels_dev = batch_labels_dev # Already on device\n",
    "                if CLASSIFICATION_MODE == 'binary' and true_labels_dev.ndim == 1:\n",
    "                    true_labels_dev = true_labels_dev.unsqueeze(1)\n",
    "                elif CLASSIFICATION_MODE == 'multiclass' and true_labels_dev.ndim > 1 and true_labels_dev.size(1) == 1:\n",
    "                    true_labels_dev = true_labels_dev.squeeze(1).long()\n",
    "                \n",
    "                loss = criterion(output_logits, true_labels_dev.float() if CLASSIFICATION_MODE == 'binary' else true_labels_dev)\n",
    "                if not (loss.isnan() or loss.isinf()):\n",
    "                    total_loss += loss.item()\n",
    "                    valid_batches_for_loss +=1\n",
    "                else:\n",
    "                    print(f\"Batch {batch_idx} in {phase}: Loss is NaN or Inf! Logits: {output_logits.flatten()[:5]}\")\n",
    "                \n",
    "                current_batch_true_labels = true_labels_dev.cpu().numpy().flatten().tolist()\n",
    "                current_batch_preds_np, current_batch_probs_np = np.array([]), np.array([])\n",
    "                \n",
    "                if CLASSIFICATION_MODE == 'binary':\n",
    "                    probs = torch.sigmoid(output_logits)\n",
    "                    if probs.isnan().any() or probs.isinf().any():\n",
    "                        print(f\"Batch {batch_idx} in {phase}: Sigmoid probs NaN/Inf.\")\n",
    "                        current_batch_preds_np = np.zeros(len(current_batch_true_labels), dtype=int) \n",
    "                        current_batch_probs_np = np.full(len(current_batch_true_labels), 0.5, dtype=float)\n",
    "                    else:\n",
    "                        current_batch_probs_np = probs.cpu().numpy().flatten()\n",
    "                        current_batch_preds_np = (probs > 0.5).cpu().numpy().flatten()\n",
    "                    all_probs_binary_list.extend(current_batch_probs_np.tolist())\n",
    "                else:\n",
    "                    current_batch_preds_np = torch.argmax(output_logits, dim=1).cpu().numpy().flatten()\n",
    "                \n",
    "                all_preds_list.extend(current_batch_preds_np.tolist())\n",
    "                all_true_list.extend(current_batch_true_labels) \n",
    "                pbar.set_postfix({'loss': loss.item() if not (loss.isnan() or loss.isinf()) else float('nan')})\n",
    "            except RuntimeError as e:\n",
    "                if \"NaN\" in str(e) or \"Inf\" in str(e) or \"nan\" in str(e):\n",
    "                    print(f\"RuntimeError involving NaN/Inf in {phase} batch {batch_idx}: {e}. Skipping.\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Unexpected RuntimeError in {phase} batch {batch_idx}: {e}\")\n",
    "                    raise e\n",
    "\n",
    "    if valid_batches_for_loss == 0: \n",
    "        empty_return = (float('nan'),0,0,0,0, None, [], [], None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "\n",
    "    avg_loss = total_loss / valid_batches_for_loss\n",
    "    if not all_true_list or not all_preds_list or len(all_true_list) != len(all_preds_list):\n",
    "        print(f\"Warning: Mismatch/empty metric lists in {phase}. True: {len(all_true_list)}, Pred: {len(all_preds_list)}\")\n",
    "        empty_return = (avg_loss,0,0,0,0,None,all_true_list,all_preds_list, None)\n",
    "        if return_embeddings_and_ids: empty_return += (torch.empty(0), torch.empty(0), [])\n",
    "        return empty_return\n",
    "    \n",
    "    accuracy = accuracy_score(all_true_list, all_preds_list)\n",
    "    avg_mode_overall = 'binary' if CLASSIFICATION_MODE == 'binary' else 'weighted'\n",
    "    pos_label_overall = 1 if CLASSIFICATION_MODE == 'binary' else None\n",
    "    \n",
    "    if CLASSIFICATION_MODE == 'binary':\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, pos_label=pos_label_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            target_names = ['Normal (0)', 'Attack (1)']\n",
    "            try: \n",
    "                class_report_dict = classification_report(all_true_list, all_preds_list, target_names=target_names, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    else: \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_true_list, all_preds_list, average=avg_mode_overall, zero_division=0)\n",
    "        if len(np.unique(all_true_list)) >=2:\n",
    "            try: class_report_dict = classification_report(all_true_list, all_preds_list, zero_division=0, output_dict=True)\n",
    "            except ValueError as e_report: print(f\"Could not generate classification report dict in {phase}: {e_report}\")\n",
    "    \n",
    "    auc = None\n",
    "    if CLASSIFICATION_MODE == 'binary' and len(all_true_list) > 0 :\n",
    "        valid_pairs = [(t, p) for t, p in zip(all_true_list, all_probs_binary_list) if not (isinstance(p, (float, np.floating)) and (np.isnan(p) or np.isinf(p)))]\n",
    "        if len(valid_pairs) > 1:\n",
    "            vt, vp = [p[0] for p in valid_pairs], [p[1] for p in valid_pairs]\n",
    "            if len(np.unique(vt)) >= 2:\n",
    "                try: auc = roc_auc_score(vt, vp)\n",
    "                except ValueError as e: print(f\"Could not compute AUC in {phase} (filtered): {e}. Unique true: {np.unique(vt)}\")\n",
    "            else: print(f\"Not enough unique classes in valid_true_for_auc ({np.unique(vt)}) for AUC in {phase}.\")\n",
    "        else: print(f\"Not enough valid (non-NaN prob) points ({len(valid_pairs)}) for AUC in {phase}.\")\n",
    "    \n",
    "    if return_embeddings_and_ids:\n",
    "        final_embeddings = torch.cat(all_node_embeddings_list, dim=0) if all_node_embeddings_list else torch.empty(0)\n",
    "        # final_indices below would be local if all_target_node_indices_global_list is not populated with global indices\n",
    "        final_indices = torch.cat(all_target_node_indices_global_list, dim=0) if all_target_node_indices_global_list else torch.empty(0) \n",
    "        final_entity_ids = [] # Placeholder, not populated in this version\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict, final_embeddings, final_indices, final_entity_ids\n",
    "    else:\n",
    "        return avg_loss, accuracy, precision, recall, f1, auc, all_true_list, all_preds_list, class_report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae711d39-282f-4cda-bb68-276e8cd4306c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW/MODIFIED - Prepare Sequences from Event Embeddings\n",
    "\n",
    "import torch.nn.utils.rnn as rnn_utils # 確保 rnn_utils 已導入，雖然此函數不直接用它，但它在序列部分被使用\n",
    "\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat,\n",
    "                             raw_file_path_for_loader_ids=None, # 新增參數\n",
    "                             col_names_for_loader_ids=None):    # 新增參數\n",
    "    \"\"\"\n",
    "    Gets TGAT embeddings for all events in data_cpu.\n",
    "    Assumes model_tgat is already trained and on the correct device.\n",
    "    \"\"\"\n",
    "    model_tgat.eval()\n",
    "    # 使用修改後的 TemporalNeighborLoader，它可以處理原始文件路徑以進行特徵相似性取樣\n",
    "    loader = TemporalNeighborLoader(\n",
    "        data_cpu, \n",
    "        batch_size_for_gen, \n",
    "        num_neighbors_tgat, \n",
    "        device_tgat, \n",
    "        shuffle=False,\n",
    "        raw_data_file_path_for_ids=raw_file_path_for_loader_ids, # 傳遞參數\n",
    "        col_names_list=col_names_for_loader_ids                    # 傳遞參數\n",
    "    )\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    all_global_indices_list = [] \n",
    "    all_original_labels_list = [] \n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data\n",
    "\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            # 假設非隨機 loader 按順序提供全局索引\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "            _, node_embeddings = model_tgat( # 假設 TGAT forward 返回 (logits, embeddings)\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu())\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu())\n",
    "    \n",
    "    if not all_embeddings_list:\n",
    "        # 如果模型有 attn_layers 屬性且不為空，則獲取輸出維度，否則使用預設值\n",
    "        emb_dim_placeholder = model_tgat.attn_layers[-1].n_out_dim_layer \\\n",
    "            if hasattr(model_tgat, 'attn_layers') and model_tgat.attn_layers \\\n",
    "            else (model_tgat.output_mlp[0].in_features if hasattr(model_tgat, 'output_mlp') and model_tgat.output_mlp else 128) # 備用回退\n",
    "        \n",
    "        # 返回兩個值以匹配解包\n",
    "        return torch.empty(0, emb_dim_placeholder), torch.empty(0, dtype=torch.long) \n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', # 'any_attack', 'all_attack', 'majority_attack'\n",
    "                               classification_mode='binary'): # For KDD, labels are binary or multiclass event-wise\n",
    "    \"\"\"\n",
    "    Creates sequences of embeddings and corresponding sequence labels.\n",
    "    event_labels should be for binary classification (0 for normal, 1 for attack event).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length]\n",
    "        seq_event_labels = event_labels[i : i + sequence_length] # These are event-level labels\n",
    "\n",
    "        if classification_mode == 'binary':\n",
    "            # Determine sequence label based on event labels within the sequence\n",
    "            if label_mode == 'any_attack':\n",
    "                # If any event in the sequence is an attack, the sequence is an attack\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                # Only if all events in sequence are attacks\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                # If majority of events are attacks\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: # Default to 'any_attack'\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # Multiclass - how to define sequence label? For now, let's assume binary sequence target.\n",
    "            # Or, one could try to predict the dominant attack type in the sequence, or a multi-label output.\n",
    "            # This part needs more sophisticated handling for multiclass sequence labeling.\n",
    "            # For simplicity, we'll stick to binary sequence classification (attack vs. normal sequence).\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is not deeply implemented. Defaulting to binary 'any_attack'.\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal in multiclass too\n",
    "\n",
    "        sequences.append(seq)\n",
    "        sequence_labels.append(label)\n",
    "    \n",
    "    if not sequences:\n",
    "        # Return empty tensors with expected structure if no sequences are generated\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "\n",
    "    # For PackedSequence, we need lengths of sequences before padding\n",
    "    # In this sliding window approach, all sequences have the same length `sequence_length`\n",
    "    lengths = [sequence_length] * len(sequences)\n",
    "    \n",
    "    # Pad sequences to the max length (which is sequence_length here)\n",
    "    # `sequences` is a list of Tensors [ (seq_len, embed_dim), ... ]\n",
    "    # Need to stack them and then pad if lengths were variable. Here they are fixed.\n",
    "    padded_sequences = torch.stack(sequences) # (num_sequences, sequence_length, embedding_dim)\n",
    "    \n",
    "    return sequences, sequence_labels, padded_sequences, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32) # For BCEWithLogitsLoss\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return sequence, its actual length, and its label\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed(batch):\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already padded to the same length `sequence_length`\n",
    "    padded_sequences = torch.stack(sequences) # (batch_size, sequence_length, embedding_dim)\n",
    "    \n",
    "    # Create PackedSequence\n",
    "    # Sort by lengths in descending order for pack_padded_sequence\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    sorted_lengths, sorted_idx = lengths.sort(descending=True)\n",
    "    sorted_sequences = padded_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Also sort labels according to sorted_idx\n",
    "    labels = torch.stack(labels)[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9075d7-1512-48d5-bfa9-2f543572affa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: NEW - Training and Evaluation for Sequence Aggregator Model\n",
    "\n",
    "def train_sequence_epoch(seq_model, loader, optimizer, criterion_seq, device):\n",
    "    seq_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "        if loss.isnan() or loss.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds.extend(preds.flatten().tolist())\n",
    "        all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_seq_preds, all_seq_true, all_seq_probs = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss = criterion_seq(output_logits_seq, labels_batch)\n",
    "            if loss.isnan() or loss.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds = (probs > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds.extend(preds.flatten().tolist())\n",
    "            all_seq_true.extend(labels_batch.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs.extend(probs.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy = accuracy_score(all_seq_true, all_seq_preds) if all_seq_true else 0.0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_seq_true, all_seq_preds, average='binary', zero_division=0) if all_seq_true else (0,0,0,None)\n",
    "    \n",
    "    auc = None\n",
    "    if all_seq_true and all_seq_probs and len(np.unique(all_seq_true)) >= 2:\n",
    "        try:\n",
    "            auc = roc_auc_score(all_seq_true, all_seq_probs)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(phase, avg_loss, accuracy, precision, recall, f1, auc, phase=f\"{phase} Results\")\n",
    "    return avg_loss, accuracy, precision, recall, f1, auc, all_seq_true, all_seq_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9261f6-ce2d-418d-a83c-c16c952b719c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Sequence Modeling Additions and Modified Pipeline (Conceptual)\n",
    "# Ensure all necessary imports from the original notebook are present\n",
    "# e.g., torch, nn, optim, tqdm, sklearn.metrics, plt, np, os, json, time, Dataset, DataLoader, F\n",
    "# from torch.utils.data import Dataset, DataLoader # Add if not already imported globally\n",
    "\n",
    "\n",
    "# 1. EventSequenceAggregator Model Definition\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class EventSequenceAggregator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, num_classes, dropout=0.1, rnn_type='GRU'):\n",
    "        super(EventSequenceAggregator, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.rnn_type = rnn_type.upper()\n",
    "\n",
    "        if self.rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type. Choose 'GRU' or 'LSTM'.\")\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout_layer = nn.Dropout(dropout) # Renamed to avoid conflict\n",
    "\n",
    "    def forward(self, packed_event_embeddings):\n",
    "        # packed_event_embeddings is a PackedSequence object\n",
    "        if self.rnn_type == 'GRU':\n",
    "            # output is (batch, seq_len, hidden_dim) for packed sequence\n",
    "            # hidden is (num_layers, batch_size, hidden_dim)\n",
    "            _, hidden = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = hidden[-1, :, :] \n",
    "        elif self.rnn_type == 'LSTM':\n",
    "            # output is (batch, seq_len, hidden_dim)\n",
    "            # h_n is (num_layers, batch_size, hidden_dim)\n",
    "            # c_n is (num_layers, batch_size, hidden_dim)\n",
    "            _, (h_n, _) = self.rnn(packed_event_embeddings) \n",
    "            last_hidden = h_n[-1, :, :]\n",
    "        \n",
    "        out = self.dropout_layer(last_hidden)\n",
    "        out = self.fc(out) \n",
    "        return out\n",
    "\n",
    "# 2. Functions to Prepare Sequences from Event Embeddings\n",
    "def get_all_event_embeddings(model_tgat, data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat):\n",
    "    model_tgat.eval()\n",
    "    # Use the modified TemporalNeighborLoader that handles sliced data loading\n",
    "    loader = TemporalNeighborLoader(data_cpu, batch_size_for_gen, num_neighbors_tgat, device_tgat, shuffle=False)\n",
    "    \n",
    "    all_embeddings_list = []\n",
    "    all_global_indices_list = [] \n",
    "    all_original_labels_list = [] \n",
    "    \n",
    "    print(\"Generating TGAT embeddings for all events...\")\n",
    "    processed_global_idx_count = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(loader, desc=\"Generating Embeddings\"):\n",
    "            target_indices_local_dev, batch_features_dev, batch_ts_dev, \\\n",
    "            neighbor_batches_local_dev, batch_labels_dev = batch_data\n",
    "\n",
    "            batch_size_actual = target_indices_local_dev.size(0)\n",
    "            # Assuming non-shuffled loader gives sequential global indices\n",
    "            global_indices_for_this_batch = torch.arange(\n",
    "                processed_global_idx_count, \n",
    "                processed_global_idx_count + batch_size_actual\n",
    "            ).long()\n",
    "            processed_global_idx_count += batch_size_actual\n",
    "\n",
    "            _, node_embeddings = model_tgat( # Assuming TGAT forward returns (logits, embeddings)\n",
    "                target_indices_local_dev, batch_features_dev, batch_ts_dev, \n",
    "                neighbor_batches_local_dev, return_embedding=True\n",
    "            )\n",
    "            all_embeddings_list.append(node_embeddings.cpu())\n",
    "            all_global_indices_list.append(global_indices_for_this_batch.cpu())\n",
    "            all_original_labels_list.append(batch_labels_dev.cpu())\n",
    "\n",
    "    if not all_embeddings_list:\n",
    "        # Determine embedding_dim from model or data if possible, else use a placeholder\n",
    "        emb_dim_placeholder = model_tgat.attn_layers[-1].n_out_dim_layer if hasattr(model_tgat, 'attn_layers') and model_tgat.attn_layers else 128 # Fallback\n",
    "        return torch.empty(0, emb_dim_placeholder), torch.empty(0, dtype=torch.long), torch.empty(0)\n",
    "\n",
    "\n",
    "    full_embeddings = torch.cat(all_embeddings_list, dim=0)\n",
    "    full_global_indices = torch.cat(all_global_indices_list, dim=0)\n",
    "    full_original_labels = torch.cat(all_original_labels_list, dim=0)\n",
    "\n",
    "    sorted_idx_map = torch.argsort(full_global_indices)\n",
    "    sorted_embeddings = full_embeddings[sorted_idx_map]\n",
    "    sorted_labels = full_original_labels[sorted_idx_map]\n",
    "    \n",
    "    print(f\"Generated {sorted_embeddings.shape[0]} event embeddings of dimension {sorted_embeddings.shape[1]}\")\n",
    "    return sorted_embeddings, sorted_labels\n",
    "\n",
    "\n",
    "def create_embedding_sequences(event_embeddings, event_labels, sequence_length, step_size,\n",
    "                               label_mode='any_attack', classification_mode='binary'):\n",
    "    sequences_as_tensors = [] # Store list of tensors directly\n",
    "    sequence_labels_list = []\n",
    "    num_events = event_embeddings.shape[0]\n",
    "\n",
    "    for i in range(0, num_events - sequence_length + 1, step_size):\n",
    "        seq = event_embeddings[i : i + sequence_length] # (sequence_length, embedding_dim)\n",
    "        seq_event_labels = event_labels[i : i + sequence_length]\n",
    "\n",
    "        label = 0 # Default to normal\n",
    "        if classification_mode == 'binary': # Ensure event_labels are binary (0 or 1)\n",
    "            if label_mode == 'any_attack':\n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'all_attack':\n",
    "                label = 1 if torch.all(seq_event_labels.float() == 1.0) else 0\n",
    "            elif label_mode == 'majority_attack':\n",
    "                label = 1 if torch.sum(seq_event_labels.float() == 1.0) > sequence_length / 2 else 0\n",
    "            else: \n",
    "                label = 1 if torch.any(seq_event_labels.float() == 1.0) else 0\n",
    "        else: # For multiclass event labels, defining sequence label needs care\n",
    "            print(\"Warning: Sequence labeling for 'multiclass' event labels is complex. Defaulting to binary 'any_attack' (event_label > 0 is attack).\")\n",
    "            label = 1 if torch.any(seq_event_labels.float() > 0) else 0 # Assuming 0 is normal\n",
    "\n",
    "        sequences_as_tensors.append(seq)\n",
    "        sequence_labels_list.append(label)\n",
    "    \n",
    "    if not sequences_as_tensors:\n",
    "        embedding_dim = event_embeddings.shape[1] if event_embeddings.numel() > 0 else 1\n",
    "        return [], torch.empty(0, sequence_length, embedding_dim), torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    padded_sequences = torch.stack(sequences_as_tensors) # (num_sequences, sequence_length, embedding_dim)\n",
    "    lengths = torch.full((len(sequences_as_tensors),), sequence_length, dtype=torch.long) # All sequences have same length\n",
    "    \n",
    "    return sequence_labels_list, padded_sequences, lengths\n",
    "\n",
    "\n",
    "class EmbeddingSequenceDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, sequence_labels, sequence_lengths):\n",
    "        self.padded_sequences = padded_sequences\n",
    "        # Ensure sequence_labels is a tensor\n",
    "        if isinstance(sequence_labels, list):\n",
    "            self.sequence_labels = torch.tensor(sequence_labels, dtype=torch.float32)\n",
    "        elif isinstance(sequence_labels, torch.Tensor):\n",
    "            self.sequence_labels = sequence_labels.float()\n",
    "        else:\n",
    "            raise TypeError(f\"sequence_labels must be a list or Tensor, got {type(sequence_labels)}\")\n",
    "\n",
    "        self.sequence_lengths = sequence_lengths # This is a tensor of lengths for each sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.padded_sequences[idx], self.sequence_lengths[idx], self.sequence_labels[idx]\n",
    "\n",
    "def collate_fn_packed_fixed_length(batch): # Simplified for fixed length sequences from sliding window\n",
    "    sequences, lengths, labels = zip(*batch)\n",
    "    # sequences are already Tensors of shape (sequence_length, embedding_dim)\n",
    "    # Stack them to create (batch_size, sequence_length, embedding_dim)\n",
    "    stacked_sequences = torch.stack(sequences)\n",
    "    \n",
    "    # lengths are all the same (SEQUENCE_LENGTH), but pack_padded_sequence still needs them\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.long) \n",
    "    \n",
    "    # Sort by lengths in descending order (though here all are same)\n",
    "    sorted_lengths, sorted_idx = lengths_tensor.sort(descending=True)\n",
    "    sorted_sequences = stacked_sequences[sorted_idx]\n",
    "    \n",
    "    packed_sequences = rnn_utils.pack_padded_sequence(sorted_sequences, sorted_lengths.cpu(), batch_first=True)\n",
    "    \n",
    "    # Sort labels\n",
    "    labels_tensor = torch.stack([l if isinstance(l, torch.Tensor) else torch.tensor(l) for l in labels])\n",
    "    sorted_labels = labels_tensor[sorted_idx]\n",
    "    \n",
    "    return packed_sequences, sorted_labels\n",
    "\n",
    "\n",
    "# 3. Training and Evaluation Functions for Sequence Model\n",
    "def train_sequence_epoch(seq_model, loader, optimizer_seq, criterion_seq, device_seq):\n",
    "    seq_model.train()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_epoch, all_seq_true_epoch = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Train Sequence Epoch\")\n",
    "    for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "        packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "        labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1) # For BCEWithLogitsLoss\n",
    "\n",
    "        optimizer_seq.zero_grad()\n",
    "        output_logits_seq = seq_model(packed_sequences_batch)\n",
    "        \n",
    "        loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "        if loss_seq.isnan() or loss_seq.isinf():\n",
    "            print(f\"Sequence Train: Loss NaN/Inf. Logits: {output_logits_seq.flatten()[:3]}, Labels: {labels_batch_seq.flatten()[:3]}. Skipping batch.\")\n",
    "            continue\n",
    "            \n",
    "        loss_seq.backward()\n",
    "        optimizer_seq.step()\n",
    "        \n",
    "        total_loss_seq += loss_seq.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds_seq = (torch.sigmoid(output_logits_seq.detach()) > 0.5).cpu().numpy()\n",
    "        all_seq_preds_epoch.extend(preds_seq.flatten().tolist())\n",
    "        all_seq_true_epoch.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "        pbar.set_postfix({'loss': loss_seq.item()})\n",
    "        \n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    # Ensure all_seq_true_epoch is not empty before calculating metrics\n",
    "    if not all_seq_true_epoch:\n",
    "        print(\"Warning: No true labels collected in sequence training epoch.\")\n",
    "        return avg_loss_seq, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    accuracy_seq = accuracy_score(all_seq_true_epoch, all_seq_preds_epoch)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_epoch, all_seq_preds_epoch, average='binary', zero_division=0)\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq\n",
    "\n",
    "def evaluate_sequence_model(seq_model, loader, criterion_seq, device_seq, phase=\"Val Seq\"):\n",
    "    seq_model.eval()\n",
    "    total_loss_seq = 0.0\n",
    "    all_seq_preds_eval, all_seq_true_eval, all_seq_probs_eval = [], [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=f\"{phase} Phase\")\n",
    "    with torch.no_grad():\n",
    "        for packed_sequences_batch, labels_batch_seq in pbar:\n",
    "            packed_sequences_batch = packed_sequences_batch.to(device_seq)\n",
    "            labels_batch_seq = labels_batch_seq.to(device_seq).unsqueeze(1)\n",
    "\n",
    "            output_logits_seq = seq_model(packed_sequences_batch)\n",
    "            loss_seq = criterion_seq(output_logits_seq, labels_batch_seq)\n",
    "            if loss_seq.isnan() or loss_seq.isinf():\n",
    "                print(f\"Sequence Eval {phase}: Loss NaN/Inf. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            total_loss_seq += loss_seq.item()\n",
    "            \n",
    "            probs_seq = torch.sigmoid(output_logits_seq.detach())\n",
    "            preds_seq = (probs_seq > 0.5).cpu().numpy()\n",
    "            \n",
    "            all_seq_preds_eval.extend(preds_seq.flatten().tolist())\n",
    "            all_seq_true_eval.extend(labels_batch_seq.cpu().numpy().flatten().tolist())\n",
    "            all_seq_probs_eval.extend(probs_seq.cpu().numpy().flatten().tolist())\n",
    "            pbar.set_postfix({'loss': loss_seq.item()})\n",
    "\n",
    "    if not all_seq_true_eval: # Check if any data was processed\n",
    "        print(f\"Warning: No true labels collected in sequence evaluation phase {phase}.\")\n",
    "        return float('nan'), 0.0, 0.0, 0.0, 0.0, None, [], []\n",
    "\n",
    "\n",
    "    avg_loss_seq = total_loss_seq / len(loader) if len(loader) > 0 else float('nan')\n",
    "    accuracy_seq = accuracy_score(all_seq_true_eval, all_seq_preds_eval)\n",
    "    precision_seq, recall_seq, f1_seq, _ = precision_recall_fscore_support(all_seq_true_eval, all_seq_preds_eval, average='binary', zero_division=0)\n",
    "    \n",
    "    auc_seq = None\n",
    "    if all_seq_probs_eval and len(np.unique(all_seq_true_eval)) >= 2:\n",
    "        try:\n",
    "            auc_seq = roc_auc_score(all_seq_true_eval, all_seq_probs_eval)\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute AUC for sequences in {phase}: {e}\")\n",
    "            \n",
    "    print_metrics(f\"{phase} Seq Aggregator\", avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, phase=f\"{phase} Seq Results\")\n",
    "    return avg_loss_seq, accuracy_seq, precision_seq, recall_seq, f1_seq, auc_seq, all_seq_true_eval, all_seq_preds_eval\n",
    "\n",
    "\n",
    "# 4. Modified train_pipeline (Conceptual - integrate stage 2)\n",
    "# This is a high-level sketch. The original train_pipeline needs to be carefully refactored.\n",
    "# For now, I will keep the original train_pipeline as is, and the sequence training\n",
    "# will be a separate set of calls in the __main__ block after TGAT training.\n",
    "\n",
    "# --- Keeping original train_pipeline for TGAT ---\n",
    "# The original train_pipeline in cell \"d6727e62-27d4-4ac9-8ffa-2563c1be7743\"\n",
    "# will train and save the best TGAT model. We will use that saved model.\n",
    "\n",
    "# --- Add these to your global configuration (e.g., Cell 2 of the notebook) ---\n",
    "# Make sure these are defined if you haven't already\n",
    "BATCH_SIZE_SEQ_EMBED_GEN = BATCH_SIZE # Use TGAT's batch size for consistency or define separately\n",
    "SEQUENCE_LENGTH = 10 \n",
    "STEP_SIZE = 5      \n",
    "SEQ_LABEL_MODE = 'any_attack'\n",
    "BATCH_SIZE_SEQ_MODEL = 64  \n",
    "LEARNING_RATE_SEQ_MODEL = 1e-4\n",
    "EPOCHS_SEQ_MODEL = 20 # Fewer epochs for the sequence model might be sufficient\n",
    "SEQ_MODEL_EMBEDDING_DIM_ACTUAL = HIDDEN_DIM # This is the output dim of TGAT's attention layers, used as input to its MLP\n",
    "                                          # and thus the dimension of embeddings `h` returned by TGAT\n",
    "SEQ_MODEL_HIDDEN_DIM = 128   \n",
    "SEQ_MODEL_NUM_LAYERS = 1 # GRU/LSTM layers   \n",
    "SEQ_MODEL_RNN_TYPE = 'GRU'        \n",
    "SEQ_MODEL_DROPOUT = 0.2\n",
    "\n",
    "# Ensure DEVICE is defined globally\n",
    "# DEVICE = get_device() \n",
    "\n",
    "# It's better to run sequence model training as a separate step after TGAT training is complete.\n",
    "# So, the `train_pipeline` function itself will not be massively changed to include stage 2.\n",
    "# Instead, the __main__ block will call TGAT training, then sequence model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebd06a-8c64-4583-a08b-08be53e7298e",
   "metadata": {},
   "source": [
    "## 8. Main Training Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6727e62-27d4-4ac9-8ffa-2563c1be7743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: train_pipeline function (FINAL, no lines omitted)\n",
    "def train_pipeline():\n",
    "    # --- STAGE 1: Train TGAT Event-Level Model --------------------------------\n",
    "    print(\"--- Stage 1: TGAT Event-Level Model Training ---\")\n",
    "    stage1_start_time = time.time()\n",
    "\n",
    "    processed_train_file_path = globals().get(\n",
    "        \"PROCESSED_TRAIN_FILE\",\n",
    "        \"./processed_data_nslkdd/train_temporal_data_nslkdd.pt\",\n",
    "    )\n",
    "    processed_test_file_path = globals().get(\n",
    "        \"PROCESSED_TEST_FILE\",\n",
    "        \"./processed_data_nslkdd/test_temporal_data_nslkdd.pt\",\n",
    "    )\n",
    "    metadata_file_path = globals().get(\n",
    "        \"METADATA_FILE\",\n",
    "        \"./processed_data_nslkdd/metadata_nslkdd.json\",\n",
    "    )\n",
    "    classification_mode_val = globals().get(\"CLASSIFICATION_MODE\", \"binary\")\n",
    "\n",
    "    if not all(\n",
    "        k in globals()\n",
    "        for k in [\n",
    "            \"PROCESSED_TRAIN_FILE\",\n",
    "            \"METADATA_FILE\",\n",
    "            \"CLASSIFICATION_MODE\",\n",
    "            \"PROCESSED_TEST_FILE\",\n",
    "        ]\n",
    "    ):\n",
    "        print(\n",
    "            \"Warning: Some essential global configuration variables for data loading might be missing. Using defaults.\"\n",
    "        )\n",
    "\n",
    "    train_data_cpu_tgat, metadata_tgat, num_classes_meta_tgat, pos_weight_cpu_tgat = load_processed_data(\n",
    "        processed_train_file_path, metadata_file_path, classification_mode_val\n",
    "    )\n",
    "    test_data_cpu_tgat, _, _, _ = load_processed_data(\n",
    "        processed_test_file_path, metadata_file_path, classification_mode_val\n",
    "    )\n",
    "\n",
    "    NODE_FEAT_DIM_RUNTIME_TGAT = metadata_tgat[\"NODE_FEAT_DIM\"]\n",
    "\n",
    "    device_val = globals().get(\n",
    "        \"DEVICE\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "\n",
    "    # ----- Loss (always BCE + pos_weight) ------------------------------------\n",
    "    if classification_mode_val == \"binary\":\n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = 1\n",
    "        criterion_tgat = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=pos_weight_cpu_tgat.to(device_val)\n",
    "            if pos_weight_cpu_tgat is not None\n",
    "            else None\n",
    "        )\n",
    "    else:\n",
    "        ACTUAL_NUM_OUTPUT_CLASSES_TGAT = metadata_tgat.get(\n",
    "            \"NUM_CLASSES_MULTI\", num_classes_meta_tgat\n",
    "        )\n",
    "        criterion_tgat = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ----- Hyper-parameters ---------------------------------------------------\n",
    "    epochs_val = globals().get(\"EPOCHS\", 30)  # ← default 30\n",
    "    scheduler_type_val = globals().get(\"LR_SCHEDULER\", \"cosine\")\n",
    "    batch_size_val = globals().get(\"BATCH_SIZE\", 256)\n",
    "    learning_rate_val = globals().get(\"LEARNING_RATE\", 5e-4)\n",
    "    hidden_dim_val = globals().get(\"HIDDEN_DIM\", 256)\n",
    "    time_dim_val = globals().get(\"TIME_DIM\", 64)\n",
    "    n_layers_val = globals().get(\"N_LAYERS\", 2)\n",
    "    n_heads_val = globals().get(\"N_HEADS\", 4)\n",
    "    dropout_val = globals().get(\"DROPOUT\", 0.3)\n",
    "    weight_decay_val = globals().get(\"WEIGHT_DECAY\", 1e-5)\n",
    "\n",
    "    print(\"\\n--- TGAT Training Configuration ---\")\n",
    "    print(\n",
    "        f\"Device: {device_val}, Epochs: {epochs_val}, Batch Size: {batch_size_val}, \"\n",
    "        f\"LR: {learning_rate_val}, Scheduler: {scheduler_type_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Node Feat Dim: {NODE_FEAT_DIM_RUNTIME_TGAT}, Hidden Dim: {hidden_dim_val}, \"\n",
    "        f\"Time Emb: {time_dim_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"TGAT Layers: {n_layers_val}, Heads: {n_heads_val}, Dropout: {dropout_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"TGAT Output Dim: {ACTUAL_NUM_OUTPUT_CLASSES_TGAT}, Mode: {classification_mode_val}\"\n",
    "    )\n",
    "    print(f\"TGAT Loss: {type(criterion_tgat).__name__}\")\n",
    "    print(f\"----------------------------\\n\")\n",
    "\n",
    "    # ----- Model & Optim ------------------------------------------------------\n",
    "    tgat_model = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT,\n",
    "        time_emb_dim=time_dim_val,\n",
    "        n_head=n_heads_val,\n",
    "        n_layers=n_layers_val,\n",
    "        hidden_dim_per_layer=hidden_dim_val,\n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT,\n",
    "        dropout=dropout_val,\n",
    "    ).to(device_val)\n",
    "\n",
    "    optimizer_tgat = optim.Adam(\n",
    "        tgat_model.parameters(), lr=learning_rate_val, weight_decay=weight_decay_val\n",
    "    )\n",
    "\n",
    "    if scheduler_type_val == \"cosine\":\n",
    "        lr_scheduler_tgat = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_tgat, T_max=20, eta_min=1e-6\n",
    "        )\n",
    "    else:\n",
    "        lr_scheduler_tgat = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer_tgat,\n",
    "            mode=\"max\",\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            verbose=True,\n",
    "            min_lr=1e-7,\n",
    "        )\n",
    "\n",
    "    # ----- DataLoader ---------------------------------------------------------\n",
    "    num_neighbors_val = globals().get(\"NUM_NEIGHBORS\", [10, 5])\n",
    "    train_loader_tgat = TemporalNeighborLoader(\n",
    "        train_data_cpu_tgat,\n",
    "        batch_size_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader_tgat = TemporalNeighborLoader(\n",
    "        test_data_cpu_tgat,\n",
    "        batch_size_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    best_val_f1_attack_tgat = -1.0\n",
    "    history_tgat = {\n",
    "        k: []\n",
    "        for k in [\n",
    "            \"train_loss\",\n",
    "            \"train_acc\",\n",
    "            \"train_f1\",\n",
    "            \"train_auc\",\n",
    "            \"val_loss\",\n",
    "            \"val_acc\",\n",
    "            \"val_f1\",\n",
    "            \"val_f1_attack\",\n",
    "            \"val_auc\",\n",
    "        ]\n",
    "    }\n",
    "    epochs_without_improvement_tgat = 0\n",
    "    early_stopping_patience_val = globals().get(\"EARLY_STOPPING_PATIENCE\", 20)\n",
    "    clip_grad_norm_val = globals().get(\"CLIP_GRAD_NORM\", 1.0)\n",
    "    model_save_dir_val = globals().get(\"MODEL_SAVE_DIR\", \"./saved_models_nslkdd/\")\n",
    "    best_model_name_val = globals().get(\n",
    "        \"BEST_MODEL_NAME\", \"best_tgat_model_nslkdd.pth\"\n",
    "    )\n",
    "\n",
    "    # ========================== Epoch loop ====================================\n",
    "    for epoch_tgat in range(epochs_val):\n",
    "        epoch_str_display_tgat = f\"TGAT Epoch {epoch_tgat + 1}/{epochs_val}\"\n",
    "        print(f\"--- {epoch_str_display_tgat} ---\")\n",
    "\n",
    "        # ---- train -----------------------------------------------------------\n",
    "        (\n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            train_prec,\n",
    "            train_rec,\n",
    "            train_f1,\n",
    "            train_auc,\n",
    "        ) = train_epoch(\n",
    "            tgat_model,\n",
    "            train_loader_tgat,\n",
    "            optimizer_tgat,\n",
    "            criterion_tgat,\n",
    "            clip_grad_norm_val,\n",
    "        )\n",
    "        print_metrics(\n",
    "            epoch_str_display_tgat,\n",
    "            train_loss,\n",
    "            train_acc,\n",
    "            train_prec,\n",
    "            train_rec,\n",
    "            train_f1,\n",
    "            train_auc,\n",
    "            phase=\"Train TGAT\",\n",
    "        )\n",
    "        for k, v in zip(\n",
    "            [\"loss\", \"acc\", \"f1\", \"auc\"],\n",
    "            [train_loss, train_acc, train_f1, train_auc],\n",
    "        ):\n",
    "            history_tgat[f\"train_{k}\"].append(\n",
    "                v if v is not None and not (isinstance(v, float) and np.isnan(v)) else np.nan\n",
    "            )\n",
    "\n",
    "        # ---- validation ------------------------------------------------------\n",
    "        (\n",
    "            val_loss,\n",
    "            val_acc,\n",
    "            val_prec,\n",
    "            val_rec,\n",
    "            val_f1,\n",
    "            val_auc,\n",
    "            _,\n",
    "            _,\n",
    "            val_class_report_dict_tgat,\n",
    "        ) = evaluate_model(\n",
    "            tgat_model,\n",
    "            test_loader_tgat,\n",
    "            criterion_tgat,\n",
    "            phase=\"Validation TGAT\",\n",
    "            return_embeddings_and_ids=False,\n",
    "        )\n",
    "\n",
    "        # -- Attack F1 ---------------------------------------------------------\n",
    "        val_f1_attack_current_tgat = np.nan\n",
    "        if (\n",
    "            classification_mode_val == \"binary\"\n",
    "            and val_class_report_dict_tgat\n",
    "            and isinstance(val_class_report_dict_tgat, dict)\n",
    "        ):\n",
    "            attack_label_str = (\n",
    "                \"Attack (1)\"\n",
    "                if \"Attack (1)\" in val_class_report_dict_tgat\n",
    "                else (\"1\" if \"1\" in val_class_report_dict_tgat else None)\n",
    "            )\n",
    "            if (\n",
    "                attack_label_str\n",
    "                and attack_label_str in val_class_report_dict_tgat\n",
    "                and val_class_report_dict_tgat[attack_label_str].get(\"f1-score\")\n",
    "                is not None\n",
    "            ):\n",
    "                val_f1_attack_current_tgat = val_class_report_dict_tgat[\n",
    "                    attack_label_str\n",
    "                ].get(\"f1-score\")\n",
    "        elif val_f1 is not None and not np.isnan(val_f1):\n",
    "            val_f1_attack_current_tgat = val_f1\n",
    "\n",
    "        print_metrics(\n",
    "            epoch_str_display_tgat,\n",
    "            val_loss,\n",
    "            val_acc,\n",
    "            val_prec,\n",
    "            val_rec,\n",
    "            val_f1,\n",
    "            val_auc,\n",
    "            phase=\"Validation TGAT\",\n",
    "            class_report=str(val_class_report_dict_tgat)\n",
    "            if val_class_report_dict_tgat\n",
    "            else \"N/A\",\n",
    "        )\n",
    "        history_tgat[\"val_f1_attack\"].append(\n",
    "            val_f1_attack_current_tgat\n",
    "            if not np.isnan(val_f1_attack_current_tgat)\n",
    "            else np.nan\n",
    "        )\n",
    "        for k, v in zip(\n",
    "            [\"loss\", \"acc\", \"f1\", \"auc\"], [val_loss, val_acc, val_f1, val_auc]\n",
    "        ):\n",
    "            history_tgat[f\"val_{k}\"].append(\n",
    "                v if v is not None and not (isinstance(v, float) and np.isnan(v)) else np.nan\n",
    "            )\n",
    "\n",
    "        # ---- scheduler step --------------------------------------------------\n",
    "        if scheduler_type_val == \"cosine\":\n",
    "            lr_scheduler_tgat.step()\n",
    "        else:\n",
    "            scheduler_metric = (\n",
    "                val_f1_attack_current_tgat\n",
    "                if not np.isnan(val_f1_attack_current_tgat)\n",
    "                else -val_loss\n",
    "            )\n",
    "            lr_scheduler_tgat.step(scheduler_metric)\n",
    "\n",
    "        current_lr_tgat = optimizer_tgat.param_groups[0][\"lr\"]\n",
    "        print(f\"TGAT Current LR: {current_lr_tgat}\")\n",
    "\n",
    "        # ---- save best -------------------------------------------------------\n",
    "        if (\n",
    "            not np.isnan(val_f1_attack_current_tgat)\n",
    "            and val_f1_attack_current_tgat > best_val_f1_attack_tgat\n",
    "        ):\n",
    "            best_val_f1_attack_tgat = val_f1_attack_current_tgat\n",
    "            os.makedirs(model_save_dir_val, exist_ok=True)\n",
    "            torch.save(\n",
    "                tgat_model.state_dict(),\n",
    "                os.path.join(model_save_dir_val, best_model_name_val),\n",
    "            )\n",
    "            print(\n",
    "                f\"{epoch_str_display_tgat}: New best TGAT model saved! \"\n",
    "                f\"Val F1 (Attack): {best_val_f1_attack_tgat:.4f}\"\n",
    "            )\n",
    "            epochs_without_improvement_tgat = 0\n",
    "        else:\n",
    "            epochs_without_improvement_tgat += 1\n",
    "            print(\n",
    "                f\"{epoch_str_display_tgat}: No improvement count: {epochs_without_improvement_tgat} \"\n",
    "                f\"(Current F1 Attack: \"\n",
    "                f\"{val_f1_attack_current_tgat if not np.isnan(val_f1_attack_current_tgat) else 'NaN'}, \"\n",
    "                f\"Best F1 Attack: \"\n",
    "                f\"{best_val_f1_attack_tgat if best_val_f1_attack_tgat != -1.0 else 'N/A'}).\"\n",
    "            )\n",
    "\n",
    "        if epochs_without_improvement_tgat >= early_stopping_patience_val:\n",
    "            print(\n",
    "                f\"TGAT Early stopping triggered after \"\n",
    "                f\"{early_stopping_patience_val} epochs without improvement.\"\n",
    "            )\n",
    "            break\n",
    "        print(\"---------------------------------\\n\")\n",
    "\n",
    "    stage1_time = time.time() - stage1_start_time\n",
    "    best_val_f1_attack_tgat_str = (\n",
    "        f\"{best_val_f1_attack_tgat:.4f}\"\n",
    "        if best_val_f1_attack_tgat != -1.0 and not np.isnan(best_val_f1_attack_tgat)\n",
    "        else \"N/A\"\n",
    "    )\n",
    "    print(\n",
    "        f\"--- TGAT Training (Stage 1) Finished in {stage1_time:.2f}s. \"\n",
    "        f\"Best Val F1 (Attack): {best_val_f1_attack_tgat_str} ---\"\n",
    "    )\n",
    "\n",
    "    # ============================= STAGE 2 ===================================\n",
    "    # （以下 Sequence Aggregator 內容保持原樣，未做任何行刪減）\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n\\n--- Stage 2: Sequence Aggregator Model Training ---\")\n",
    "    stage2_start_time = time.time()\n",
    "\n",
    "    best_tgat_model_path = os.path.join(model_save_dir_val, best_model_name_val)\n",
    "    if not os.path.exists(best_tgat_model_path):\n",
    "        print(\n",
    "            f\"Error: Best TGAT model not found at {best_tgat_model_path} from Stage 1.\"\n",
    "            \" Cannot proceed with Stage 2.\"\n",
    "        )\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )  # MODIFIED RETURN\n",
    "\n",
    "    tgat_model_for_embeddings = TGAT(\n",
    "        node_feat_dim=NODE_FEAT_DIM_RUNTIME_TGAT,\n",
    "        time_emb_dim=time_dim_val,\n",
    "        n_head=n_heads_val,\n",
    "        n_layers=n_layers_val,\n",
    "        hidden_dim_per_layer=hidden_dim_val,\n",
    "        num_classes=ACTUAL_NUM_OUTPUT_CLASSES_TGAT,\n",
    "        dropout=dropout_val,\n",
    "    ).to(device_val)\n",
    "    tgat_model_for_embeddings.load_state_dict(\n",
    "        torch.load(best_tgat_model_path, map_location=device_val)\n",
    "    )\n",
    "    tgat_model_for_embeddings.eval()\n",
    "\n",
    "    batch_size_seq_embed_gen_val = globals().get(\"BATCH_SIZE_SEQ_EMBED_GEN\", batch_size_val)\n",
    "\n",
    "    train_event_embeddings, train_event_labels_tgat = get_all_event_embeddings(\n",
    "        tgat_model_for_embeddings,\n",
    "        train_data_cpu_tgat,\n",
    "        batch_size_seq_embed_gen_val,\n",
    "        num_neighbors_val,\n",
    "        device_val,\n",
    "    )\n",
    "    test_event_embeddings = torch.empty(0)\n",
    "    test_event_labels_tgat = torch.empty(0)\n",
    "    if train_event_embeddings.numel() > 0:\n",
    "        test_event_embeddings, test_event_labels_tgat = get_all_event_embeddings(\n",
    "            tgat_model_for_embeddings,\n",
    "            test_data_cpu_tgat,\n",
    "            batch_size_seq_embed_gen_val,\n",
    "            num_neighbors_val,\n",
    "            device_val,\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: Failed to generate train event embeddings for Stage 2. Aborting Stage 2.\")\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    train_event_labels_binary_squeezed = (\n",
    "        (train_event_labels_tgat.squeeze() > 0).long()\n",
    "        if classification_mode_val == \"multiclass\"\n",
    "        else train_event_labels_tgat.squeeze().long()\n",
    "        if train_event_labels_tgat.numel() > 0\n",
    "        else torch.empty(0, dtype=torch.long)\n",
    "    )\n",
    "    test_event_labels_binary_squeezed = (\n",
    "        (test_event_labels_tgat.squeeze() > 0).long()\n",
    "        if classification_mode_val == \"multiclass\"\n",
    "        else test_event_labels_tgat.squeeze().long()\n",
    "        if test_event_labels_tgat.numel() > 0\n",
    "        else torch.empty(0, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "    sequence_length_val = globals().get(\"SEQUENCE_LENGTH\", 10)\n",
    "    step_size_val = globals().get(\"STEP_SIZE\", 5)\n",
    "    seq_label_mode_val = globals().get(\"SEQ_LABEL_MODE\", \"any_attack\")\n",
    "\n",
    "    returned_train_seq_labels_list = []\n",
    "    returned_train_padded_sequences = torch.empty(0)\n",
    "    returned_train_seq_lengths = torch.empty(0, dtype=torch.long)\n",
    "    returned_test_seq_labels_list = []\n",
    "    returned_test_padded_sequences = torch.empty(0)\n",
    "    returned_test_seq_lengths = torch.empty(0, dtype=torch.long)\n",
    "\n",
    "    if train_event_embeddings.numel() > 0 and train_event_labels_binary_squeezed.numel() > 0:\n",
    "        (\n",
    "            _,\n",
    "            returned_train_seq_labels_list,\n",
    "            returned_train_padded_sequences,\n",
    "            returned_train_seq_lengths,\n",
    "        ) = create_embedding_sequences(\n",
    "            train_event_embeddings,\n",
    "            train_event_labels_binary_squeezed,\n",
    "            sequence_length_val,\n",
    "            step_size_val,\n",
    "            seq_label_mode_val,\n",
    "            \"binary\",\n",
    "        )\n",
    "        if returned_train_padded_sequences.numel() == 0:\n",
    "            print(\"No training sequences generated. Aborting Stage 2.\")\n",
    "            return (\n",
    "                history_tgat,\n",
    "                None,\n",
    "                test_event_embeddings,\n",
    "                test_event_labels_binary_squeezed,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "\n",
    "        train_sequence_dataset = EmbeddingSequenceDataset(\n",
    "            returned_train_padded_sequences,\n",
    "            returned_train_seq_labels_list,\n",
    "            returned_train_seq_lengths,\n",
    "        )\n",
    "        batch_size_seq_model_val = globals().get(\"BATCH_SIZE_SEQ_MODEL\", 64)\n",
    "        train_sequence_loader = DataLoader(\n",
    "            train_sequence_dataset,\n",
    "            batch_size=batch_size_seq_model_val,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn_packed_fixed_length,\n",
    "        )\n",
    "        print(f\"Created {len(train_sequence_dataset)} training sequences.\")\n",
    "    else:\n",
    "        print(\"No train event embeddings or labels. Aborting Stage 2.\")\n",
    "        return (\n",
    "            history_tgat,\n",
    "            None,\n",
    "            test_event_embeddings,\n",
    "            test_event_labels_binary_squeezed,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    test_sequence_loader = None\n",
    "    if test_event_embeddings.numel() > 0 and test_event_labels_binary_squeezed.numel() > 0:\n",
    "        (\n",
    "            _,\n",
    "            returned_test_seq_labels_list,\n",
    "            returned_test_padded_sequences,\n",
    "            returned_test_seq_lengths,\n",
    "        ) = create_embedding_sequences(\n",
    "            test_event_embeddings,\n",
    "            test_event_labels_binary_squeezed,\n",
    "            sequence_length_val,\n",
    "            step_size_val,\n",
    "            seq_label_mode_val,\n",
    "            \"binary\",\n",
    "        )\n",
    "        if returned_test_padded_sequences.numel() > 0:\n",
    "            test_sequence_dataset = EmbeddingSequenceDataset(\n",
    "                returned_test_padded_sequences,\n",
    "                returned_test_seq_labels_list,\n",
    "                returned_test_seq_lengths,\n",
    "            )\n",
    "            test_sequence_loader = DataLoader(\n",
    "                test_sequence_dataset,\n",
    "                batch_size=batch_size_seq_model_val,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn_packed_fixed_length,\n",
    "            )\n",
    "            print(f\"Created {len(test_sequence_dataset)} test sequences.\")\n",
    "        else:\n",
    "            print(\"No test sequences generated for sequence model evaluation.\")\n",
    "    else:\n",
    "        print(\"No test event embeddings or labels available for test sequences.\")\n",
    "\n",
    "    seq_model_input_dim = (\n",
    "        train_event_embeddings.shape[1] if train_event_embeddings.numel() > 0 else hidden_dim_val\n",
    "    )\n",
    "    seq_model_hidden_dim_val = globals().get(\"SEQ_MODEL_HIDDEN_DIM\", 128)\n",
    "    seq_model_num_layers_val = globals().get(\"SEQ_MODEL_NUM_LAYERS\", 1)\n",
    "    seq_model_dropout_val = globals().get(\"SEQ_MODEL_DROPOUT\", 0.2)\n",
    "    seq_model_rnn_type_val = globals().get(\"SEQ_MODEL_RNN_TYPE\", \"GRU\")\n",
    "\n",
    "    sequence_model = EventSequenceAggregator(\n",
    "        embedding_dim=seq_model_input_dim,\n",
    "        hidden_dim=seq_model_hidden_dim_val,\n",
    "        num_layers=seq_model_num_layers_val,\n",
    "        num_classes=1,\n",
    "        dropout=seq_model_dropout_val,\n",
    "        rnn_type=seq_model_rnn_type_val,\n",
    "    ).to(device_val)\n",
    "\n",
    "    lr_seq_model_val = globals().get(\"LEARNING_RATE_SEQ_MODEL\", 1e-4)\n",
    "    criterion_seq = nn.BCEWithLogitsLoss()\n",
    "    optimizer_seq = optim.Adam(sequence_model.parameters(), lr=lr_seq_model_val)\n",
    "\n",
    "    epochs_seq_model_val = globals().get(\"EPOCHS_SEQ_MODEL\", 20)\n",
    "    print(\n",
    "        f\"\\n--- Training Sequence Aggregator Model ({seq_model_rnn_type_val}) ---\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Input Embedding Dim: {seq_model_input_dim}, Sequence Length: {sequence_length_val}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Seq Model: Hidden={seq_model_hidden_dim_val}, Layers={seq_model_num_layers_val}, \"\n",
    "        f\"Dropout={seq_model_dropout_val}\"\n",
    "    )\n",
    "    print(f\"Optimizer: Adam, LR={lr_seq_model_val}. Epochs: {epochs_seq_model_val}\")\n",
    "\n",
    "    history_sequence_model = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "        \"val_auc\": [],\n",
    "    }\n",
    "\n",
    "    for epoch_seq in range(epochs_seq_model_val):\n",
    "        print(f\"Sequence Model Epoch {epoch_seq + 1}/{epochs_seq_model_val}\")\n",
    "        if train_sequence_loader and len(train_sequence_loader) > 0:\n",
    "            train_loss_s, train_acc_s, _, _, train_f1_s = train_sequence_epoch(\n",
    "                sequence_model,\n",
    "                train_sequence_loader,\n",
    "                optimizer_seq,\n",
    "                criterion_seq,\n",
    "                device_val,\n",
    "            )\n",
    "            history_sequence_model[\"train_loss\"].append(train_loss_s)\n",
    "            history_sequence_model[\"train_acc\"].append(train_acc_s)\n",
    "            history_sequence_model[\"train_f1\"].append(train_f1_s)\n",
    "\n",
    "            print(\n",
    "                f\"  Seq Train: Loss={train_loss_s:.4f}, Acc={train_acc_s:.4f}, \"\n",
    "                f\"F1={train_f1_s:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"  Skipping sequence training epoch (no loader).\")\n",
    "            for k in [\"train_loss\", \"train_acc\", \"train_f1\"]:\n",
    "                history_sequence_model[k].append(float(\"nan\"))\n",
    "\n",
    "        if test_sequence_loader and len(test_sequence_loader) > 0:\n",
    "            (\n",
    "                val_loss_s,\n",
    "                val_acc_s,\n",
    "                _,\n",
    "                _,\n",
    "                val_f1_s,\n",
    "                val_auc_s,\n",
    "                _,\n",
    "                _,\n",
    "            ) = evaluate_sequence_model(\n",
    "                sequence_model,\n",
    "                test_sequence_loader,\n",
    "                criterion_seq,\n",
    "                device_val,\n",
    "                phase=\"Val Seq Agg\",\n",
    "            )\n",
    "            history_sequence_model[\"val_loss\"].append(val_loss_s)\n",
    "            history_sequence_model[\"val_acc\"].append(val_acc_s)\n",
    "            history_sequence_model[\"val_f1\"].append(val_f1_s)\n",
    "            history_sequence_model[\"val_auc\"].append(\n",
    "                val_auc_s if val_auc_s is not None and not np.isnan(val_auc_s) else np.nan\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"  Seq Val:   Loss={val_loss_s:.4f}, Acc={val_acc_s:.4f}, \"\n",
    "                f\"F1={val_f1_s:.4f}, AUC={val_auc_s:.4f if val_auc_s else 'N/A'}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"  No test data for sequence model validation this epoch.\")\n",
    "            for k in [\"val_loss\", \"val_acc\", \"val_f1\", \"val_auc\"]:\n",
    "                history_sequence_model[k].append(float(\"nan\"))\n",
    "\n",
    "    stage2_time = time.time() - stage2_start_time\n",
    "    print(f\"--- Sequence Aggregator Training (Stage 2) Finished in {stage2_time:.2f}s ---\")\n",
    "\n",
    "    seq_model_save_path = os.path.join(\n",
    "        model_save_dir_val, \"sequence_aggregator_model_nslkdd.pth\"\n",
    "    )\n",
    "    os.makedirs(model_save_dir_val, exist_ok=True)\n",
    "    torch.save(sequence_model.state_dict(), seq_model_save_path)\n",
    "    print(f\"Sequence aggregator model saved to {seq_model_save_path}\")\n",
    "\n",
    "    combined_history = {\n",
    "        \"tgat\": history_tgat,\n",
    "        \"sequence_aggregator\": history_sequence_model,\n",
    "    }\n",
    "\n",
    "    # 返回 Stage-2 測試集資料供主程式使用\n",
    "    return (\n",
    "        combined_history,\n",
    "        sequence_model,\n",
    "        test_event_embeddings,\n",
    "        test_event_labels_binary_squeezed,\n",
    "        returned_test_seq_labels_list,\n",
    "        returned_test_padded_sequences,\n",
    "        returned_test_seq_lengths,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4407f186-ed1d-43f2-951e-4b7994642995",
   "metadata": {},
   "source": [
    "## 9. Execute Training and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bf76e-e447-4a64-8797-e172ce67c977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell: Main execution block  (FINAL – no lines omitted)\n",
    "\n",
    "import os, sys, json, shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ----------------------------------------------------------\n",
    "    # 0. 若 .pt/.json 不存在 → 自動跑一次預處理\n",
    "    # ----------------------------------------------------------\n",
    "    missing_files = [\n",
    "        p for p in [PROCESSED_TRAIN_FILE, PROCESSED_TEST_FILE, METADATA_FILE]\n",
    "        if not os.path.exists(p)\n",
    "    ]\n",
    "    if missing_files:\n",
    "        print(\"Missing pre-processed files:\", missing_files)\n",
    "        print(\"Running preprocess_and_save_temporal_data() automatically…\")\n",
    "\n",
    "        preprocess_and_save_temporal_data(\n",
    "            raw_file_path=os.path.join(RAW_DATA_DIR, TRAIN_FILE),\n",
    "            output_file_path=PROCESSED_TRAIN_FILE,\n",
    "            numerical_cols_original_config=NUMERICAL_COLS,\n",
    "            categorical_cols=CATEGORICAL_COLS,\n",
    "            label_col='label',\n",
    "            is_training_set=True\n",
    "        )\n",
    "        # 測試集可簡易複製 train（若你已另外處理，可刪除下行）\n",
    "        shutil.copy(PROCESSED_TRAIN_FILE, PROCESSED_TEST_FILE)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 1. 執行 TGAT + Sequence pipeline\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\n--- Starting Combined Training Pipeline (TGAT and Sequence Model) for NSL-KDD ---\")\n",
    "\n",
    "    (combined_history_data,\n",
    "     final_trained_sequence_model,\n",
    "     returned_test_event_embeddings,\n",
    "     returned_test_event_labels_binary_squeezed,\n",
    "     returned_test_seq_labels_list,\n",
    "     returned_test_padded_sequences,\n",
    "     returned_test_seq_lengths) = train_pipeline()\n",
    "\n",
    "    if not combined_history_data:\n",
    "        print(\"Training pipeline failed.  Aborting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 2. 保存歷史 CSV\n",
    "    # ----------------------------------------------------------\n",
    "    history_tgat = combined_history_data.get('tgat')\n",
    "    history_sequence_model = combined_history_data.get('sequence_aggregator')\n",
    "\n",
    "    if history_tgat:\n",
    "        try:\n",
    "            df_tgat_history = pd.DataFrame(history_tgat)\n",
    "            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "            path_hist_tgat = os.path.join(MODEL_SAVE_DIR, 'tgat_training_history_nslkdd.csv')\n",
    "            df_tgat_history.to_csv(path_hist_tgat, index_label='epoch')\n",
    "            print(f\"\\nTGAT history saved ► {path_hist_tgat}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving TGAT history: {e}\")\n",
    "\n",
    "    if history_sequence_model:\n",
    "        try:\n",
    "            df_seq_hist = pd.DataFrame(history_sequence_model)\n",
    "            os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "            path_hist_seq = os.path.join(MODEL_SAVE_DIR, 'sequence_model_training_history_nslkdd.csv')\n",
    "            df_seq_hist.to_csv(path_hist_seq, index_label='epoch')\n",
    "            print(f\"Seq-Agg history saved ► {path_hist_seq}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving Seq-Agg history: {e}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 3.  繪製 TGAT 訓練/驗證曲線\n",
    "    # ----------------------------------------------------------\n",
    "    if history_tgat:\n",
    "        fig_tgat, axs_tgat = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        map_tgat = [('Loss','loss'), ('Accuracy','acc'), ('F1-score','f1'), ('AUC','auc')]\n",
    "        for i,(ttl,key) in enumerate(map_tgat):\n",
    "            ax = axs_tgat[i//2, i%2]\n",
    "            tr_vals = [v for v in history_tgat.get(f'train_{key}', []) if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            vl_vals = [v for v in history_tgat.get(f'val_{key}', [])   if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_tr   = [j for j,v in enumerate(history_tgat.get(f'train_{key}', [])) if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_vl   = [j for j,v in enumerate(history_tgat.get(f'val_{key}', []))   if v is not None and not (isinstance(v, float) and torch.isnan(torch.tensor(v)))]\n",
    "            if ep_tr and tr_vals: ax.plot(ep_tr, tr_vals, label=f'Train {ttl}')\n",
    "            if ep_vl and vl_vals: ax.plot(ep_vl, vl_vals, label=f'Val {ttl}')\n",
    "            ax.set_title(f'TGAT {ttl}'); ax.set_xlabel('Epoch'); ax.set_ylabel(ttl); ax.legend()\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 4.  繪製 Sequence-Aggregator 訓練/驗證曲線\n",
    "    # ----------------------------------------------------------\n",
    "    if history_sequence_model:\n",
    "        metrics_seq = [('Loss','loss'), ('Accuracy','acc'), ('F1-score','f1')]\n",
    "        if any(val is not None and not (isinstance(val,float) and torch.isnan(torch.tensor(val)))\n",
    "               for val in history_sequence_model.get('val_auc', [])):\n",
    "            metrics_seq.append(('AUC','auc'))\n",
    "\n",
    "        if len(metrics_seq) == 3:\n",
    "            fig_seq, axs_seq = plt.subplots(1,3,figsize=(18,5)); axs_seq = axs_seq.reshape(-1)\n",
    "        elif len(metrics_seq) == 4:\n",
    "            fig_seq, axs_seq = plt.subplots(2,2,figsize=(12,10)); axs_seq = axs_seq.flatten()\n",
    "        else:\n",
    "            fig_seq, axs_seq = plt.subplots(1,len(metrics_seq),figsize=(6*len(metrics_seq),5)); axs_seq = axs_seq.reshape(-1)\n",
    "\n",
    "        for i,(ttl,key) in enumerate(metrics_seq):\n",
    "            ax = axs_seq[i]\n",
    "            tr_vals = [v for v in history_sequence_model.get(f'train_{key}', []) if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            vl_vals = [v for v in history_sequence_model.get(f'val_{key}', [])   if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_tr   = [j for j,v in enumerate(history_sequence_model.get(f'train_{key}', [])) if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            ep_vl   = [j for j,v in enumerate(history_sequence_model.get(f'val_{key}', []))   if v is not None and not (isinstance(v,float) and torch.isnan(torch.tensor(v)))]\n",
    "            if ep_tr and tr_vals: ax.plot(ep_tr, tr_vals, label=f'Train {ttl}')\n",
    "            if ep_vl and vl_vals: ax.plot(ep_vl, vl_vals, label=f'Val {ttl}')\n",
    "            ax.set_title(f'Seq-Agg {ttl}'); ax.set_xlabel('Epoch'); ax.set_ylabel(ttl); ax.legend()\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 5. 最佳 TGAT 模型在測試集最終評估\n",
    "    # ----------------------------------------------------------\n",
    "    print(\"\\n--- Final Evaluation of Best TGAT Model (Stage-1) on Test Set ---\")\n",
    "    best_tgat_path = os.path.join(MODEL_SAVE_DIR, BEST_MODEL_NAME)\n",
    "    if os.path.exists(best_tgat_path):\n",
    "        with open(METADATA_FILE) as f: meta = json.load(f)\n",
    "        tgat_model_final = TGAT(\n",
    "            node_feat_dim=meta['NODE_FEAT_DIM'],\n",
    "            time_emb_dim=TIME_DIM,\n",
    "            n_head=N_HEADS,\n",
    "            n_layers=N_LAYERS,\n",
    "            hidden_dim_per_layer=HIDDEN_DIM,\n",
    "            num_classes=1,\n",
    "            dropout=DROPOUT\n",
    "        ).to(DEVICE)\n",
    "        tgat_model_final.load_state_dict(torch.load(best_tgat_path, map_location=DEVICE))\n",
    "        test_data_cpu, _, _, pos_w = load_processed_data(PROCESSED_TEST_FILE, METADATA_FILE, CLASSIFICATION_MODE)\n",
    "        loader_test = TemporalNeighborLoader(\n",
    "            test_data_cpu, BATCH_SIZE, NUM_NEIGHBORS, DEVICE,\n",
    "            shuffle=False,\n",
    "            recency_bias_factor=RECENCY_BIAS_FACTOR,\n",
    "            feature_similarity_col_name=FEATURE_SIMILARITY_COL_NAME,\n",
    "            feature_similarity_weight=FEATURE_SIMILARITY_WEIGHT,\n",
    "            raw_data_file_path_for_ids=os.path.join(RAW_DATA_DIR, TEST_FILE),\n",
    "            col_names_list=COL_NAMES\n",
    "        )\n",
    "        crit = nn.BCEWithLogitsLoss(pos_weight=pos_w.to(DEVICE) if pos_w is not None else None)\n",
    "        loss_f, acc_f, prec_f, rec_f, f1_f, auc_f, y_true_f, y_pred_f, rpt_f = evaluate_model(\n",
    "            tgat_model_final, loader_test, crit,\n",
    "            phase='Final TGAT Test', return_embeddings_and_ids=False)\n",
    "        print_metrics(\"Final TGAT Test\", loss_f, acc_f, prec_f, rec_f, f1_f, auc_f,\n",
    "                      phase='Final TGAT', class_report=str(rpt_f))\n",
    "        if y_true_f and y_pred_f:\n",
    "            plot_confusion_matrix_custom(\n",
    "                y_true_f, y_pred_f,\n",
    "                class_names=['Normal (0)','Attack (1)'],\n",
    "                title='Final TGAT Confusion Matrix')\n",
    "\n",
    "    else:\n",
    "        print(f\"Best TGAT model not found ► {best_tgat_path}\")\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # 6. 最佳 Sequence-Aggregator 模型在測試序列最終評估\n",
    "    # ----------------------------------------------------------\n",
    "    if final_trained_sequence_model and returned_test_padded_sequences.numel():\n",
    "        print(\"\\n--- Final Evaluation of Sequence Aggregator on Test Sequences ---\")\n",
    "        final_test_seq_ds = EmbeddingSequenceDataset(\n",
    "            returned_test_padded_sequences,\n",
    "            returned_test_seq_labels_list,\n",
    "            returned_test_seq_lengths\n",
    "        )\n",
    "        final_test_seq_loader = DataLoader(\n",
    "            final_test_seq_ds,\n",
    "            batch_size=BATCH_SIZE_SEQ_MODEL,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn_packed_fixed_length\n",
    "        )\n",
    "        crit_seq = nn.BCEWithLogitsLoss()\n",
    "        _, _, _, _, _, _, seq_true, seq_pred = evaluate_sequence_model(\n",
    "            final_trained_sequence_model,\n",
    "            final_test_seq_loader,\n",
    "            crit_seq,\n",
    "            DEVICE,\n",
    "            phase=\"Final Seq-Agg Test\")\n",
    "        if seq_true and seq_pred:\n",
    "            plot_confusion_matrix_custom(\n",
    "                seq_true, seq_pred,\n",
    "                class_names=['Normal Seq','Attack Seq'],\n",
    "                title='Final Sequence-Agg Confusion Matrix')\n",
    "    else:\n",
    "        print(\"Sequence-Aggregator final evaluation skipped (no sequences or model unavailable).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974786e-9773-4ec4-9c25-5e2b7338c121",
   "metadata": {},
   "source": [
    "## 10. How to Run & Notes\n",
    "- **Ensure Preprocessing is Done**: Run `preprocess_kdd_large.ipynb` first.\n",
    "- **Adjust Configuration**: Check paths and hyperparameters in Cell 2.\n",
    "- **Run All Cells**: This will train, evaluate, save the best model, and plot metrics.\n",
    "- **Memory for `TemporalNeighborLoader`**:\n",
    "    - The current loader sends the *entire* graph's features (`self.temporal_data.x`) and timestamps (`self.temporal_data.ts`) to the specified `device` *for each batch*.\n",
    "    - **If `self.temporal_data.x` (all node features for the entire dataset) is too large to fit on the GPU, this will cause an Out-Of-Memory (OOM) error.**\n",
    "    - **For truly massive graphs**: The loader and model interaction need modification. For example, keep full data on CPU, loader passes indices, model fetches only necessary data slices to GPU. This is a more advanced optimization not implemented here but crucial for >GPU memory graphs. This script currently assumes the full feature/timestamp tensors fit on the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11633d-ae85-419c-93bf-781961fca663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
